import pandas as pd
import os
from datetime import datetime, timedelta
import re

# è½‰æ›æ°‘åœ‹å¹´ç‚ºè¥¿å…ƒå¹´
def convert_roc_to_gregorian(roc_date_str):
    """å°‡ 'YYY/MM/DD' æˆ– 'YYY/M/D' æ ¼å¼çš„æ°‘åœ‹æ—¥æœŸå­—ä¸²è½‰æ›ç‚º 'YYYY/MM/DD' è¥¿å…ƒæ—¥æœŸå­—ä¸²ã€‚"""
    if pd.isna(roc_date_str) or not isinstance(roc_date_str, str):
        return None
    
    parts = roc_date_str.split('/')
    if len(parts) == 3:
        try:
            roc_year = int(parts[0].strip())
            gregorian_year = roc_year + 1911
            
            month = parts[1].strip().zfill(2) 
            day = parts[2].strip().zfill(2)  
            
            return f"{gregorian_year}/{month}/{day}"
        except ValueError:
            return None 
    return None

# --- è¨­å®šè·¯å¾‘èˆ‡è­‰åˆ¸è³‡è¨Š ---
STOCK_CODE = "8039"
STOCK_NAME = "å°è™¹" 
input_dir = r"D:\Python_repo\python\Jason_Stock_Analyzer\datas\raw\1_STOCK_DAY\\" + STOCK_CODE
output_file = f"{STOCK_CODE}_stocks_data.csv"
output_path = os.path.join(os.path.dirname(input_dir), output_file) 

ENCODINGS_TO_TRY = ['utf-8-sig', 'big5', 'utf-8', 'cp950'] 
PRICE_COLS = ['é–‹ç›¤åƒ¹', 'æœ€é«˜åƒ¹', 'æœ€ä½Žåƒ¹', 'æ”¶ç›¤åƒ¹']
VOL_COL = 'æˆäº¤è‚¡æ•¸' 
ALL_REQUIRED_COLS = ['æ—¥æœŸ'] + PRICE_COLS + [VOL_COL] 


# --- è³‡æ–™è™•ç†éƒ¨åˆ† (åˆä½µèˆ‡æ¸…ç†) ---
all_data = []
print(f"--- ðŸš€ é–‹å§‹è™•ç†è³‡æ–™å¤¾ï¼š{input_dir} ---")

for filename in os.listdir(input_dir):
    if filename.endswith(".csv"):
        filepath = os.path.join(input_dir, filename)
        df, used_encoding = None, None
        
        for encoding in ENCODINGS_TO_TRY:
            try:
                # è®€å–æ™‚ä¸è·³éŽæ¨™é ­ï¼Œç¢ºä¿èƒ½ç²å–æ­£ç¢ºçš„æ¬„ä½åç¨±
                df = pd.read_csv(filepath, encoding=encoding, header=0) 
                used_encoding = encoding
                break
            except UnicodeDecodeError:
                continue
            except Exception as e:
                print(f"âŒ æª”æ¡ˆ {filename} ä½¿ç”¨ {encoding} è®€å–æ™‚ç™¼ç”Ÿéžç·¨ç¢¼éŒ¯èª¤: {e}")
                break
        
        if df is None:
            continue
        
        try:
            df.columns = df.columns.str.strip()
            
            if not all(col in df.columns for col in ALL_REQUIRED_COLS):
                 missing_cols = [col for col in ALL_REQUIRED_COLS if col not in df.columns]
                 raise KeyError(f"æª”æ¡ˆæ¬„ä½åç¨±ä¸ç¬¦é æœŸï¼Œç¼ºå°‘æ¬„ä½: {', '.join(missing_cols)}")

            print(f"\nDEBUG: æª”æ¡ˆ {filename} è®€å–æˆåŠŸ (ä½¿ç”¨ {used_encoding} ç·¨ç¢¼)ã€‚")
            print(f"DEBUG: æ¸…ç†å‰è³‡æ–™ç­†æ•¸: {len(df)}")
            
            # --- æ­¥é©Ÿ 2.1: è™•ç†æ—¥æœŸæ¬„ä½æ ¼å¼ (æ°‘åœ‹å¹´è½‰è¥¿å…ƒå¹´) ---
            date_strings = df['æ—¥æœŸ'].astype(str).str.strip()
            df['æ—¥æœŸ'] = [convert_roc_to_gregorian(date_str) for date_str in date_strings]
            
            df.dropna(subset=['æ—¥æœŸ'], inplace=True)
            df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], format='%Y/%m/%d')
            
            # --- æ­¥é©Ÿ 2.2: æ¸…ç†æ‰€æœ‰åƒ¹æ ¼å’Œæˆäº¤é‡æ¬„ä½ ---
            all_value_cols = PRICE_COLS + [VOL_COL]
            for col in all_value_cols:
                # ç§»é™¤é€—è™Ÿ
                df[col] = df[col].astype(str).str.replace(',', '', regex=False)
                # å°‡æ‰€æœ‰ç©ºå€¼ã€ç„¡æ•ˆå€¼æ›¿æ›ç‚º NA
                df[col] = df[col].replace(['-', 'nan', 'NaN', ''], pd.NA) 
            
            # ç§»é™¤åŒ…å« NA çš„è¡Œ
            df.dropna(subset=ALL_REQUIRED_COLS, inplace=True)
            
            # è½‰æ›ç‚ºæµ®é»žæ•¸ï¼ˆåƒ¹æ ¼ï¼‰å’Œæ•´æ•¸ï¼ˆæˆäº¤é‡ï¼‰
            for col in PRICE_COLS:
                 df[col] = df[col].astype(float)
            df[VOL_COL] = df[VOL_COL].astype(float) # å…ˆè½‰ float è™•ç† NAï¼Œä¹‹å¾Œè½‰ int
            
            all_data.append(df[ALL_REQUIRED_COLS])
            
            print(f"DEBUG: æ¸…ç†å¾Œæœ€çµ‚ç­†æ•¸: {len(df)}")
            print(f"âœ… æˆåŠŸè™•ç†æª”æ¡ˆ: {filename} (äº¤æ˜“è³‡æ–™ {len(df)} ç­†)")
            
        except Exception as e:
            print(f"âŒ æª”æ¡ˆ {filename} è™•ç†è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            continue

# 3. åˆä½µæ‰€æœ‰è³‡æ–™ä¸¦é€²è¡Œæ™‚é–“æŽ’åº
if not all_data:
    print("\nâš ï¸ éŒ¯èª¤ï¼šè³‡æ–™å¤¾ä¸­æ²’æœ‰æ‰¾åˆ°å¯ç”¨çš„è³‡æ–™æª”æ¡ˆã€‚ç„¡æ³•é€²è¡Œå¾ŒçºŒè™•ç†ã€‚")
    exit()

combined_df = pd.concat(all_data, ignore_index=True)
combined_df.drop_duplicates(subset=['æ—¥æœŸ'], inplace=True)
combined_df.sort_values(by='æ—¥æœŸ', ascending=True, inplace=True)
combined_df.reset_index(drop=True, inplace=True)

# ç¢ºä¿æˆäº¤é‡ç‚ºæ•´æ•¸
combined_df[VOL_COL] = combined_df[VOL_COL].astype(int) 

print("\n--- ðŸ“Š è³‡æ–™åˆä½µèˆ‡æŽ’åºå®Œæˆ ---")

# =================================================================
# 4. è¨ˆç®—æ‰€æœ‰æŠ€è¡“æŒ‡æ¨™
# =================================================================

# --- 4.1. MA (MA5, MA10, MA20) ---
combined_df['MA5'] = combined_df['æ”¶ç›¤åƒ¹'].rolling(window=5, min_periods=1).mean().round(2).fillna(0)
combined_df['MA10'] = combined_df['æ”¶ç›¤åƒ¹'].rolling(window=10, min_periods=1).mean().round(2).fillna(0)
combined_df['MA20'] = combined_df['æ”¶ç›¤åƒ¹'].rolling(window=20, min_periods=1).mean().round(2).fillna(0)

# --- 4.2. MACD (12, 26, 9) ---
exp12 = combined_df['æ”¶ç›¤åƒ¹'].ewm(span=12, adjust=False).mean()
exp26 = combined_df['æ”¶ç›¤åƒ¹'].ewm(span=26, adjust=False).mean()
combined_df['MACD'] = (exp12 - exp26).round(2)
combined_df['Signal'] = combined_df['MACD'].ewm(span=9, adjust=False).mean().round(2)
combined_df['MACD_Hist'] = (combined_df['MACD'] - combined_df['Signal']).round(2)

# --- 4.3. KD (9, 3, 3) ---
low_9 = combined_df['æœ€ä½Žåƒ¹'].rolling(window=9).min()
high_9 = combined_df['æœ€é«˜åƒ¹'].rolling(window=9).max()
combined_df['RSV'] = ((combined_df['æ”¶ç›¤åƒ¹'] - low_9) / (high_9 - low_9) * 100).round(2)
combined_df['K'] = combined_df['RSV'].ewm(com=2, adjust=False).mean().round(2) # com=2 ç›¸ç•¶æ–¼ span=3
combined_df['D'] = combined_df['K'].ewm(com=2, adjust=False).mean().round(2) # com=2 ç›¸ç•¶æ–¼ span=3

# =================================================================
# ã€åˆªé™¤ KDJ (K9, D9, J) è¨ˆç®—ã€‘
# --- 4.4. KDJ (K9, D9, J) --- æ­¤éƒ¨åˆ†å·²åˆªé™¤
# =================================================================


# --- 4.5. BBands (20, 2) ---
BB_PERIOD = 20
BB_STD_DEV = 2
# ä¸­ç·š (MB)
combined_df['MB'] = combined_df['æ”¶ç›¤åƒ¹'].rolling(window=BB_PERIOD).mean().round(2)
# æ¨™æº–å·® (Std Dev)
std_dev = combined_df['æ”¶ç›¤åƒ¹'].rolling(window=BB_PERIOD).std()
# ä¸Šè»Œç·š (UB)
combined_df['UB'] = (combined_df['MB'] + BB_STD_DEV * std_dev).round(2)
# ä¸‹è»Œç·š (LB)
combined_df['LB'] = (combined_df['MB'] - BB_STD_DEV * std_dev).round(2)
# åˆªé™¤éŽæ¸¡æ¬„ä½
combined_df.drop(columns=['MB'], inplace=True)


# --- 4.6. RSI (RSI5, RSI10) ---
def calculate_rsi(data, period):
    # è¨ˆç®—æ¯æ—¥æ¼²è·Œå¹…
    delta = data.diff()
    # åˆ†é›¢ä¸Šæ¼²å’Œä¸‹è·Œ
    gain = delta.where(delta > 0, 0)
    loss = -delta.where(delta < 0, 0)
    
    # è¨ˆç®—å¹³æ»‘å¹³å‡ (é€šå¸¸ä½¿ç”¨ä¿®æ­£çš„æŒ‡æ•¸ç§»å‹•å¹³å‡ Wilders Smoothing)
    # pandas ewm(com=period-1) å¯¦ç¾èˆ‡ RSI æ…£ç”¨çš„ Wilders Smoothing ç›¸åŒ
    avg_gain = gain.ewm(com=period - 1, adjust=False).mean()
    avg_loss = loss.ewm(com=period - 1, adjust=False).mean()
    
    # é¿å…é™¤ä»¥é›¶
    rs = avg_gain / avg_loss.replace(0, 1e-10)
    rsi = 100 - (100 / (1 + rs))
    return rsi.round(2)

combined_df['RSI5'] = calculate_rsi(combined_df['æ”¶ç›¤åƒ¹'], 5)
combined_df['RSI10'] = calculate_rsi(combined_df['æ”¶ç›¤åƒ¹'], 10)


# --- 4.7. VOL MA (VOL5, VOL10) ---
# åŽŸå§‹æˆäº¤é‡ (VOL) å°±æ˜¯ 'æˆäº¤è‚¡æ•¸'ï¼Œç‚ºäº†æ–¹ä¾¿è¼¸å‡ºï¼Œå°‡å…¶æ”¹åç‚º VOL
combined_df['VOL'] = combined_df[VOL_COL] 
combined_df['VOL5'] = combined_df['VOL'].rolling(window=5, min_periods=1).mean().round(0).astype(int)
combined_df['VOL10'] = combined_df['VOL'].rolling(window=10, min_periods=1).mean().round(0).astype(int)
# åˆªé™¤åŽŸå§‹æˆäº¤è‚¡æ•¸æ¬„ä½ï¼Œåªä¿ç•™ VOL
combined_df.drop(columns=[VOL_COL], inplace=True)


# --- 4.8. æ¸…ç†æ‰€æœ‰æ–°å¢žæŒ‡æ¨™çš„ NaN å€¼ ---
# ã€ä¿®æ­£é»žã€‘ï¼šåˆªé™¤ K9, D9, J
indicator_cols = ['MACD', 'Signal', 'MACD_Hist', 'RSV', 'K', 'D', 'UB', 'LB', 'RSI5', 'RSI10']
combined_df[indicator_cols] = combined_df[indicator_cols].fillna(0)

# ç¢ºä¿ BBands çš„ UB/LB åœ¨ç„¡æ•ˆæ™‚é¡¯ç¤ºç‚º 0
combined_df['UB'] = combined_df['UB'].fillna(0)
combined_df['LB'] = combined_df['LB'].fillna(0)


print("--- âœ… æ‰€æœ‰æŒ‡æ¨™ (MA, MACD, KD, BBands, RSI, VOL MA) è¨ˆç®—å®Œæˆ ---")


# 5. å¦å­˜æª”æ¡ˆç‚º 2330_stocks_data.csv 
combined_df['æ—¥æœŸ_str'] = combined_df['æ—¥æœŸ'].dt.strftime('%Y/%m/%d') 

# ã€ä¿®æ­£é»žã€‘ï¼šåˆªé™¤ K9, D9, J è¼¸å‡ºæ¬„ä½
output_cols = (
    ['æ—¥æœŸ_str'] + PRICE_COLS + 
    ['MA5', 'MA10', 'MA20'] + 
    ['MACD', 'Signal', 'MACD_Hist', 'RSV', 'K', 'D'] + 
    ['UB', 'LB'] + 
    ['RSI5', 'RSI10'] + 
    ['VOL', 'VOL5', 'VOL10'] # K9, D9, J å·²åˆªé™¤
)

combined_df.to_csv(output_path, index=False, encoding='utf-8-sig', columns=output_cols)
combined_df.drop(columns=['æ—¥æœŸ_str'], inplace=True) 

print(f"\n--- ðŸŽ‰ è³‡æ–™å·²è™•ç†ä¸¦å„²å­˜è‡³ï¼š{output_path} ---")


print(f"\nðŸŽ‰ ç¸½é«”ä»»å‹™å®Œæˆï¼")