import tkinter as tk
from tkinter import scrolledtext
import sys
import time
import threading
import requests
import pandas as pd
from typing import Optional, List, Any, Dict
from io import StringIO
from datetime import datetime, timedelta
import pathlib
import urllib3
import re # å¼•å…¥æ­£å‰‡è¡¨é”å¼

# æŠ‘åˆ¶ç•¶ verify=False æ™‚å½ˆå‡ºçš„ InsecureRequestWarning è­¦å‘Š
requests.packages.urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- è¨­å®šèˆ‡è·¯å¾‘ (å…¨é¢ä½¿ç”¨ pathlib) ---
# ç²å–ç•¶å‰æ–‡ä»¶æ‰€åœ¨çš„ç›®éŒ„
BASE_DIR = pathlib.Path(__file__).resolve().parent

# äº¤æ˜“æ—¥æ¸…å–®è·¯å¾‘ (ç”¨æ–¼æ±ºå®šæ‰€æœ‰è³‡æ–™æºçš„æŠ“å–æ—¥æœŸ/æœˆä»½ç¯„åœ)
TRADING_DAY_CSV_PATH = BASE_DIR / "datas" / "processed" / "get_holidays" / f"trading_day_2021-2025.csv"

# è‚¡ç¥¨æ¸…å–®è·¯å¾‘ (æ–°å¢ï¼Œç”¨æ–¼ STOCK_DAY æŠ“å–)
STOCKS_ALL_CSV_PATH = BASE_DIR / "datas" / "raw" / "stocks_all.csv"

# STOCK_DAY è¼¸å‡ºåŸºæœ¬è·¯å¾‘ (æ–°å¢)
STOCK_DAY_OUTPUT_BASE_DIR = BASE_DIR / "datas" / "raw" / "1_STOCK_DAY"
STOCK_DAY_BASE_URL = "https://www.twse.com.tw/rwd/zh/afterTrading/STOCK_DAY"


# --- æ—¥å ±è¡¨ (æ¯æ—¥æ‘˜è¦) è³‡æ–™æºé…ç½® ---
# æ ¼å¼: (URLåŸºæœ¬è·¯å¾‘, è¼¸å‡ºç›®éŒ„å, æª”æ¡ˆå¾Œç¶´, æ¸…ç†æ¬„ä½å, è¡¨é ­è¡Œç´¢å¼•, é¡å¤–URLåƒæ•¸)
DATA_SOURCES = [
    ("https://www.twse.com.tw/rwd/zh/afterTrading/MI_INDEX", "2_MI_INDEX", "_MI_INDEX_Sector", "æŒ‡æ•¸", 2, "&type=ALLBUT0999"),
    ("https://www.twse.com.tw/rwd/zh/afterTrading/BWIBBU_d", "3_BWIBBU_d", "_BWIBBU_d_IndexReturn", "ç”¢æ¥­åˆ¥", 1, None),
    ("https://www.twse.com.tw/rwd/zh/afterTrading/TWTASU", "5_TWTASU", "_TWTASU_VolumePrice", "é …ç›®", 1, None),
    ("https://www.twse.com.tw/rwd/zh/afterTrading/BFIAMU", "6_BFIAMU", "_BFIAMU_DealerTrade", "è‡ªç‡Ÿå•†", 1, None),
    ("https://www.twse.com.tw/rwd/zh/afterTrading/FMTQIK", "7_FMTQIK", "_FMTQIK_BrokerVolume", "åˆ¸å•†", 1, None),
    ("https://www.twse.com.tw/rwd/zh/fund/BFI82U", "8_BFI82U", "_BFI82U_3IParty_Day", "é …ç›®", 1, None),
    ("https://www.twse.com.tw/rwd/zh/fund/TWT43U", "9_TWT43U", "_TWT43U_ForeignTrade", "å¤–è³‡åŠé™¸è³‡", 1, None),
    ("https://www.twse.com.tw/rwd/zh/fund/TWT44U", "10_TWT44U", "_TWT44U_InvestmentTrust", "æŠ•ä¿¡", 1, None),
    ("https://www.twse.com.tw/rwd/zh/fund/T86", "11_T86", "_T86_InstitutionalTrades", "è­‰åˆ¸ä»£è™Ÿ", 1, "&selectType=ALL"),
]


# ==========================================================
# æ ¸å¿ƒåŸå­åŠŸèƒ½å‡½å¼ (å–®ä¸€è·è²¬)
# ==========================================================

def ensure_output_directory_exists(path: pathlib.Path):
    """
    åŠŸèƒ½: ç¢ºä¿çµ¦å®šçš„ç›®éŒ„è·¯å¾‘å­˜åœ¨ã€‚
    """
    if not path.exists():
        path.mkdir(parents=True, exist_ok=True)
        print(f"âœ… å·²å‰µå»ºè¼¸å‡ºç›®éŒ„: {path}")
        
def get_latest_end_date() -> datetime.date:
    """åŠŸèƒ½: æ ¹æ“šç¾åœ¨æ™‚é–“ (21:00 å‰/å¾Œ) ç¢ºå®šæŠ“å–çš„æˆªæ­¢æ—¥æœŸ (æ˜¨å¤©/ä»Šå¤©)ã€‚"""
    now = datetime.now()
    cutoff_time = datetime.strptime("21:00:00", "%H:%M:%S").time()
    
    if now.time() >= cutoff_time:
        return now.date()
    else:
        return (now - timedelta(days=1)).date()

def fetch_raw_data_from_url(url: str, is_stock_day: bool = False) -> Optional[str]:
    """
    åŠŸèƒ½: å˜—è©¦å¾ TWSE æŠ“å–è³‡æ–™ï¼Œä¸¦è¿”å›åŸå§‹æ–‡æœ¬ã€‚
    """
    try:
        headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, verify=False, timeout=10)
        response.raise_for_status() 
        response.encoding = 'Big5' # TWSE æ•¸æ“šå¤§å¤šä½¿ç”¨ Big5 ç·¨ç¢¼
        
        # æª¢æŸ¥ TWSE å›å‚³å…§å®¹æ˜¯å¦ç‚ºéŒ¯èª¤è¨Šæ¯
        if "å¾ˆæŠ±æ­‰" in response.text or "æŸ¥ç„¡ç›¸é—œè³‡æ–™" in response.text:
            return None
        
        # æ—¥å ±è¡¨å°ˆç”¨æª¢æŸ¥
        if not is_stock_day and "æŸ¥è©¢æ—¥æœŸå¤§æ–¼ä»Šæ—¥" in response.text:
            return None
            
        return response.text
        
    except requests.exceptions.HTTPError:
        # å°æ–¼ STOCK_DAYï¼Œ404/400 ç­‰ä¹Ÿè¦–ç‚ºç„¡è³‡æ–™ï¼Œè¿”å› None å³å¯
        return None
    except requests.exceptions.RequestException:
        # é€£ç·šæˆ– Requests éŒ¯èª¤ï¼Œè¿”å› None
        return None
    except Exception:
        # å…¶ä»–éŒ¯èª¤ï¼Œè¿”å› None
        return None
        
    return None

def parse_twse_raw_csv(response_text: str, header_index: int, cleanup_column: str) -> Optional[pd.DataFrame]:
    """
    åŠŸèƒ½: å°‡ TWSE è¿”å›çš„æ–‡æœ¬è§£æç‚º Pandas DataFrameï¼Œä¸¦åŸ·è¡Œæ¸…ç† (é©ç”¨æ–¼æ—¥å ±è¡¨æ‘˜è¦)ã€‚
    """
    try:
        # ä½¿ç”¨ StringIO æ¨¡æ“¬æª”æ¡ˆè®€å–ï¼Œä¸¦æŒ‡å®šç·¨ç¢¼ç‚º 'utf-8-sig' å…¼å®¹è™•ç†
        data = StringIO(response_text)
        
        df = pd.read_csv(data, 
                         header=header_index, 
                         encoding='utf-8-sig', # åœ¨è§£ææ™‚ä½¿ç”¨ utf-8-sig è™•ç† CSV å…§å®¹
                         skipinitialspace=True,
                         engine='python',
                         on_bad_lines='skip' 
        )
        
        if df.empty:
            return None
        
        df.columns = df.columns.str.strip() 
        df.dropna(axis=1, how='all', inplace=True)
        
        if cleanup_column in df.columns:
            # ç§»é™¤æ¸…ç†æ¬„ä½ç‚ºç©ºçš„è¡Œ
            df = df[df[cleanup_column].astype(str).str.strip() != '']
            
        return df if not df.empty else None 

    except Exception:
        return None

def parse_twse_stock_day_csv(response_text: str, header_row: int = 1) -> Optional[pd.DataFrame]:
    """
    åŠŸèƒ½: å°‡ TWSE è¿”å›çš„ STOCK_DAY æ–‡æœ¬è§£æç‚º Pandas DataFrameï¼Œä¸¦åŸ·è¡Œæ¸…ç†ã€‚
    """
    try:
        data = StringIO(response_text)
        # STOCK_DAY çš„ CSV æ ¼å¼é€šå¸¸è¡¨é ­åœ¨ç´¢å¼• 1
        df = pd.read_csv(data, 
                         header=header_row, 
                         encoding='utf-8-sig', # åœ¨è§£ææ™‚ä½¿ç”¨ utf-8-sig è™•ç† CSV å…§å®¹
                         skipinitialspace=True,
                         engine='python',
                         on_bad_lines='skip' 
        )
        if not df.empty:
            df.columns = df.columns.str.strip() # æ¸…ç†æ¬„ä½åç¨±
            df.dropna(axis=1, how='all', inplace=True) # ç§»é™¤æ‰€æœ‰å…§å®¹ç‚ºç©ºçš„æ¬„ä½
            
            if df.empty:
                return None
            
            # æ¸…ç†ï¼šç§»é™¤æ—¥æœŸç‚ºç©ºçš„è¡Œ (é€šå¸¸æ˜¯å°¾éƒ¨çš„è¨»è§£æˆ–ç©ºè¡Œ)
            if 'æ—¥æœŸ' in df.columns:
                 df = df[df['æ—¥æœŸ'].astype(str).str.strip() != '']
                
            return df if not df.empty else None

        return None

    except Exception:
        return None

def save_dataframe_to_csv(df: pd.DataFrame, file_path: pathlib.Path) -> bool:
    """
    åŠŸèƒ½: å°‡ DataFrame å„²å­˜ç‚º CSV æª”æ¡ˆ (Pathlib)ã€‚
    
    æ³¨æ„: ä¾ç…§ä½¿ç”¨è€…è¦æ±‚ï¼Œå¯«å…¥ç·¨ç¢¼è¨­å®šç‚º 'big5'ã€‚
    """
    try:
        ensure_output_directory_exists(file_path.parent) 
        # ä¾ç…§ä½¿ç”¨è€…è¦æ±‚ï¼Œå¯«å…¥ç·¨ç¢¼ä½¿ç”¨ 'big5'
        df.to_csv(file_path, index=False, encoding='big5') 
        return True
    except Exception as e:
        print(f"âŒ è³‡æ–™å„²å­˜å¤±æ•—: {e}")
        return False

# ==========================================================
# è³‡æ–™æ¸…å–®ç²å–å‡½å¼ (é©ç”¨æ–¼æ‰€æœ‰ä»»å‹™)
# ==========================================================

def get_trading_dates_from_csv(csv_path: pathlib.Path) -> Optional[List[str]]:
    """
    åŠŸèƒ½: è®€å–ã€è™•ç†ã€ç¯©é¸äº¤æ˜“æ—¥æ¸…å–® (å«å¤šç¨®ç·¨ç¢¼å˜—è©¦)ã€‚
    """
    # ä¾ç…§ä½¿ç”¨è€…è¦æ±‚ï¼Œå˜—è©¦å¤šç¨®ç·¨ç¢¼è®€å–
    encodings_to_try = ['utf-8-sig', 'cp950', 'big5', 'utf-8']
    df = None
    
    print(f"--- å˜—è©¦è®€å–æª”æ¡ˆ {csv_path.name} ---")
    
    if not csv_path.exists():
        print(f"éŒ¯èª¤: æ‰¾ä¸åˆ°æª”æ¡ˆ {csv_path}ï¼Œè«‹ç¢ºèªè·¯å¾‘ã€‚")
        return None
        
    for encoding in encodings_to_try:
        try:
            df = pd.read_csv(csv_path, encoding=encoding)
            print(f"ã€æˆåŠŸã€‘æª”æ¡ˆä½¿ç”¨ '{encoding}' ç·¨ç¢¼æˆåŠŸè®€å–ã€‚")
            break 
        except UnicodeDecodeError:
            continue
        except Exception as e:
            print(f"è®€å–æª”æ¡ˆ {csv_path.name} æ™‚ç™¼ç”Ÿéç·¨ç¢¼éŒ¯èª¤: {e}")
            return None 
            
    if df is None or df.empty:
        print(f"éŒ¯èª¤: æª”æ¡ˆ {csv_path.name} ç„¡æ³•ç”¨ä»»ä½•é è¨­ç·¨ç¢¼è®€å–æˆ–å…§å®¹ç‚ºç©ºã€‚")
        return None
        
    try:
        # å‡è¨­æ—¥æœŸåœ¨ç¬¬ä¸€æ¬„
        date_column = df.columns[0]
        df['dt_obj'] = pd.to_datetime(df[date_column].astype(str).str.strip(), errors='coerce')
        df.dropna(subset=['dt_obj'], inplace=True)
        processed_dates = df['dt_obj'].dt.strftime('%Y%m%d').unique().tolist()
        all_dates_list = sorted(processed_dates)
        
        if not all_dates_list:
            print(f"éŒ¯èª¤: æª”æ¡ˆ {csv_path.name} ä¸­æ‰¾ä¸åˆ°ä»»ä½•æœ‰æ•ˆæ—¥æœŸæ•¸æ“šã€‚")
            return None
            
        return all_dates_list
            
    except Exception as e:
        print(f"éŒ¯èª¤: è™•ç†æª”æ¡ˆ {csv_path.name} å…§å®¹æ™‚ç™¼ç”ŸéŒ¯èª¤ (å¦‚æ¬„ä½ç¼ºå¤±): {e}")
        return None

def get_filtered_daily_date_list(all_dates_list: List[str]) -> Optional[List[str]]:
    """
    åŠŸèƒ½: å¾æ‰€æœ‰äº¤æ˜“æ—¥ä¸­ï¼Œç¯©é¸å‡ºç¬¦åˆæŠ“å–æˆªæ­¢æ™‚é–“çš„æ¯æ—¥æ¸…å–®ã€‚
    """
    if not all_dates_list:
        return None
        
    end_date = get_latest_end_date()
    
    print(f"ã€æ™‚é–“åˆ¤æ–·ã€‘æˆªæ­¢æ—¥ç‚º {end_date.strftime('%Y/%m/%d')}ã€‚")

    start_date_str = all_dates_list[0]
    end_date_str = end_date.strftime("%Y%m%d")
    
    filtered_dates = [
        date_str for date_str in all_dates_list 
        if start_date_str <= date_str <= end_date_str
    ]

    if not filtered_dates:
        print(f"è­¦å‘Š: åœ¨ç¯„åœ [{start_date_str} - {end_date_str}] å…§æ‰¾ä¸åˆ°ä»»ä½•æ—¥æœŸã€‚")
        return []
        
    print(f"--- æœ€çµ‚æ¯æ—¥æ—¥æœŸæ¸…å–® (å…± {len(filtered_dates)} å¤©) ---")
    return filtered_dates

def get_month_list_from_start_to_end(all_dates_list: List[str]) -> Optional[List[str]]:
    """
    åŠŸèƒ½: æ ¹æ“šäº¤æ˜“æ—¥æ¸…å–®ï¼Œç”Ÿæˆå¾èµ·å§‹æœˆä»½åˆ°æˆªæ­¢æœˆä»½çš„æ‰€æœ‰æœˆä»½æ¸…å–® (YYYYMMDDï¼Œä»¥è©²æœˆç¬¬ä¸€å¤©è¡¨ç¤º)ã€‚
    """
    if not all_dates_list:
        print("éŒ¯èª¤: äº¤æ˜“æ—¥æ¸…å–®ç‚ºç©ºã€‚")
        return None

    start_date_str = all_dates_list[0]
    end_date = get_latest_end_date()
    
    # è½‰æ›ç‚º datetime object
    start_dt = datetime.strptime(start_date_str, "%Y%m%d")
    end_dt = datetime(end_date.year, end_date.month, end_date.day)

    month_list = []
    current_dt = datetime(start_dt.year, start_dt.month, 1)

    while current_dt <= end_dt:
        # TWSE STOCK_DAY API åªéœ€è¦ YYYYMMDD æ ¼å¼ï¼Œé€šå¸¸é¸æ“‡è©²æœˆçš„ç¬¬ä¸€å¤©ä½œç‚ºä»£è¡¨æ—¥æœŸ
        month_list.append(current_dt.strftime("%Y%m%d")) 
        
        # ç§»å‹•åˆ°ä¸‹å€‹æœˆ
        if current_dt.month == 12:
            current_dt = current_dt.replace(year=current_dt.year + 1, month=1)
        else:
            current_dt = current_dt.replace(month=current_dt.month + 1)

    print(f"--- æœ€çµ‚æœˆä»½æ¸…å–® (å…± {len(month_list)} å€‹æœˆ) ---")
    print(f"èµ·å§‹æœˆä»½: {month_list[0][:6]}, æˆªæ­¢æœˆä»½: {month_list[-1][:6]}")
    return month_list

def get_stock_list(file_path: pathlib.Path) -> Optional[List[str]]:
    """åŠŸèƒ½: å¾ stocks_all.csv è®€å–æ‰€æœ‰è‚¡ç¥¨ä»£è™Ÿã€‚"""
    try:
        # å˜—è©¦ä½¿ç”¨ utf-8-sig è®€å–
        df = pd.read_csv(file_path, encoding='utf-8-sig')
        # å‡è¨­è‚¡ç¥¨ä»£è™Ÿåœ¨ç¬¬ä¸€æ¬„
        stock_list = df.iloc[:, 0].astype(str).str.strip().tolist()
        
        # ç°¡å–®éæ¿¾ï¼šåªä¿ç•™é•·åº¦ç‚º 4~6 çš„æ•¸å­—ä¸²
        filtered_stocks = [s for s in stock_list if re.fullmatch(r'\d{4,6}', s)]
        
        if not filtered_stocks:
            print(f"éŒ¯èª¤: æª”æ¡ˆ {file_path.name} ä¸­æ‰¾ä¸åˆ°ä»»ä½•æœ‰æ•ˆçš„è‚¡ç¥¨ä»£è™Ÿã€‚")
            return None
        
        print(f"--- æˆåŠŸè®€å– {len(filtered_stocks)} å€‹è‚¡ç¥¨ä»£è™Ÿ ---")
        return filtered_stocks
    except FileNotFoundError:
        print(f"éŒ¯èª¤: æ‰¾ä¸åˆ°è‚¡ç¥¨æ¸…å–®æª”æ¡ˆ {file_path}ï¼Œè«‹ç¢ºèªè·¯å¾‘ã€‚")
        return None
    except Exception as e:
        print(f"éŒ¯èª¤: è®€å–æˆ–è™•ç†è‚¡ç¥¨æ¸…å–®æª”æ¡ˆ {file_path.name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

# ==========================================================
# æµç¨‹æ§åˆ¶å‡½å¼ (Orchestrator) - è² è²¬èª¿åº¦å’Œé‡è©¦
# ==========================================================

def orchestrate_daily_summary_tasks(date_list: List[str], stop_event: threading.Event):
    """
    åŠŸèƒ½: è² è²¬è™•ç†æ‰€æœ‰æ¯æ—¥å ±è¡¨æ‘˜è¦çš„æ‰¹æ¬¡æŠ“å–æµç¨‹ã€‚
    """
    print("\n========================================================")
    print("--- é–‹å§‹æ‰¹æ¬¡æŠ“å– TWSE æ¯æ—¥å ±è¡¨æ‘˜è¦ (Daily Summaries) ---")
    print("========================================================\n")
    
    for source in DATA_SOURCES:
        if stop_event.is_set():
            break
            
        base_url, dir_name, file_suffix, cleanup_column, header_index, url_suffix_fragment = source
        
        current_raw_data_dir = BASE_DIR / "datas" / "raw" / dir_name
        ensure_output_directory_exists(current_raw_data_dir)
        
        print(f"\n--- ğŸ”„ æ­£åœ¨è™•ç†è³‡æ–™æº: {dir_name} (å…± {len(date_list)} å¤©) ---")

        for target_date in date_list:
            if stop_event.is_set():
                break
                
            max_attempts = 4
            file_path = current_raw_data_dir / f"{target_date}{file_suffix}.csv"
            
            # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å·²å­˜åœ¨ï¼Œå­˜åœ¨å‰‡è·³é
            if file_path.exists():
                continue 
            
            is_successful = False
            
            for attempt in range(1, max_attempts + 1):
                if stop_event.is_set():
                    break

                # æ§‹å»º URL 
                url_parts = [base_url, "?"]
                url_parts.append(f"date={target_date}")
                if url_suffix_fragment:
                    url_parts.append(url_suffix_fragment)
                url_parts.append("&response=csv") 
                url = "".join(url_parts)
                
                # å‘¼å«åŸå­åŠŸèƒ½å‡½å¼: æŠ“å–åŸå§‹æ–‡æœ¬
                response_text = fetch_raw_data_from_url(url, is_stock_day=False)
                
                df = None
                if response_text is not None:
                    # å‘¼å«åŸå­åŠŸèƒ½å‡½å¼: è§£æç‚º DataFrame
                    df = parse_twse_raw_csv(response_text, header_index, cleanup_column)
                
                if df is not None and not df.empty:
                    # å‘¼å«åŸå­åŠŸèƒ½å‡½å¼: å„²å­˜ CSV
                    if save_dataframe_to_csv(df, file_path):
                        print(f" âœ… {target_date} / {dir_name} è³‡æ–™å·²å®Œæˆã€‚")
                        is_successful = True
                        break 
                elif response_text is None:
                    # ç¶²ç«™è¿”å›ç„¡è³‡æ–™ (å¦‚å‡æ—¥)ï¼Œå¯èƒ½æ˜¯æ­£å¸¸æƒ…æ³ï¼Œé€€å‡ºé‡è©¦
                    break
                
                # å¤±æ•—è™•ç† (åªæœ‰åœ¨æŠ“å–åˆ°æ•¸æ“šä½†è§£æå¤±æ•—ï¼Œæˆ–é€£ç·šæœ‰å•é¡Œæ™‚æ‰é‡è©¦)
                if not is_successful and not stop_event.is_set() and attempt < max_attempts:
                    delay_seconds = attempt * 5 
                    time.sleep(delay_seconds)
                elif not is_successful and not stop_event.is_set() and attempt == max_attempts:
                    print(f"âŒ {target_date} / {dir_name} è³‡æ–™ç¶“é {max_attempts} æ¬¡å˜—è©¦å¾Œä»ç„¶å¤±æ•—ï¼Œè·³éæ­¤æ—¥æœŸã€‚")
                    break
                    
            if not stop_event.is_set():
                time.sleep(2) # æŠ“å–é–“éš”
                
    if stop_event.is_set():
        print("\n*** Daily Summaries ä»»å‹™è¢«ä½¿ç”¨è€…å¼·åˆ¶åœæ­¢ ***")
    else:
        print("\n=== Daily Summaries ä»»å‹™è™•ç†å®Œç•¢ ===")


def fetch_twse_stock_day_single(target_date: str, stock_no: str) -> Optional[pd.DataFrame]:
    """
    åŠŸèƒ½: æŠ“å–æŒ‡å®šæœˆä»½å’Œè‚¡ç¥¨ä»£è™Ÿçš„ STOCK_DAY å ±å‘Šã€‚
    è¡Œç‚ºæ›´æ–°: è‹¥ç¶²è·¯ä¸Šæœ‰è³‡æ–™ï¼Œç›´æ¥å¯«å…¥ä¸¦è¦†è“‹ç•¶æœˆæª”æ¡ˆ (ä¸å†å› æª”æ¡ˆå­˜åœ¨è€Œè·³é)ã€‚
    è¿”å›å€¼:
      - DataFrame: æˆåŠŸæŠ“å–ä¸¦å„²å­˜
      - None: æŠ“å–å¤±æ•—æˆ–ç„¡è³‡æ–™
    """
    # è¼¸å‡ºè·¯å¾‘ (åŒ…å«è‚¡ç¥¨ä»£è™Ÿ)
    output_dir = STOCK_DAY_OUTPUT_BASE_DIR / stock_no
    month_str = target_date[:6]
    filename = output_dir / f"{month_str}_{stock_no}_STOCK_DAY.csv"
    ensure_output_directory_exists(output_dir)

    # æ§‹é€  URL
    url = f"{STOCK_DAY_BASE_URL}?date={target_date}&stockNo={stock_no}&response=csv"

    # 1. æŠ“å–æ•¸æ“š
    response_text = fetch_raw_data_from_url(url, is_stock_day=True)
    if response_text is None:
        # ç„¡æ•¸æ“šæˆ–è«‹æ±‚å¤±æ•—
        return None

    # 2. è§£ææ•¸æ“š
    df = parse_twse_stock_day_csv(response_text, header_row=1)
    if df is None or df.empty:
        # è§£æå¤±æ•—æˆ–è©²æœˆç„¡äº¤æ˜“è³‡æ–™
        return None

    # 3. å„²å­˜è³‡æ–™ï¼ˆè‹¥æª”æ¡ˆå·²å­˜åœ¨ï¼Œpandas æœƒç›´æ¥è¦†å¯«ï¼‰
    saved = save_dataframe_to_csv(df, filename)
    if saved:
        return df
    else:
        return None
    
def orchestrate_stock_day_task(month_list: List[str], stock_list: List[str], stop_event: threading.Event):
    """
    åŠŸèƒ½: è² è²¬è™•ç† TWSE STOCK_DAY (è‚¡ç¥¨æ—¥ç·šåœ–) çš„æ‰¹æ¬¡æŠ“å–æµç¨‹ã€‚
    è¡Œç‚ºæ›´æ–°: æœƒå˜—è©¦æŠ“å–æ¯ä¸€å€‹æœˆçš„è³‡æ–™ï¼Œè‹¥æˆåŠŸæœƒå¯«å…¥ä¸¦è¦†è“‹ç•¶æœˆæª”æ¡ˆï¼›ä¸å†ä»¥ã€Œå·²å­˜åœ¨ã€è·³éã€‚
    """
    print("\n========================================================")
    print("--- é–‹å§‹æ‰¹æ¬¡æŠ“å– TWSE STOCK_DAY (è‚¡ç¥¨æ—¥ç·šåœ–) ---")
    print("========================================================\n")
    
    total_tasks = len(month_list) * len(stock_list)
    tasks_successful = 0
    tasks_overwritten = 0
    tasks_new = 0
    tasks_failed = 0
    
    for stock_no in stock_list:
        if stop_event.is_set():
            break
            
        print(f"\n--- ğŸ”„ é–‹å§‹è™•ç†è‚¡ç¥¨ä»£è™Ÿ: {stock_no} (å…± {len(month_list)} å€‹æœˆ) ---")
        
        for target_date in month_list:
            if stop_event.is_set():
                break
                
            month_str = target_date[:6]
            is_done = False
            
            max_attempts = 4
            for attempt in range(1, max_attempts + 1):
                if stop_event.is_set():
                    break
                    
                df_result = fetch_twse_stock_day_single(target_date, stock_no)
                
                if isinstance(df_result, pd.DataFrame):
                    filename = (STOCK_DAY_OUTPUT_BASE_DIR / stock_no / f"{month_str}_{stock_no}_STOCK_DAY.csv")
                    # åˆ¤æ–·æ˜¯å¦ç‚ºè¦†å¯«é‚„æ˜¯æ–°å»ºï¼ˆæª”æ¡ˆåœ¨å¯«å…¥å‰æ˜¯å¦å­˜åœ¨ï¼‰
                    if filename.exists():
                        print(f" âœ… {stock_no} | {month_str} è³‡æ–™å·²è¦†å¯« (overwrite)ã€‚")
                        tasks_overwritten += 1
                    else:
                        print(f" âœ… {stock_no} | {month_str} è³‡æ–™å„²å­˜æˆåŠŸ (new).")
                        tasks_new += 1
                    tasks_successful += 1
                    is_done = True
                    break
                elif df_result is None:
                    # ç„¡è³‡æ–™æˆ–è«‹æ±‚å¤±æ•—ï¼Œç›´æ¥é€€å‡ºé‡è©¦ (é€šå¸¸è¡¨ç¤ºè©²æœˆç„¡äº¤æ˜“æˆ–é€£ç·šè¢«æ‹’)
                    tasks_failed += 1
                    break 
                
                # å¤±æ•—è™•ç† (åªæœ‰åœ¨é€£ç·šæœ‰å•é¡Œæ™‚æ‰é‡è©¦)
                if not is_done and not stop_event.is_set() and attempt < max_attempts:
                    delay_seconds = attempt * 5 
                    time.sleep(delay_seconds)
                elif not is_done and not stop_event.is_set() and attempt == max_attempts:
                    print(f"âŒ {stock_no} | {month_str} è³‡æ–™ç¶“é {max_attempts} æ¬¡å˜—è©¦å¾Œä»ç„¶å¤±æ•—ï¼Œè·³éæ­¤æœˆä»½ã€‚")
                    tasks_failed += 1
                    break
            
            if not stop_event.is_set():
                time.sleep(2) # æŠ“å–é–“éš”
    
    if stop_event.is_set():
        print("\n*** STOCK_DAY ä»»å‹™è¢«ä½¿ç”¨è€…å¼·åˆ¶åœæ­¢ ***")
    else:
        print("\n--- ğŸ STOCK_DAY æ‰¹æ¬¡æŠ“å–çµæŸ ---")
        print(f"æˆåŠŸå„²å­˜ä»»å‹™æ•¸ (å«è¦†å¯«èˆ‡æ–°å»º): {tasks_successful}")
        print(f"  - è¦†å¯«æª”æ¡ˆæ•¸: {tasks_overwritten}")
        print(f"  - æ–°å»ºæª”æ¡ˆæ•¸: {tasks_new}")
        print(f"å¤±æ•—ä»»å‹™æ•¸: {tasks_failed}")
        print(f"ç¸½ä»»å‹™æ•¸: {total_tasks}")


def orchestrate_main_crawling(stop_event: threading.Event):
    """
    åŠŸèƒ½: å”èª¿æ‰€æœ‰çˆ¬èŸ²ä»»å‹™çš„é ‚å±¤å‡½å¼ã€‚
    """
    
    print("--- ğŸ å•Ÿå‹• TWSE ç¸½çˆ¬èŸ²ä»»å‹™ ---")
    
    # 1. ç²å–æ ¸å¿ƒæ—¥æœŸæ¸…å–® (æ‰€æœ‰ä»»å‹™çš„æ—¥æœŸç¯„åœéƒ½ä»¥æ­¤ç‚ºæº–)
    all_trading_dates = get_trading_dates_from_csv(TRADING_DAY_CSV_PATH)
    if not all_trading_dates:
        print("è‡´å‘½éŒ¯èª¤ï¼šç„¡æ³•å–å¾—äº¤æ˜“æ—¥æ¸…å–®ï¼Œçµ‚æ­¢æ‰€æœ‰çˆ¬èŸ²ä»»å‹™ã€‚")
        return

    # --- åŸ·è¡Œæ¯æ—¥å ±è¡¨æ‘˜è¦ (Daily Summaries) ---
    daily_date_list = get_filtered_daily_date_list(all_trading_dates)
    if daily_date_list:
        orchestrate_daily_summary_tasks(daily_date_list, stop_event)
    
    if stop_event.is_set():
        return

    # --- åŸ·è¡Œè‚¡ç¥¨æ—¥ç·šåœ– (STOCK_DAY) ---
    month_list = get_month_list_from_start_to_end(all_trading_dates)
    stock_list = get_stock_list(STOCKS_ALL_CSV_PATH)
    
    if month_list and stock_list:
        orchestrate_stock_day_task(month_list, stock_list, stop_event)

    print("\n=== ç¸½çˆ¬èŸ²ä»»å‹™æ‰¹æ¬¡è™•ç†å®Œç•¢ ===")


# ==========================================================
# GUI ä»‹é¢è¨­å®š
# ==========================================================

class TextRedirector:
    """åŠŸèƒ½: å°‡ stdout å°å‘ Tkinter çš„ ScrolledText widget"""
    def __init__(self, widget):
        self.widget = widget
        self.widget.tag_configure("stdout", foreground="black")

    def write(self, string):
        self.widget.insert(tk.END, string, "stdout")
        self.widget.see(tk.END)
        self.widget.update_idletasks() 

    def flush(self):
        pass

def _set_start_button_normal(start_btn: tk.Button):
    """GUI è¼”åŠ©: å°‡é–‹å§‹æŒ‰éˆ•è¨­ç‚º NORMAL ç‹€æ…‹"""
    start_btn.config(state=tk.NORMAL, text="é–‹å§‹åŸ·è¡Œ")

def _set_stop_button_disabled(stop_btn: tk.Button):
    """GUI è¼”åŠ©: å°‡åœæ­¢æŒ‰éˆ•è¨­ç‚º DISABLED ç‹€æ…‹"""
    stop_btn.config(state=tk.DISABLED)

def _revert_stop_button_text(button: tk.Button):
    """
    GUI è¼”åŠ©: å°‡åœæ­¢æŒ‰éˆ•çš„æ–‡å­—å¾ 'åœæ­¢ä¸­...' æ¢å¾©ç‚º 'åœæ­¢'ã€‚
    æ­¤å‡½å¼ç”¨æ–¼å¯¦ç¾ 3 ç§’å¾Œæ–‡å­—é‚„åŸã€‚
    """
    button.config(text="åœæ­¢")

def _reset_gui_buttons(start_btn: tk.Button, stop_btn: tk.Button):
    """åŠŸèƒ½: æ›´æ–° GUI æŒ‰éˆ•ç‹€æ…‹ (ç¢ºä¿åœ¨ä¸»åŸ·è¡Œç·’ä¸ŠåŸ·è¡Œ)"""
    root = start_btn.winfo_toplevel()
    root.after(0, _set_start_button_normal, start_btn)
    root.after(0, _set_stop_button_disabled, stop_btn)
    root.after(0, _revert_stop_button_text, stop_btn) # ç¢ºä¿çµæŸæ™‚æ–‡å­—ä¹Ÿæ¢å¾©

# å®šç¾©ä¸€å€‹å…¨åŸŸè®Šæ•¸ä¾†ä¿å­˜æ’ç¨‹ ID
SCHEDULE_JOB_ID = None

def _schedule_next_run(root, start_btn, stop_event, schedule_label_var, on_start_func):
    """
    åŠŸèƒ½: ä»»å‹™çµæŸå¾Œï¼Œå»¶é² 1 ç§’é‡æ–°å•Ÿå‹•æ’ç¨‹ã€‚
    """
    schedule_daily_run(root, start_btn, stop_event, schedule_label_var, on_start_func)

def run_crawling_thread(start_btn: tk.Button, stop_btn: tk.Button, stop_event: threading.Event, on_start_func, schedule_label_var):
    """
    åŠŸèƒ½: ä½œç‚ºåŸ·è¡Œç·’ç›®æ¨™çš„ä¸»é‚è¼¯ï¼Œè² è²¬èª¿åº¦æ‰€æœ‰çˆ¬èŸ²ä»»å‹™ã€‚
    """
    
    # åŸ·è¡Œä¸»æµç¨‹æ§åˆ¶
    orchestrate_main_crawling(stop_event)
    
    # é‡ç½® GUI ç‹€æ…‹
    _reset_gui_buttons(start_btn, stop_btn)
    
    # ä»»å‹™çµæŸå¾Œï¼Œé‡æ–°å•Ÿå‹•æ’ç¨‹
    root = start_btn.winfo_toplevel()
    root.after(1000, _schedule_next_run, root, start_btn, stop_event, schedule_label_var, on_start_func) 


def _reschedule_next_day(root, btn_start, stop_event, schedule_label, on_start_func):
    """
    åŠŸèƒ½: æ’ç¨‹å‹•ä½œçµæŸå¾Œï¼Œé‡æ–°è¨­å®šä¸‹ä¸€å¤©çš„æ’ç¨‹ã€‚
    """
    schedule_daily_run(root, btn_start, stop_event, schedule_label, on_start_func)


def schedule_daily_run(root, btn_start, stop_event, schedule_label, on_start_func):
    """
    åŠŸèƒ½: è¨ˆç®—ä¸¦è¨­å®šä¸‹ä¸€æ¬¡æ¯æ—¥ 21:00 åŸ·è¡Œçˆ¬èŸ²çš„æ™‚é–“ã€‚
    """
    global SCHEDULE_JOB_ID
    
    if SCHEDULE_JOB_ID:
        try:
            root.after_cancel(SCHEDULE_JOB_ID)
        except:
            pass 
            
    TARGET_HOUR = 21
    TARGET_MINUTE = 0
    TARGET_SECOND = 0
    
    now = datetime.now()
    target_time_today = now.replace(hour=TARGET_HOUR, minute=TARGET_MINUTE, second=TARGET_SECOND, microsecond=0)
    
    if now > target_time_today:
        next_run = target_time_today + timedelta(days=1)
    else:
        next_run = target_time_today
        
    delay_seconds = (next_run - now).total_seconds()
    delay_ms = max(1000, int(delay_seconds * 1000))

    schedule_label.set(f"ä¸‹æ¬¡æ’ç¨‹åŸ·è¡Œæ™‚é–“: {next_run.strftime('%Y/%m/%d %H:%M:%S')} (æ‰‹å‹•é»æ“Šå¯ç«‹å³åŸ·è¡Œ)")
    print(f"\n[ç³»çµ±è¨Šæ¯] ä¸‹æ¬¡æ’ç¨‹æŠ“å–æ™‚é–“å·²è¨­å®šç‚º: {next_run.strftime('%Y/%m/%d %H:%M:%S')}")

    def scheduled_action():
        """æ’ç¨‹è§¸ç™¼æ™‚åŸ·è¡Œçš„å‹•ä½œ (å®šç¾©åœ¨å…§éƒ¨ä»¥æ–¹ä¾¿å­˜å–é–‰åŒ…è®Šæ•¸)"""
        global SCHEDULE_JOB_ID
        SCHEDULE_JOB_ID = None 
        
        if btn_start['state'] == tk.NORMAL:
            print("\n[ç³»çµ±è¨Šæ¯] ğŸš¨ æ’ç¨‹æ™‚é–“åˆ°é” (21:00)ï¼Œè‡ªå‹•é–‹å§‹æŠ“å–ä»»å‹™...")
            # å‘¼å«å‚³å…¥çš„ on_start å‡½å¼å¼•ç”¨
            on_start_func()
        else:
            print("\n[ç³»çµ±è¨Šæ¯] ğŸš¨ æ’ç¨‹æ™‚é–“åˆ°é”ï¼Œä½†å› ä»»å‹™æ­£åœ¨åŸ·è¡Œï¼Œæ•…è·³éæœ¬æ¬¡è‡ªå‹•å•Ÿå‹•ã€‚")
            
        # ç„¡è«–æ˜¯å¦å•Ÿå‹•ï¼Œéƒ½å¿…é ˆé‡æ–°æ’ç¨‹ä¸‹ä¸€è¼ªé‹è¡Œ
        if btn_start['state'] == tk.NORMAL:
              root.after(1000, _reschedule_next_day, root, btn_start, stop_event, schedule_label, on_start_func)

    SCHEDULE_JOB_ID = root.after(delay_ms, scheduled_action)


def run_gui():
    """åŠŸèƒ½: å•Ÿå‹• Tkinter GUI æ‡‰ç”¨ç¨‹å¼ã€‚"""
    
    root = tk.Tk()
    root.title("Python TWSE å¤šæºçˆ¬èŸ² (æ•´åˆ STOCK_DAY) - å›ºå®šæ¯æ—¥ 21:00 æ’ç¨‹æŠ“å–")
    
    # --- è¦–çª—å±…ä¸­è¨ˆç®— ---
    window_width = 800
    window_height = 600
    screen_width = root.winfo_screenwidth()
    screen_height = root.winfo_screenheight()
    center_x = int((screen_width / 2) - (window_width / 2))
    center_y = int((screen_height / 2) - (window_height / 2))
    root.geometry(f'{window_width}x{window_height}+{center_x}+{center_y}')
    # --- è¦–çª—å±…ä¸­è¨ˆç®—çµæŸ ---


    # æ–‡å­—è¼¸å‡ºå€
    scrolled_text = scrolledtext.ScrolledText(root, width=80, height=20, font=("Consolas", 10))
    scrolled_text.pack(padx=10, pady=10, expand=True, fill='both')

    # é‡å°å‘ stdout
    sys.stdout = TextRedirector(scrolled_text)
    
    # æ’ç¨‹ç‹€æ…‹é¡¯ç¤º
    schedule_status = tk.StringVar()
    schedule_label = tk.Label(root, textvariable=schedule_status, fg="#2E86C1", font=("Arial", 10, "bold"))
    schedule_label.pack(pady=(0, 5)) 

    # æ§åˆ¶å€
    btn_frame = tk.Frame(root)
    btn_frame.pack(pady=10)

    # åœæ­¢äº‹ä»¶
    stop_event = threading.Event()
    
    # é å…ˆå®£å‘ŠæŒ‰éˆ• 
    btn_start = None
    btn_stop = None

    def on_exit():
        """åŠŸèƒ½: è™•ç†æ‡‰ç”¨ç¨‹å¼é—œé–‰ã€‚"""
        # 1. è¨­ç½®åœæ­¢äº‹ä»¶ï¼Œé€šçŸ¥çˆ¬èŸ²åŸ·è¡Œç·’åœæ­¢
        stop_event.set()
        # 2. å–æ¶ˆæ’ç¨‹
        global SCHEDULE_JOB_ID
        if SCHEDULE_JOB_ID:
            try:
                root.after_cancel(SCHEDULE_JOB_ID)
            except Exception:
                pass
        # 3. é—œé–‰è¦–çª—
        root.destroy()
        
    def on_start():
        """åŠŸèƒ½: æ‰‹å‹•å•Ÿå‹•çˆ¬èŸ²ä»»å‹™ (å®šç¾©åœ¨å…§éƒ¨ä»¥å­˜å–æŒ‰éˆ•è®Šæ•¸)"""
        global SCHEDULE_JOB_ID
        
        if SCHEDULE_JOB_ID:
            try:
                # å–æ¶ˆç•¶å‰æ’ç¨‹ï¼Œå› ç‚ºæ‰‹å‹•å•Ÿå‹•å¾Œæœƒé‡æ–°è¨­å®šä¸‹ä¸€æ¬¡æ’ç¨‹
                root.after_cancel(SCHEDULE_JOB_ID)
                SCHEDULE_JOB_ID = None
                print("\n[ç³»çµ±è¨Šæ¯] æ‰‹å‹•å•Ÿå‹•ï¼Œå·²å–æ¶ˆç•¶å‰æ’ç¨‹ã€‚")
            except:
                pass 
                
        stop_event.clear()
        btn_start.config(state=tk.DISABLED, text="åŸ·è¡Œä¸­...")
        btn_stop.config(state=tk.NORMAL, text="åœæ­¢") # ç¢ºä¿å•Ÿå‹•æ™‚æ–‡å­—æ˜¯ã€Œåœæ­¢ã€
        
        # å•Ÿå‹•åŸ·è¡Œç·’ä¾†åŸ·è¡Œçˆ¬èŸ²é‚è¼¯ (å‚³é on_start å‡½å¼å¼•ç”¨ï¼Œå› ç‚ºå®ƒæ˜¯æ ¸å¿ƒå•Ÿå‹•é‚è¼¯)
        t = threading.Thread(target=run_crawling_thread, args=(btn_start, btn_stop, stop_event, on_start, schedule_status))
        t.daemon = True
        t.start()

    def on_stop():
        """åŠŸèƒ½: æ‰‹å‹•åœæ­¢çˆ¬èŸ²ä»»å‹™"""
        stop_event.set()
        # ç«‹å³ç¦ç”¨æŒ‰éˆ•ä¸¦æ›´æ”¹æ–‡å­—
        btn_stop.config(state=tk.DISABLED, text="åœæ­¢ä¸­...")
        
        # 3 ç§’å¾Œå°‡æ–‡å­—é‚„åŸå›ã€Œåœæ­¢ã€
        root.after(3000, _revert_stop_button_text, btn_stop)


    btn_start = tk.Button(btn_frame, text="é–‹å§‹åŸ·è¡Œ", command=on_start, 
                         bg="#4CAF50", fg="white", font=("Arial", 12, "bold"), padx=15)
    btn_start.pack(side=tk.LEFT, padx=10)

    btn_stop = tk.Button(btn_frame, text="åœæ­¢", command=on_stop, 
                         bg="#F44336", fg="white", font=("Arial", 12, "bold"), padx=15, state=tk.DISABLED)
    btn_stop.pack(side=tk.LEFT, padx=10)
    
    btn_exit = tk.Button(btn_frame, text="é›¢é–‹ç¨‹å¼", command=on_exit,
                         bg="#607D8B", fg="white", font=("Arial", 12, "bold"), padx=15)
    btn_exit.pack(side=tk.LEFT, padx=10)
    
    # é¦–æ¬¡å•Ÿå‹•æ’ç¨‹
    # å‚³å…¥ on_start å‡½å¼å¼•ç”¨ï¼Œè®“æ’ç¨‹å™¨èƒ½åœ¨æ™‚é–“åˆ°é”æ™‚è§¸ç™¼å®ƒ
    schedule_daily_run(root, btn_start, stop_event, schedule_status, on_start)


    # é¡¯ç¤ºæ‰€æœ‰è³‡æ–™çš„é è¨ˆå­˜å„²çˆ¶ç›®éŒ„
    initial_dir = BASE_DIR / "datas" / "raw"
    print(f"ç³»çµ±æº–å‚™å°±ç·’ã€‚")
    print(f"äº¤æ˜“æ—¥æ¸…å–®è·¯å¾‘: {TRADING_DAY_CSV_PATH}")
    print(f"è‚¡ç¥¨æ¸…å–®è·¯å¾‘: {STOCKS_ALL_CSV_PATH}")
    print(f"æ‰€æœ‰æ—¥å ±è¡¨æ‘˜è¦å°‡å­˜æ–¼å­ç›®éŒ„ä¸‹: {initial_dir} (2_MI_INDEX ~ 11_T86)")
    print(f"æ‰€æœ‰è‚¡ç¥¨æ—¥ç·šåœ–å°‡å­˜æ–¼å­ç›®éŒ„ä¸‹: {STOCK_DAY_OUTPUT_BASE_DIR} / {{è‚¡ç¥¨ä»£è™Ÿ}}")

    root.protocol("WM_DELETE_WINDOW", on_exit) 
    
    root.mainloop()

if __name__ == '__main__':
    # ç¢ºä¿ä¸»è¼¸å‡ºç›®éŒ„å­˜åœ¨
    ensure_output_directory_exists(BASE_DIR / "datas" / "raw") 
    run_gui()