import time as time_module # ç”¨æ–¼ sleep() æˆ– time()
import os, pandas, requests
import pathlib     # as pathlib
from typing import Optional, Tuple, List, Union, Dict, Any
from io import StringIO
import pandas as pd # ç”¨æ–¼è³‡æ–™è™•ç†èˆ‡åˆ†æ
from datetime import date, datetime, timedelta, time as time_TimeClass


CODE_DIR = os.path.dirname(os.path.abspath(__file__))

def _fetch_twse_data(url: str) -> Optional[str]:
    """å˜—è©¦å¾ TWSE æŠ“å–è³‡æ–™ï¼Œä¸¦è¿”å›åŸå§‹æ–‡æœ¬ã€‚"""
    try:
        headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, verify=False, timeout=10)
        response.raise_for_status() 
        response.encoding = 'Big5'
        
        if "å¾ˆæŠ±æ­‰" in response.text or "æŸ¥ç„¡ç›¸é—œè³‡æ–™" in response.text:
            return None
        
        return response.text
        
    except requests.exceptions.HTTPError:
        return None 
    except requests.exceptions.RequestException as err:
        print(f"âŒ é€£ç·šæˆ– Requests éŒ¯èª¤: {err}")
    except Exception as e:
        print(f"âŒ ç™¼ç”Ÿå…¶ä»–éŒ¯èª¤: {e}")
        
    return None

# å…±ç”¨çš„è¼”åŠ©å‡½å¼ï¼Œç”¨æ–¼è™•ç† TWSE çš„ Big5 ç·¨ç¢¼å’Œ Pandas è®€å–é‚è¼¯ã€‚
def _read_twse_csv(response_text: str, header_row: int) -> Optional[pd.DataFrame]:
    """
    Args:
        response_text: HTTP è«‹æ±‚å›å‚³çš„æ–‡å­—å…§å®¹ (Big5 ç·¨ç¢¼)ã€‚
        header_row: CSV æª”æ¡ˆä¸­è³‡æ–™è¡¨é ­æ‰€åœ¨çš„è¡Œæ•¸ (0-indexed)ã€‚
    Returns:
        Optional[pd.DataFrame]: è™•ç†å¾Œçš„ DataFrameã€‚
    """
    try:
        csv_data = StringIO(response_text)
        # å˜—è©¦è®€å– CSV
        df = pd.read_csv(
            csv_data, 
            header=header_row,          # è³‡æ–™è¡¨é ­æ‰€åœ¨çš„è¡Œæ•¸
            skipinitialspace=True,      # è·³éåˆ†éš”ç¬¦å¾Œçš„ç©ºæ ¼
            on_bad_lines='skip',        # è·³éæ ¼å¼ä¸æ­£ç¢ºçš„è¡Œ
            encoding='Big5'             # ä½¿ç”¨ Big5 ç·¨ç¢¼è®€å–
        )
        # TWSE çš„ CSV æ¬„ä½åç¨±å¸¸æœ‰éš±è—ç©ºæ ¼ï¼Œå°è‡´ df.columns ç„¡æ³•æ­£ç¢ºåŒ¹é…ã€‚
        if not df.empty:
            df.columns = df.columns.str.strip()
        # ç§»é™¤æ‰€æœ‰æ¬„ä½çš†ç‚ºç©ºçš„è¡Œ
        df = df.dropna(how='all')
        # ç§»é™¤è³‡æ–™å°¾éƒ¨å¯èƒ½å‡ºç¾çš„å½™ç¸½æˆ–å‚™è¨»è¡Œ
        if not df.empty and df.iloc[-1].astype(str).str.contains('åˆè¨ˆ|ç¸½è¨ˆ|å‚™è¨»', na=False).any():
            df = df.iloc[:-1]
        return df
    except Exception as e:
        print(f"åœ¨è®€å–æˆ–æ¸…ç† CSV æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

        return None
    
# æŠ“å–ç•¶æœˆæ‰€æœ‰è‚¡ç¥¨çš„ STOCK_DAY è³‡æ–™ï¼Œä¸¦ç›´æ¥è¦†è“‹æª”æ¡ˆã€‚
def fetch_twse_stock_day_single_month(month_date: str, stock_list: List[str]):

    print(f"\n--- ğŸš€ é–‹å§‹ STOCK_DAY æŠ“å– ({month_date[:6]}) (å°‡ç›´æ¥è¦†è“‹) ---")
    
    OUTPUT_BASE_DIR = os.path.join(CODE_DIR, "datas", "raw", "1_STOCK_DAY")
    BASE_URL = "https://www.twse.com.tw/rwd/zh/afterTrading/STOCK_DAY"
    
    tasks_successful = 0
    tasks_failed = 0
    
    for stock_no in stock_list:
        output_dir = os.path.join(OUTPUT_BASE_DIR, stock_no)
        month_str = month_date[:6]
        filename = os.path.join(output_dir, f"{month_str}_{stock_no}_STOCK_DAY.csv") 
        pathlib.Path(filename).parent.mkdir(parents=True, exist_ok=True)
        is_successful = False
        max_attempts = 4
        for attempt in range(1, max_attempts + 1):
            
            url = f"{BASE_URL}?date={month_date}&stockNo={stock_no}&response=csv"
            
            # 1. æŠ“å–æ•¸æ“š
            response_text = _fetch_twse_data(url)
            df = None
            if response_text is not None:
                df = _read_twse_csv(response_text, header_row=1, first_col_name='æ—¥æœŸ') 
            
            if df is not None and not df.empty:
                # 2. å„²å­˜è³‡æ–™ (ç›´æ¥è¦†è“‹)
                try:
                    df.to_csv(filename, index=False, encoding='big5')
                    print(f" Â âœ… {stock_no} | {month_str} è³‡æ–™å·²è¦†è“‹å„²å­˜ã€‚")
                    tasks_successful += 1
                    is_successful = True
                    break
                except Exception as e:
                    print(f"âŒ {stock_no} | {month_str} è³‡æ–™å„²å­˜å¤±æ•—: {e}")
                    tasks_failed += 1
                    break
            
            # æŠ“å–å¤±æ•— (df is None)
            if attempt < max_attempts:
                delay_seconds = attempt * 5 
                print(f"ğŸš¨ {stock_no} | {month_str} æŠ“å–å¤±æ•—ã€‚å°‡åœ¨ {delay_seconds} ç§’å¾Œé‡è©¦...")
                time_module.sleep(delay_seconds)
            else:
                print(f"âŒ {stock_no} | {month_str} è³‡æ–™ç¶“é {max_attempts} æ¬¡å˜—è©¦å¾Œä»ç„¶å¤±æ•—ï¼Œè·³éæ­¤è‚¡ç¥¨ã€‚")
                tasks_failed += 1
                break
                
        # 3. æ¯æ¬¡å˜—è©¦ç¶²è·¯è«‹æ±‚å¾Œï¼Œç­‰å¾… 2 ç§’ (ç„¡è«–æˆåŠŸæˆ–å¤±æ•—)
        if is_successful or attempt == max_attempts:
            time_module.sleep(2)
            
    print(f"\n--- ğŸ STOCK_DAY æŠ“å–çµæŸã€‚æˆåŠŸè¦†è“‹: {tasks_successful}, å¤±æ•—: {tasks_failed} ---")
# ==========================================================

# å¾ stocks_all.csv è®€å–è‚¡ç¥¨æ¸…å–®ï¼Œä¸¦ä¾æ“šã€å¸‚å ´åˆ¥ã€‘æ¬„ä½ç¯©é¸å‡ºã€Œä¸Šå¸‚ã€å…¬å¸ã€‚
def get_stock_list(file_path: str) -> Optional[List[str]]:

    try:
        # è®€å–æ•´å€‹ CSV æª”æ¡ˆ
        df = pd.read_csv(file_path, encoding='big5')
        
        # 1. å°‹æ‰¾ã€å¸‚å ´åˆ¥ã€‘æ¬„ä½
        # å˜—è©¦å¾æ¬„ä½åç¨±ä¸­æ‰¾å‡ºåŒ…å« "å¸‚å ´åˆ¥"ã€"é¡åˆ¥" æˆ– "å¸‚å ´" çš„æ¬„ä½
        market_col = None
        for col in df.columns:
            if "å¸‚å ´åˆ¥" in col or "å¸‚å ´" in col or "é¡åˆ¥" in col:
                market_col = col
                break
        
        if market_col is None:
            # è­¦å‘Šï¼šå¦‚æœæ‰¾ä¸åˆ°å¸‚å ´åˆ¥æ¬„ä½ï¼Œå‰‡é€€å›åˆ°åªæŠ“å– 4 ä½æ•¸å­—çš„ä»£è™Ÿï¼ˆé¿å…æŠ“å–å…¨éƒ¨ï¼‰
            print("è­¦å‘Šï¼šæ‰¾ä¸åˆ°åŒ…å« 'å¸‚å ´åˆ¥' æˆ– 'å¸‚å ´' å­—æ¨£çš„æ¬„ä½ï¼Œå°‡é€€å›åƒ…ç¯©é¸ 4 ä½æ•¸å­—ä»£è™Ÿã€‚")
            
            stock_list = df.iloc[:, 0].astype(str).str.strip().tolist()
            filtered_stocks = [
                s for s in stock_list 
                if re.fullmatch(r'^\d{4}$', s)
            ]
            
        else:
            # 2. æ‰¾åˆ°å¸‚å ´åˆ¥æ¬„ä½ï¼Œé€²è¡Œç¯©é¸
            
            # æ¸…ç†å¸‚å ´åˆ¥æ¬„ä½çš„å­—ä¸²ï¼Œä¸¦ç¯©é¸å‡ºåŒ…å«ã€Œä¸Šå¸‚ã€å­—æ¨£çš„è¡Œ
            df_listed = df[
                df[market_col].astype(str).str.strip().str.contains("ä¸Šå¸‚", na=False)
            ].copy() # ä½¿ç”¨ copy é¿å… SettingWithCopyWarning
            
            # 3. å–å¾—ç¬¬ä¸€æ¬„çš„è‚¡ç¥¨ä»£è™Ÿ
            # å‡è¨­è‚¡ç¥¨ä»£è™Ÿæ˜¯ç¬¬ä¸€æ¬„ (ç´¢å¼• 0)
            stock_list = df_listed.iloc[:, 0].astype(str).str.strip().tolist()
            
            # é¡å¤–æª¢æŸ¥ï¼šç¢ºä¿ä»£è™Ÿæ˜¯æœ‰æ•ˆçš„æ•¸å­—æ ¼å¼ï¼ˆé€šå¸¸æ˜¯ 4 ä½ç´”æ•¸å­—ï¼‰
            filtered_stocks = [s for s in stock_list if re.fullmatch(r'\d{4,6}', s)]
            
        
        if not filtered_stocks:
            print("éŒ¯èª¤: ä¾æ“šã€Œå¸‚å ´åˆ¥ã€ç¯©é¸å¾Œï¼Œæ‰¾ä¸åˆ°ä»»ä½•ç¬¦åˆæ¢ä»¶çš„ä¸Šå¸‚å…¬å¸ä»£è™Ÿã€‚")
            return None
            
        print(f"--- æˆåŠŸä¾æ“šã€Œå¸‚å ´åˆ¥ã€ç¯©é¸ï¼Œè®€å– {len(filtered_stocks)} å€‹ä¸Šå¸‚å…¬å¸ä»£è™Ÿ ---")
        print(filtered_stocks)
        return filtered_stocks
    except pd.errors.EmptyDataError:
        print(f"éŒ¯èª¤: è‚¡ç¥¨æ¸…å–®æª”æ¡ˆ {file_path} ç‚ºç©ºã€‚")
        return None
    except Exception as e:
        print(f"éŒ¯èª¤: è®€å–æˆ–è™•ç†è‚¡ç¥¨æ¸…å–®æª”æ¡ˆ {file_path} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

# --- é€šç”¨æ—¥å ±æŠ“å–ä¸»å‡½æ•¸ (åƒ…æŠ“å–ç•¶æ—¥) ---
def fetch_single_daily_report(
    target_date: str, 
    base_url: str, 
    output_folder_num: str,
    output_filename_suffix: str,
    url_params: str = "",
    first_col_name: Optional[str] = None,
    header_row: int = 1
):
    """
    æŠ“å–å–®æ—¥å ±è¡¨æ•¸æ“šçš„é€šç”¨å‡½æ•¸ï¼Œå…·å‚™æª”æ¡ˆå­˜åœ¨å³è·³éçš„æ©Ÿåˆ¶ã€‚
    """
    
    OUTPUT_DIR = os.path.join(CODE_DIR, "datas", "raw", output_folder_num)
    filename = os.path.join(OUTPUT_DIR, f"{target_date}{output_filename_suffix}.csv")
    pathlib.Path(filename).parent.mkdir(parents=True, exist_ok=True)

    print(f"\n--- ğŸš€ è™•ç† {output_folder_num} ({target_date}) ---")

    # 1. æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å·²å­˜åœ¨
    if os.path.exists(filename):
        print(f" Â â„¹ï¸ {target_date} è³‡æ–™å·²å­˜åœ¨ï¼Œè·³éã€‚")
        return # è·³éï¼Œä¸åŸ·è¡Œå»¶é²

    # 2. æª”æ¡ˆä¸å­˜åœ¨ï¼Œé–‹å§‹åŸ·è¡ŒæŠ“å–å’Œé‡è©¦
    is_successful = False
    max_attempts = 4
    for attempt in range(1, max_attempts + 1):
        
        url = f"{base_url}?date={target_date}{url_params}&response=csv"
        
        # åŸ·è¡ŒæŠ“å–
        response_text = _fetch_twse_data(url)
        df = None
        if response_text is not None:
            df = _read_twse_csv(response_text, header_row=header_row, first_col_name=first_col_name)

        if df is not None:
            # æˆåŠŸå„²å­˜
            try:
                df.to_csv(filename, index=False, encoding='big5')
                print(f" Â âœ… {target_date} è³‡æ–™å„²å­˜æˆåŠŸã€‚")
                is_successful = True
                break
            except Exception as e:
                print(f"âŒ {target_date} è³‡æ–™å„²å­˜å¤±æ•—: {e}")
                break

        # å¤±æ•—è™•ç†
        if attempt < max_attempts:
            delay_seconds = attempt * 5 
            print(f"ğŸš¨ æŠ“å–å¤±æ•— (ç¬¬ {attempt} æ¬¡)ã€‚å°‡åœ¨ {delay_seconds} ç§’å¾Œé‡è©¦...")
            time_module.sleep(delay_seconds)
        else:
            print(f"âŒ {target_date} è³‡æ–™ç¶“é {max_attempts} æ¬¡å˜—è©¦å¾Œä»ç„¶å¤±æ•—ã€‚")
            break
    
    # 3. åªæœ‰åœ¨é€²è¡Œäº†ç¶²è·¯æŠ“å–æˆ–é‡è©¦ä¹‹å¾Œï¼Œæ‰éœ€è¦ç­‰å¾… 2 ç§’
    if is_successful or attempt == max_attempts:
        time_module.sleep(2)
        
def fetch_all_twse_reports(daily_date: str, monthly_date: str, stock_list: list):
    """
    åŸ·è¡Œæ‰€æœ‰ TWSE æ—¥å ±å’Œæœˆå ±çš„è³‡æ–™æŠ“å–ä»»å‹™ã€‚
    """
    print("="*50 + "\n--- ç¨‹å¼é–‹å§‹åŸ·è¡Œï¼šTWSE å ±å‘Šè³‡æ–™æŠ“å– ---")
    
    if daily_date is None:
        print("âš ï¸ ç”±æ–¼ç„¡æ³•ç¢ºå®šç›®æ¨™äº¤æ˜“æ—¥ï¼Œæ—¥å ±ä»»å‹™å·²è·³éã€‚")
    else:
        print(f"--- A. è™•ç†å–®æ—¥å ±è¡¨ ({daily_date}) ---")
        
        # å®šç¾©æ‰€æœ‰æ—¥å ±ä»»å‹™çš„æ¸…å–®
        # çµæ§‹: (url, file_prefix, folder_suffix, first_col, header_row, url_params)
        DAILY_REPORTS = [
            ("https://www.twse.com.tw/rwd/zh/afterTrading/MI_INDEX", "2_MI_INDEX", "_MI_INDEX_Sector", "é …ç›®", 2, None),
            ("https://www.twse.com.tw/rwd/zh/afterTrading/BWIBBU_d", "3_BWIBBU_d", "_BWIBBU_d_IndexReturn", "ç”¢æ¥­åˆ¥", 1, None),
            ("https://www.twse.com.tw/rwd/zh/afterTrading/TWTASU", "5_TWTASU", "_TWTASU_VolumePrice", "é …ç›®", 1, None),
            ("https://www.twse.com.tw/rwd/zh/afterTrading/BFIAMU", "6_BFIAMU", "_BFIAMU_DealerTrade", "è‡ªç‡Ÿå•†", 1, None),
            ("https://www.twse.com.tw/rwd/zh/afterTrading/FMTQIK", "7_FMTQIK", "_FMTQIK_BrokerVolume", "åˆ¸å•†", 1, None),
            ("https://www.twse.com.tw/rwd/zh/fund/BFI82U", "8_BFI82U", "_BFI82U_3IParty_Day", "é …ç›®", 1, "&type=day&dayDate"),
            ("https://www.twse.com.tw/rwd/zh/fund/TWT43U", "9_TWT43U", "_TWT43U_ForeignTrade", "å¤–è³‡åŠé™¸è³‡", 1, None),
            ("https://www.twse.com.tw/rwd/zh/fund/TWT44U", "10_TWT44U", "_TWT44U_InvestmentTrust", "æŠ•ä¿¡", 1, None),
            ("https://www.twse.com.tw/rwd/zh/fund/T86", "11_T86", "_T86_InstitutionalTrades", "è­‰åˆ¸ä»£è™Ÿ", 1, "&selectType=ALL"),
            # TWT92U èè³‡èåˆ¸ (å¦‚æœéœ€è¦å†å•Ÿç”¨)
            # ("https://www.twse.com.tw/rwd/zh/marginTrading/TWT92U", "4_TWT92U", "_TWT92U_Margin", "è‚¡ç¥¨ä»£è™Ÿ", 1, None),
        ]
        
        for url, prefix, suffix, first_col, header_row, url_params in DAILY_REPORTS:
            fetch_single_daily_report(
                daily_date, url, prefix, suffix, 
                first_col_name=first_col, 
                header_row=header_row, 
                url_params=url_params
            )
            time_module.sleep(1) # å¢åŠ é–“éš”ï¼Œé¿å…è¢«é–

    # --- è™•ç† STOCK_DAY (æœˆå ±) ---
    if stock_list and monthly_date:
        print(f"--- B. è™•ç† STOCK_DAY (ä»»å‹™ 1 - {monthly_date} è¦†è“‹) ---")
        fetch_twse_stock_day_single_month(monthly_date, stock_list)
    elif not stock_list:
        print("è­¦å‘Šï¼šç„¡æ³•å–å¾—è‚¡ç¥¨æ¸…å–® (stocks_all.csv)ï¼Œè·³é STOCK_DAY æŠ“å–ã€‚")
    elif not monthly_date:
        print("è­¦å‘Šï¼šç„¡æ³•å–å¾—ç›®æ¨™æœˆä»½ï¼Œè·³é STOCK_DAY æŠ“å–ã€‚")

    print("\n======================================")
    print("âœ… TWSE æ•¸æ“šæŠ“å–ä»»å‹™å·²å®Œæˆã€‚")
    print("======================================")

