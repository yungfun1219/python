import pathlib     # as pathlib
from typing import Optional, Tuple, List, Union, Dict, Any
import pandas as pd # ç”¨æ–¼è³‡æ–™è™•ç†èˆ‡åˆ†æ
from datetime import date, datetime, timedelta, time as time_TimeClass
from dotenv import load_dotenv # âŠ åŒ¯å…¥å‡½å¼åº«

# å¾ Excel æª”æ¡ˆä¸­è®€å–è‚¡ç¥¨åº«å­˜ï¼Œå°‡å…¶å¦å­˜ç‚º CSV æª”æ¡ˆã€‚
def extract_excel_sheet_filter_and_save(excel_file_path: str, sheet_name: str, filter_column: str, filter_value: any, output_dir: str = None) -> pathlib.Path:
    """
    å¾æŒ‡å®šçš„ Excel æª”æ¡ˆä¸­è®€å–ç‰¹å®šå·¥ä½œè¡¨ï¼Œè·³éç¬¬äºŒè¡Œï¼Œç¯©é¸è³‡æ–™å¾Œï¼Œå°‡å…¶å¦å­˜ç‚º CSV æª”æ¡ˆã€‚

    Args:
        excel_file_path (str): åŸå§‹ Excel æª”æ¡ˆçš„å®Œæ•´è·¯å¾‘ã€‚
        sheet_name (str): è¦è®€å–çš„å·¥ä½œè¡¨åç¨± (ä¾‹å¦‚: 'è‚¡ç¥¨åº«å­˜çµ±è¨ˆ')ã€‚
        filter_column (str): è¦é€²è¡Œç¯©é¸çš„æ¬„ä½åç¨± (ä¾‹å¦‚: 'ç›®å‰è‚¡æ•¸åº«å­˜çµ±è¨ˆ')ã€‚
        filter_value (any): è¦ç¯©é™¤çš„å€¼ã€‚
        output_dir (str, optional): CSV æª”æ¡ˆçš„å„²å­˜ç›®éŒ„ã€‚å¦‚æœç‚º Noneï¼Œå‰‡å„²å­˜åœ¨åŸå§‹æª”æ¡ˆçš„ç›®éŒ„ã€‚

    Returns:
        Path: å„²å­˜æˆåŠŸçš„ CSV æª”æ¡ˆè·¯å¾‘ã€‚
    """
    
    original_path = pathlib.Path(excel_file_path)
    
    if not original_path.exists():
        raise FileNotFoundError(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° Excel æª”æ¡ˆåœ¨è·¯å¾‘ï¼š{excel_file_path}")

    print(f"âœ… æ­£åœ¨è®€å– Excel æª”æ¡ˆï¼š{original_path.name}")
    print(f"ğŸ¯ ç›®æ¨™å·¥ä½œè¡¨åç¨±ï¼š{sheet_name}")

    try:
        # 1. è®€å– Excel ä¸­æŒ‡å®šå·¥ä½œè¡¨çš„è³‡æ–™
        # header=0: æŒ‡å®š Excel çš„ç¬¬ä¸€è¡Œï¼ˆç´¢å¼• 0ï¼‰ä½œç‚ºæ¬„ä½åç¨±
        # skiprows=[1]: è·³éç´¢å¼•ç‚º 1 çš„è¡Œï¼Œå³ Excel ä¸­çš„ç¬¬äºŒè¡Œ
        df = pd.read_excel(
            original_path, 
            sheet_name=sheet_name, 
            header=0,
            skiprows=[1]  # <--- â— é€™è£¡åŠ å…¥è·³é Excel ç¬¬äºŒè¡Œï¼ˆç´¢å¼• 1ï¼‰çš„è¨­å®š
        )
        
        if df.empty:
            print(f"è­¦å‘Šï¼šå·¥ä½œè¡¨ '{sheet_name}' è®€å–åˆ°çš„æ•¸æ“šç‚ºç©ºã€‚")
            return None

    except ValueError as e:
        raise ValueError(f"éŒ¯èª¤ï¼šåœ¨ Excel æª”æ¡ˆä¸­æ‰¾ä¸åˆ°åç‚º '{sheet_name}' çš„å·¥ä½œè¡¨ã€‚è«‹æª¢æŸ¥åç¨±æ˜¯å¦æ­£ç¢ºã€‚è©³ç´°éŒ¯èª¤: {e}")
    except Exception as e:
        raise Exception(f"è®€å– Excel æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        
    # 2. **ã€é—œéµç¯©é¸æ­¥é©Ÿã€‘**
    if filter_column not in df.columns:
        print(f"è­¦å‘Šï¼šæ‰¾ä¸åˆ°ç¯©é¸æ¬„ä½ '{filter_column}'ã€‚è·³éç¯©é¸æ­¥é©Ÿã€‚")
    else:
        initial_rows = len(df)
        print(f"\nğŸ” é–‹å§‹ç¯©é¸ï¼šç§»é™¤ '{filter_column}' å€¼ç‚º '{filter_value}' çš„è³‡æ–™...")
        
        # å˜—è©¦å°‡ç¯©é¸æ¬„ä½è½‰æ›ç‚ºæ•¸å€¼é¡å‹ï¼Œcoerce æœƒå°‡éæ•¸å€¼è½‰æ›ç‚º NaN
        df[filter_column] = pd.to_numeric(df[filter_column], errors='coerce')
        
        # ç¯©é¸é‚è¼¯ï¼šä¿ç•™ 'ç›®å‰è‚¡æ•¸åº«å­˜çµ±è¨ˆ' ä¸ç­‰æ–¼ 0 çš„è¡Œ
        df_filtered = df[df[filter_column] != float(filter_value)]
        
        removed_rows = initial_rows - len(df_filtered)
        print(f"  -> åŸå§‹ç­†æ•¸ (å·²è·³éç¬¬äºŒè¡Œ): {initial_rows} ç­†")
        print(f"  -> ç§»é™¤ç­†æ•¸: {removed_rows} ç­†")
        print(f"  -> å‰©é¤˜ç­†æ•¸: {len(df_filtered)} ç­†")
        
        df = df_filtered
        
        if df.empty:
            print("è­¦å‘Šï¼šç¯©é¸å¾Œæ•¸æ“šç‚ºç©ºã€‚")
            return None


    # 3. æº–å‚™è¼¸å‡º CSV æª”æ¡ˆçš„è·¯å¾‘
    
    if output_dir is None:
        output_dir = original_path.parent
    else:
        output_dir = pathlib.Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime("_%Y%m%d_%H%M%S")
    csv_file_name = f"{sheet_name}_filtered{timestamp}.csv"
    output_csv_path = output_dir / csv_file_name
    
    # 4. å„²å­˜ç‚º CSV æª”æ¡ˆ
    df.to_csv(output_csv_path, index=False, encoding='big5-sig')

    return output_csv_path

def process_and_send_stock_report(
    excel_path: str, sheet_name: str, filter_column: str, filter_value: str, 
    trading_day_file_path: pathlib.Path, base_dir: pathlib.Path, date_to_check: str,
    now_day_time: str, line_user_id: str
):
    """
    ä¸»è¦è™•ç†è‚¡ç¥¨æ¸…å–®æå–ã€æ•¸æ“šåˆ†æã€å ±å‘Šç”Ÿæˆå’Œ Line é€šçŸ¥ç™¼é€çš„æµç¨‹ã€‚
    """
    
    # 1. æª”æ¡ˆè¤‡è£½èˆ‡æå– (å¯ç¨ç«‹ç‚ºä¸€å€‹æ¨¡çµ„å‡½å¼ï¼Œæé«˜å¯æ¸¬è©¦æ€§)
    # copy_file_to_directory(SOURCE_FILE, excel_path) # å‡è¨­é€™éƒ¨åˆ†åœ¨ä¸»ç¨‹å¼æˆ–è¼”åŠ©å·¥å…·ä¸­è™•ç†
    base_dir = pathlib.Path(base_dir)
    excel_path = pathlib.Path(excel_path)
    try:
        final_csv_path = extract_excel_sheet_filter_and_save(
            excel_file_path=excel_path,
            sheet_name=sheet_name,
            filter_column=filter_column,
            filter_value=filter_value,
            output_dir=None
        )
    except Exception as e:
        print(f"âŒ Excel è™•ç†å¤±æ•—: {e}")
        return # å¦‚æœå¤±æ•—ï¼Œå¾ŒçºŒåˆ†æç„¡æ³•é€²è¡Œ

    # 2. ç²å–åº«å­˜è‚¡å’Œé—œæ³¨è‚¡æ¸…å–®
    df = pd.read_csv(final_csv_path, encoding='big5', skipinitialspace=True)
    df.columns = df.columns.str.strip()
    TARGET_STOCK_NAMES = df["è­‰åˆ¸åç¨±"].tolist()
    
    focused_sheet_name = "é—œæ³¨çš„è‚¡ç¥¨"
    focused_column_name = "è­‰åˆ¸åç¨±"
    focused_stock_names = get_stock_names_from_excel(excel_path, focused_sheet_name, focused_column_name)

    # 3. ç²å–æœ€è¿‘ N å€‹äº¤æ˜“æ—¥
    N_DAYS = 6 
    recent_trading_days_df = find_last_n_trading_days_with_time_check(trading_day_file_path, n=N_DAYS)
    if recent_trading_days_df is None:
        print("è­¦å‘Šï¼šç„¡æ³•å–å¾—æœ€è¿‘äº¤æ˜“æ—¥æ¸…å–®ï¼Œè·³éå€‹è‚¡åˆ†æã€‚")
        return

    # å°‡æ—¥æœŸæ ¼å¼è½‰æ›ç‚º 'YYYYMMDD' æ¸…å–®
    day_roll_list = [row.replace("/", "") for row in recent_trading_days_df["æ—¥æœŸ"]]

    # 4. ç”Ÿæˆæ‰€æœ‰è‚¡ç¥¨çš„å ±å‘Šå…§å®¹
    Send_message_ALL = generate_stock_report_content(
        stock_names=TARGET_STOCK_NAMES, 
        is_focused=False,
        day_roll_list=day_roll_list,
        base_dir=base_dir,
        date_to_check=date_to_check
    )
    
    Send_message_ALL += f"*****************************\n"
    Send_message_ALL += f"ğŸ’¡ {date_to_check} é—œæ³¨è‚¡è³‡è¨ŠğŸ’¡\n"
    Send_message_ALL += f"*****************************"

    Send_message_ALL += generate_stock_report_content(
        stock_names=focused_stock_names, 
        is_focused=True,
        day_roll_list=day_roll_list,
        base_dir=base_dir,
        date_to_check=date_to_check
    )
    
    # 5. ç™¼é€ Line é€šçŸ¥
    # é€™è£¡çœç•¥ Line Bot çš„åˆå§‹åŒ–å’Œ Token æª¢æŸ¥ï¼Œå‡è¨­åœ¨ä¸»ç¨‹å¼å•Ÿå‹•æ™‚å·²å®Œæˆ
    if line_user_id:
        send_stock_notification(line_user_id, Send_message_ALL)
    else:
        print("è­¦å‘Šï¼šLINE_USER_ID æœªè¨­å®šï¼Œè·³é Line é€šçŸ¥ç™¼é€ã€‚")
        
    print("\n--- æœ€çµ‚å ±å‘Šå·²åˆ—å°/ç™¼é€ ---")
    print(Send_message_ALL)

# è¼”åŠ©å‡½å¼ (å°‡æ‚¨åŸå§‹ç¨‹å¼ç¢¼ä¸­é‡è¤‡çš„é‚è¼¯æç…‰å‡ºä¾†)
def generate_stock_report_content(stock_names: list, is_focused: bool, day_roll_list: list, base_dir: pathlib.Path, date_to_check: str) -> str:
    """
    ç”Ÿæˆå–®ä¸€é¡å‹è‚¡ç¥¨ (åº«å­˜è‚¡æˆ–é—œæ³¨è‚¡) çš„å ±å‘Šå…§å®¹ã€‚
    (æ­¤è™•çš„å…§å®¹å¯æ ¹æ“šæ‚¨çš„åŸå§‹ç¢¼é‚è¼¯å¡«å¯«)
    """
    # ... (åŒ…å« stock_names è¿´åœˆã€lookup_stock_priceã€get_day_stock_details æˆ– è‡ªè¨‚åƒ¹æ ¼è¨ˆç®—/è²·è³£è¶…è¨ˆç®— çš„é‚è¼¯)
    report_text = ""
    # ç”±æ–¼ç¯‡å¹…é™åˆ¶ï¼Œé€™è£¡åªç•™ä¸‹æ¡†æ¶
    # æ‚¨çš„åŸå§‹ç¢¼ä¸­é‡å°åº«å­˜è‚¡å’Œé—œæ³¨è‚¡æœ‰ç›¸ä¼¼ä½†ç•¥æœ‰ä¸åŒçš„é‚è¼¯ï¼Œè«‹å°‡å…¶å·®ç•°åŒ–è™•ç†å¾Œå¡«å…¥
    for stock_name in stock_names:
        # 1. å–å¾—å‰ä¸€äº¤æ˜“æ—¥åƒ¹æ ¼ (ä½œç‚ºæ¯”è¼ƒåŸºæº–)
        CSV_PATH_BEFORE = base_dir / "datas" / "raw" / "3_BWIBBU_d" / f"{day_roll_list[0]}_BWIBBU_d_IndexReturn.csv"
        get_price_before = lookup_stock_price(CSV_PATH_BEFORE, stock_name, "è­‰åˆ¸åç¨±", "æ”¶ç›¤åƒ¹")
        total_price_percent = 0
        Send_message = ""
        final_indicators = {}
        
        # 2. è¿´åœˆè™•ç†è¿‘ N-1 å¤©çš„æ•¸æ“š
        for day_roll1 in day_roll_list[1:]:
            
            if is_focused:
                 # é—œæ³¨è‚¡çš„åƒ¹æ ¼/æ¼²è·Œå¹…/ä¸‰å¤§æ³•äººè²·è³£è¶…è¨ˆç®—
                 # é€™éƒ¨åˆ†èˆ‡åŸå§‹ç¢¼çš„é‚è¼¯å¤§è‡´ç›¸åŒ
                 day_data = get_day_stock_details(day_roll1, stock_name, get_price_before, base_dir, "è­‰åˆ¸åç¨±", "æ”¶ç›¤åƒ¹")
            else:
                 # åº«å­˜è‚¡çš„åƒ¹æ ¼/æ¼²è·Œå¹…/ä¸‰å¤§æ³•äººè²·è³£è¶…è¨ˆç®—
                 day_data = get_day_stock_details(day_roll1, stock_name, base_dir, get_price_before, "è­‰åˆ¸åç¨±", "æ”¶ç›¤åƒ¹")
                 final_indicators = { 'pa_ratio': day_data['pa_ratio'], 'pe_ratio': day_data['pe_ratio'], 'pb_ratio': day_data['pb_ratio'], }

            # å½™ç¸½ç¸¾æ•ˆå’Œå–®æ—¥è¨Šæ¯
            total_price_percent += day_data['price_percent']
            Send_message += f"{day_data['day_mmdd']}:{day_data['get_price']}{day_data['price_percent_formatted']}({day_data['net_volume_data']})\n"
            get_price_before = day_data['get_price']

        # 3. æ ¼å¼åŒ–ç¸½é«”ç¸¾æ•ˆ
        total_price_percent = round(total_price_percent, 1)
        total_price_percent_formatted = f"ğŸ”´ {abs(total_price_percent)}%" if total_price_percent > 0 else f"ğŸŸ¢ {abs(total_price_percent)}%"
        
        # 4. çµ„åˆå ±å‘Š
        prefix = "ğŸ¥‡" if not is_focused else "âš ï¸"
        report_text += f"\n= {prefix} {stock_name} æœ€è¿‘5æ—¥æ”¶ç›¤åƒ¹ {prefix} =\n{Send_message}"
        report_text += f"== è¿‘5æ—¥ç¸¾æ•ˆ:{total_price_percent_formatted} ==\n"
        
        if not is_focused:
            # åº«å­˜è‚¡æ‰é¡¯ç¤ºæŒ‡æ¨™
            report_text += (
                f"\n--ğŸ¯ã€{stock_name}ã€‘å€‹è‚¡è³‡è¨Š ğŸ¯--\n"
                f" Â æœ¬ç›Šæ¯” Â : {final_indicators.get('pe_ratio', 'N/A')}\n"
                f"è‚¡åƒ¹æ·¨å€¼æ¯”: {final_indicators.get('pb_ratio', 'N/A')}\n"
                f" Â æ®–åˆ©ç‡ Â : {final_indicators.get('pa_ratio', 'N/A')}%\n\n"
            )

    return report_text

# è®€å–é—œæ³¨çš„è‚¡ç¥¨
def get_stock_names_from_excel(file_path: str, sheet_name: str, column_name: str) -> Optional[pd.Series]:
    """
    è®€å– Excel æª”æ¡ˆä¸­æŒ‡å®šå·¥ä½œè¡¨çš„æŒ‡å®šæ¬„ä½æ•¸æ“šã€‚
    Args:
        file_path (str): Excel æª”æ¡ˆçš„å®Œæ•´è·¯å¾‘ã€‚
        sheet_name (str): å·¥ä½œè¡¨çš„æ¨™ç±¤åç¨± (e.g., 'ã€é—œæ³¨çš„è‚¡ç¥¨ã€‘')ã€‚
        column_name (str): è¦æŠ“å–çš„æ¬„ä½åç¨± (e.g., 'è­‰åˆ¸åç¨±')ã€‚

    Returns:
        pd.Series or None: åŒ…å«è­‰åˆ¸åç¨±çš„ Seriesï¼Œå¦‚æœå¤±æ•—å‰‡è¿”å› Noneã€‚
    """
    print(f"ğŸ”„ æ­£åœ¨å˜—è©¦è®€å– Excel æª”æ¡ˆï¼š{file_path}")
    print(f"ğŸ¯ é–å®šå·¥ä½œè¡¨ï¼šã€{sheet_name}ã€‘")

    try:
        # è®€å– Excel æª”æ¡ˆä¸­æŒ‡å®šçš„å·¥ä½œè¡¨
        df = pd.read_excel(file_path, sheet_name=sheet_name)
        
        # æª¢æŸ¥æ¬„ä½æ˜¯å¦å­˜åœ¨
        if column_name in df.columns:
            # æŠ“å–ä¸¦è¿”å› 'è­‰åˆ¸åç¨±' æ¬„ä½çš„è³‡æ–™
            stock_names = df[column_name]
            
            print(f"âœ… æˆåŠŸæŠ“å–å·¥ä½œè¡¨ '{sheet_name}' ä¸­ '{column_name}' æ¬„ä½çš„æ•¸æ“šã€‚")
            
            # è¼¸å‡ºåˆ—è¡¨å…§å®¹
            print("-" * 50)
            print("ã€è­‰åˆ¸åç¨±ã€‘åˆ—è¡¨ï¼š")
            print(stock_names.to_string(index=False)) # è¼¸å‡ºä¹¾æ·¨çš„åˆ—è¡¨
            print("-" * 50)
            
            return stock_names
        else:
            print(f"âŒ éŒ¯èª¤ï¼šå·¥ä½œè¡¨ '{sheet_name}' ä¸­æ‰¾ä¸åˆ°æ¬„ä½ '{column_name}'ã€‚")
            print(f"å¯¦éš›æ¬„ä½åç¨±ï¼š{list(df.columns)}")
            return None

    except FileNotFoundError:
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æŒ‡å®šçš„ Excel æª”æ¡ˆè·¯å¾‘ -> {file_path}")
        return None
    except ValueError as e:
        if "Worksheet named" in str(e):
            print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°åç‚º '{sheet_name}' çš„å·¥ä½œè¡¨ã€‚è«‹æª¢æŸ¥æ¨™ç±¤åç¨±æ˜¯å¦æ­£ç¢ºã€‚")
        else:
            print(f"âŒ è®€å– Excel æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None
    except Exception as e:
        print(f"âŒ ç™¼ç”Ÿå…¶ä»–éŒ¯èª¤: {e}")
        return None
    
    
# å¾ Excel æª”æ¡ˆä¸­è®€å–è‚¡ç¥¨åº«å­˜ï¼Œå°‡å…¶å¦å­˜ç‚º CSV æª”æ¡ˆã€‚
def extract_excel_sheet_filter_and_save(excel_file_path: str, sheet_name: str, filter_column: str, filter_value: any, output_dir: str = None) -> pathlib.Path:
    """
    å¾æŒ‡å®šçš„ Excel æª”æ¡ˆä¸­è®€å–ç‰¹å®šå·¥ä½œè¡¨ï¼Œè·³éç¬¬äºŒè¡Œï¼Œç¯©é¸è³‡æ–™å¾Œï¼Œå°‡å…¶å¦å­˜ç‚º CSV æª”æ¡ˆã€‚

    Args:
        excel_file_path (str): åŸå§‹ Excel æª”æ¡ˆçš„å®Œæ•´è·¯å¾‘ã€‚
        sheet_name (str): è¦è®€å–çš„å·¥ä½œè¡¨åç¨± (ä¾‹å¦‚: 'è‚¡ç¥¨åº«å­˜çµ±è¨ˆ')ã€‚
        filter_column (str): è¦é€²è¡Œç¯©é¸çš„æ¬„ä½åç¨± (ä¾‹å¦‚: 'ç›®å‰è‚¡æ•¸åº«å­˜çµ±è¨ˆ')ã€‚
        filter_value (any): è¦ç¯©é™¤çš„å€¼ã€‚
        output_dir (str, optional): CSV æª”æ¡ˆçš„å„²å­˜ç›®éŒ„ã€‚å¦‚æœç‚º Noneï¼Œå‰‡å„²å­˜åœ¨åŸå§‹æª”æ¡ˆçš„ç›®éŒ„ã€‚

    Returns:
        Path: å„²å­˜æˆåŠŸçš„ CSV æª”æ¡ˆè·¯å¾‘ã€‚
    """
    
    original_path = pathlib.Path(excel_file_path)
    
    if not original_path.exists():
        raise FileNotFoundError(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° Excel æª”æ¡ˆåœ¨è·¯å¾‘ï¼š{excel_file_path}")

    print(f"âœ… æ­£åœ¨è®€å– Excel æª”æ¡ˆï¼š{original_path.name}")
    print(f"ğŸ¯ ç›®æ¨™å·¥ä½œè¡¨åç¨±ï¼š{sheet_name}")

    try:
        # 1. è®€å– Excel ä¸­æŒ‡å®šå·¥ä½œè¡¨çš„è³‡æ–™
        # header=0: æŒ‡å®š Excel çš„ç¬¬ä¸€è¡Œï¼ˆç´¢å¼• 0ï¼‰ä½œç‚ºæ¬„ä½åç¨±
        # skiprows=[1]: è·³éç´¢å¼•ç‚º 1 çš„è¡Œï¼Œå³ Excel ä¸­çš„ç¬¬äºŒè¡Œ
        df = pd.read_excel(
            original_path, 
            sheet_name=sheet_name, 
            header=0,
            skiprows=[1]  # <--- â— é€™è£¡åŠ å…¥è·³é Excel ç¬¬äºŒè¡Œï¼ˆç´¢å¼• 1ï¼‰çš„è¨­å®š
        )
        
        if df.empty:
            print(f"è­¦å‘Šï¼šå·¥ä½œè¡¨ '{sheet_name}' è®€å–åˆ°çš„æ•¸æ“šç‚ºç©ºã€‚")
            return None

    except ValueError as e:
        raise ValueError(f"éŒ¯èª¤ï¼šåœ¨ Excel æª”æ¡ˆä¸­æ‰¾ä¸åˆ°åç‚º '{sheet_name}' çš„å·¥ä½œè¡¨ã€‚è«‹æª¢æŸ¥åç¨±æ˜¯å¦æ­£ç¢ºã€‚è©³ç´°éŒ¯èª¤: {e}")
    except Exception as e:
        raise Exception(f"è®€å– Excel æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        
    # 2. **ã€é—œéµç¯©é¸æ­¥é©Ÿã€‘**
    if filter_column not in df.columns:
        print(f"è­¦å‘Šï¼šæ‰¾ä¸åˆ°ç¯©é¸æ¬„ä½ '{filter_column}'ã€‚è·³éç¯©é¸æ­¥é©Ÿã€‚")
    else:
        initial_rows = len(df)
        print(f"\nğŸ” é–‹å§‹ç¯©é¸ï¼šç§»é™¤ '{filter_column}' å€¼ç‚º '{filter_value}' çš„è³‡æ–™...")
        
        # å˜—è©¦å°‡ç¯©é¸æ¬„ä½è½‰æ›ç‚ºæ•¸å€¼é¡å‹ï¼Œcoerce æœƒå°‡éæ•¸å€¼è½‰æ›ç‚º NaN
        df[filter_column] = pd.to_numeric(df[filter_column], errors='coerce')
        
        # ç¯©é¸é‚è¼¯ï¼šä¿ç•™ 'ç›®å‰è‚¡æ•¸åº«å­˜çµ±è¨ˆ' ä¸ç­‰æ–¼ 0 çš„è¡Œ
        df_filtered = df[df[filter_column] != float(filter_value)]
        
        removed_rows = initial_rows - len(df_filtered)
        print(f"  -> åŸå§‹ç­†æ•¸ (å·²è·³éç¬¬äºŒè¡Œ): {initial_rows} ç­†")
        print(f"  -> ç§»é™¤ç­†æ•¸: {removed_rows} ç­†")
        print(f"  -> å‰©é¤˜ç­†æ•¸: {len(df_filtered)} ç­†")
        
        df = df_filtered
        
        if df.empty:
            print("è­¦å‘Šï¼šç¯©é¸å¾Œæ•¸æ“šç‚ºç©ºã€‚")
            return None


    # 3. æº–å‚™è¼¸å‡º CSV æª”æ¡ˆçš„è·¯å¾‘
    
    if output_dir is None:
        output_dir = original_path.parent
    else:
        output_dir = pathlib.Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime("_%Y%m%d_%H%M%S")
    csv_file_name = f"{sheet_name}_filtered{timestamp}.csv"
    output_csv_path = output_dir / csv_file_name
    
    # 4. å„²å­˜ç‚º CSV æª”æ¡ˆ
    df.to_csv(output_csv_path, index=False, encoding='big5')

    return output_csv_path


# å¾äº¤æ˜“æ—¥æª”æ¡ˆä¸­ï¼Œæ‰¾å‡ºä»Šå¤©å¾€å‰æ•¸ N å€‹äº¤æ˜“æ—¥ï¼Œä¸¦æ ¹æ“šç•¶å‰æ™‚é–“ (15:00) åˆ¤æ–·æ˜¯å¦ç´å…¥ä»Šå¤©ã€‚
def find_last_n_trading_days_with_time_check(file_path, n=6):
    """
    å¾äº¤æ˜“æ—¥æª”æ¡ˆä¸­ï¼Œæ‰¾å‡ºä»Šå¤©å¾€å‰æ•¸ N å€‹äº¤æ˜“æ—¥ï¼Œä¸¦æ ¹æ“šç•¶å‰æ™‚é–“ (15:00) åˆ¤æ–·æ˜¯å¦ç´å…¥ä»Šå¤©ã€‚

    :param file_path: è‚¡ç¥¨äº¤æ˜“æ—¥ CSV æª”æ¡ˆè·¯å¾‘
    :param n: å¾€å‰æ‰¾çš„äº¤æ˜“æ—¥æ•¸é‡ (é è¨­ç‚º 6)
    --å–6å€‹ä½†æœ€å¾Œä¸€å€‹ä¸é¡¯ç¤ºï¼Œä½œç‚ºæ•¸æ“šè¨ˆç®—ç”¨
    :return: åŒ…å«æœ€è¿‘ N å€‹äº¤æ˜“æ—¥çš„ DataFrame (æˆ– None if failed)
    """
    
    # 1. å®šç¾©ç•¶å‰æ™‚é–“å’Œåˆ¤æ–·æ¨™æº–
    now = datetime.now()
    today_date = now.date()
    cutoff_time = time_TimeClass(15, 0, 0) # ä¸‹åˆ 15:00:00
    is_after_cutoff = now.time() >= cutoff_time

    print(f"ç•¶å‰æ—¥æœŸ: {today_date.strftime('%Y/%m/%d')}, ç•¶å‰æ™‚é–“æ˜¯å¦åœ¨ 15:00 ä¹‹å¾Œ: {is_after_cutoff}")
    
    # 2. è®€å–äº¤æ˜“æ—¥æª”æ¡ˆ
    try:
        df = pd.read_csv(file_path, encoding='big5')
    except FileNotFoundError:
        print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æª”æ¡ˆ {file_path}")
        return None
    except Exception as e:
        print(f"è®€å–æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹æª¢æŸ¥æª”æ¡ˆè·¯å¾‘å’Œç·¨ç¢¼: {e}")
        return None

    # å‡è¨­æ—¥æœŸæ¬„ä½ç‚º 'æ—¥æœŸ'
    date_column = 'æ—¥æœŸ' 
    if date_column not in df.columns:
        # å˜—è©¦ä½¿ç”¨å¸¸è¦‹çš„è‹±æ–‡æ¬„ä½å
        if 'Date' in df.columns:
            date_column = 'Date'
        else:
            print(f"éŒ¯èª¤ï¼šç„¡æ³•è­˜åˆ¥äº¤æ˜“æ—¥æœŸçš„æ¬„ä½åç¨±ã€‚è«‹æª¢æŸ¥æ‚¨çš„ CSV æª”æ¡ˆã€‚")
            return None
        
    # 3. æ¸…ç†å’Œè½‰æ›æ—¥æœŸæ ¼å¼
    df[date_column] = pd.to_datetime(df[date_column], errors='coerce').dt.normalize()
    df.dropna(subset=[date_column], inplace=True)
    
    # å»ºç«‹æ‰€æœ‰äº¤æ˜“æ—¥çš„é›†åˆï¼Œç”¨æ–¼å¿«é€Ÿåˆ¤æ–·ä»Šå¤©æ˜¯å¦ç‚ºäº¤æ˜“æ—¥
    all_trading_dates = set(df[date_column].dt.date)
    is_today_trading_day = today_date in all_trading_dates
    
    print(f"ä»Šå¤© ({today_date.strftime('%Y/%m/%d')}) æ˜¯å¦ç‚ºäº¤æ˜“æ—¥: {is_today_trading_day}")

    # 4. æ ¹æ“šæ™‚é–“åˆ¤æ–·æ±ºå®šè³‡æ–™ç¯©é¸çš„æˆªæ­¢æ—¥æœŸ
    
    # é è¨­ï¼šå¦‚æœä¸æ»¿è¶³ç´å…¥ä»Šå¤©çš„æ¢ä»¶ï¼Œå‰‡æˆªæ­¢æ—¥æœŸç‚ºæ˜¨å¤©
    inclusion_date = today_date - timedelta(days=1)
    
    # åˆ¤æ–·æ˜¯å¦æ‡‰è©²ç´å…¥ä»Šå¤©
    if is_today_trading_day and is_after_cutoff:
        # æ¢ä»¶ 1: ä»Šå¤©æ˜¯äº¤æ˜“æ—¥
        # æ¢ä»¶ 2: ä¸”æ™‚é–“åœ¨ 15:00 ä¹‹å¾Œ (è¦–ç‚ºä»Šå¤©äº¤æ˜“å·²å®Œæˆ)
        # -> ç´å…¥ä»Šå¤©
        inclusion_date = today_date
        print("-> åˆ¤æ–·ï¼šç´å…¥ä»Šå¤©çš„äº¤æ˜“æ—¥ã€‚")
    else:
        # å…¶ä»–æƒ…æ³ (éäº¤æ˜“æ—¥ã€æˆ–äº¤æ˜“æ—¥ä½†æœªæ»¿ 15:00)
        # -> æ’é™¤ä»Šå¤©ï¼Œåªå–æ˜¨å¤©åŠæ›´æ—©çš„äº¤æ˜“æ—¥
        inclusion_date = today_date - timedelta(days=1)
        print("-> åˆ¤æ–·ï¼šæ’é™¤ä»Šå¤©çš„äº¤æ˜“æ—¥ï¼Œåªå–æ˜¨å¤©åŠæ›´æ—©çš„æ—¥æœŸã€‚")

    # 5. ç¯©é¸ã€æ’åºä¸¦é¸å–æœ€è¿‘ N å€‹äº¤æ˜“æ—¥
    
    # ç¯©é¸å‡ºæ—¥æœŸå°æ–¼æˆ–ç­‰æ–¼æ±ºå®šæˆªæ­¢æ—¥æœŸçš„äº¤æ˜“æ—¥
    df_past = df[df[date_column].dt.date <= inclusion_date]
    
    # ç¢ºä¿æ—¥æœŸç”±è¿‘åˆ°é æ’åº
    df_past = df_past.sort_values(by=date_column, ascending=False)

    # é¸å–æœ€è¿‘çš„ N å€‹äº¤æ˜“æ—¥
    last_n_days = df_past.head(n)

    if last_n_days.empty:
        print(f"è­¦å‘Šï¼šäº¤æ˜“æ—¥è³‡æ–™ä¸è¶³ï¼Œç„¡æ³•æ‰¾åˆ°å¾€å‰ {n} å€‹äº¤æ˜“æ—¥ã€‚")
        return None

    # å°‡çµæœç”±èˆŠåˆ°æ–°æ’åºä¸¦æ ¼å¼åŒ–è¼¸å‡º
    last_n_days = last_n_days.sort_values(by=date_column, ascending=True)
    last_n_days[date_column] = last_n_days[date_column].dt.strftime('%Y/%m/%d')
    
    print(f"\nâœ… æˆåŠŸæ‰¾åˆ°ä»Šå¤©å¾€å‰ {n} å€‹äº¤æ˜“æ—¥ã€‚")
    return last_n_days

# å¾æŒ‡å®šçš„ CSV æª”æ¡ˆä¸­æŸ¥è©¢ç‰¹å®šè­‰åˆ¸çš„æ”¶ç›¤åƒ¹ã€‚
def lookup_stock_price(file_path: pathlib.Path, stock_name: str, name_col: str, price_col: str) -> Optional[str]:
    """
    å¾æŒ‡å®šçš„ BWIBBU CSV æª”æ¡ˆä¸­æŸ¥æ‰¾ç‰¹å®šè‚¡ç¥¨çš„æ”¶ç›¤åƒ¹ã€‚
    
    ä¿®æ­£: ç¢ºä¿åœ¨è¿”å›åƒ¹æ ¼å‰ï¼Œç§»é™¤åƒä½åˆ†éš”ç¬¦è™Ÿ (,) ä»¥é¿å… ValueErrorã€‚
    """
    df = _read_local_csv(file_path)
    if df is None:
        print(f"  > è­¦å‘Š: åƒ¹æ ¼æª”æ¡ˆ {file_path.name} ç¼ºå¤±æˆ–è®€å–å¤±æ•—ã€‚")
        #sys.exit(1)  # æš«åœåŸ·è¡Œï¼Œè«‹ç¢ºèªæ—¥æœŸç„¡èª¤å¾Œå†ç§»é™¤æ­¤è¡Œ
        return None
        
    try:
        # å°‹æ‰¾åŒ¹é…çš„è‚¡ç¥¨åç¨±
        result = df[df[name_col] == stock_name]
        if not result.empty and price_col in result.columns:
            price_raw = result.iloc[0][price_col]

            # --- åƒ¹æ ¼æ¸…ç†èˆ‡è½‰æ› ---
            price_float = None
            if price_raw is not None:
                # 1. å¦‚æœæ˜¯å­—ä¸²ï¼Œç§»é™¤é€—è™Ÿå’Œå‰å¾Œç©ºç™½
                if isinstance(price_raw, str):
                    price_clean_str = price_raw.replace(',', '').strip()
                else:
                    price_clean_str = str(price_raw)
                
                # 2. å˜—è©¦è½‰æ›ç‚º float
                try:
                    price_float = float(price_clean_str)
                except (ValueError, TypeError):
                    print(f"  > è­¦å‘Š: {stock_name} çš„åƒ¹æ ¼ '{price_raw}' ç„¡æ³•è½‰æ›ç‚ºæ•¸å­—ã€‚")
                    return None
            
            if price_float is not None:
                # è¿”å›æ ¼å¼åŒ–ç‚ºå…©ä½å°æ•¸çš„åƒ¹æ ¼å­—ä¸²
                return f"{price_float:.2f}"
            else:
                return None
        else:
            # print(f"  > è­¦å‘Š: æ‰¾ä¸åˆ° {stock_name} çš„åƒ¹æ ¼è³‡æ–™ã€‚")
            return None
    except Exception as e:
        print(f"  > åƒ¹æ ¼æŸ¥è©¢å¤±æ•—: {e}")
        return None
    
def get_day_stock_details(
    day_roll1: str,
    target_stock_name: str,
    base_dir: pathlib.Path,
    get_price_before: Optional[str],
    csv_name_column: str,
    csv_price_column: str
) -> Dict[str, Any]:
    """
    ç²å–å–®ä¸€äº¤æ˜“æ—¥ (day_roll1) ç‰¹å®šè‚¡ç¥¨ (target_stock_name) çš„è©³ç´°è³‡è¨Šï¼Œ
    åŒ…æ‹¬æ”¶ç›¤åƒ¹ã€æ¼²è·Œå¹…ã€ä¸‰å¤§æ³•äººè²·è³£è¶…ã€ä»¥åŠå€‹è‚¡æŒ‡æ¨™ã€‚
    
    Args:
        day_roll1: ç•¶å‰äº¤æ˜“æ—¥ (YYYYMMDD æ ¼å¼)ã€‚
        target_stock_name: è‚¡ç¥¨åç¨±ã€‚
        base_dir: å°ˆæ¡ˆåŸºç¤è·¯å¾‘ã€‚
        get_price_before: å‰ä¸€äº¤æ˜“æ—¥çš„æ”¶ç›¤åƒ¹ (å­—ä¸²æˆ– None)ã€‚
        csv_name_column: CSV ä¸­ç”¨æ–¼æ¯”å°çš„è‚¡ç¥¨åç¨±æ¬„ä½åç¨±ã€‚
        csv_price_column: CSV ä¸­æ”¶ç›¤åƒ¹çš„æ¬„ä½åç¨±ã€‚

    Returns:
        åŒ…å«ç•¶æ—¥æ‰€æœ‰è™•ç†çµæœçš„å­—å…¸ã€‚
    """
    
    # ------------------ 1. å®šç¾©æª”æ¡ˆè·¯å¾‘ ------------------
    
    # åƒ¹æ ¼èˆ‡æŒ‡æ¨™ CSV è·¯å¾‘ (3_BWIBBU_d)
    csv_price_path = base_dir / "datas" / "raw" / "3_BWIBBU_d" / f"{day_roll1}_BWIBBU_d_IndexReturn.csv"
    # ä¸‰å¤§æ³•äººè²·è³£è¶… CSV è·¯å¾‘ (11_T86)
    csv_volume_path = base_dir / "datas" / "raw" / "11_T86" / f"{day_roll1}_T86_InstitutionalTrades.csv"

    # åˆå§‹åŒ–çµæœå­—å…¸
    result = {
        'day_mmdd': f"{day_roll1[4:6]}/{day_roll1[-2:]}",
        'get_price': None,
        'price_percent': 0.0,
        'price_percent_formatted': "0.0%",
        'net_volume_data': "0", # é è¨­ç‚º "0" (ä¸å¸¶å¼µå­—ï¼Œå¾Œé¢çµ±ä¸€åŠ ä¸Š)
        'pa_ratio': "-",
        'pe_ratio': "-",
        'pb_ratio': "-"
    }

    # ------------------ 2. ç²å–æ”¶ç›¤åƒ¹ ------------------

    # å‡è¨­ lookup_stock_price è¿”å›å­—ä¸²æˆ– None
    get_price = lookup_stock_price(
        file_path=csv_price_path,
        stock_name=target_stock_name,
        name_col=csv_name_column,
        price_col=csv_price_column
    )
    result['get_price'] = get_price

    # ------------------ 3. è¨ˆç®—åƒ¹æ ¼æ¼²è·Œå¹… ------------------
    
    if get_price is not None and get_price_before is not None:
        try:
            current_price = float(get_price)
            previous_price = float(get_price_before)
            
            if previous_price != 0:
                price_percent = (current_price - previous_price) / previous_price * 100
                result['price_percent'] = round(price_percent, 1)
                
                # æ ¼å¼åŒ–è¼¸å‡º
                formatted_percent = abs(result['price_percent'])
                if price_percent > 0:
                    result['price_percent_formatted'] = f"ğŸ”´{formatted_percent}%"
                else:
                    result['price_percent_formatted'] = f"ğŸŸ¢{formatted_percent}%"
            else:
                print(f"âš ï¸ è­¦å‘Š: {result['day_mmdd']} å‰ä¸€æ—¥åƒ¹æ ¼ç‚º 0ï¼Œç„¡æ³•è¨ˆç®—æ¼²è·Œå¹…ã€‚")
        except (ValueError, TypeError) as e:
            print(f"âŒ éŒ¯èª¤: {result['day_mmdd']} åƒ¹æ ¼è½‰æ›æˆ–è¨ˆç®—å¤±æ•— ({e})ï¼Œè·³éæ¼²è·Œå¹…ã€‚")
    else:
        # ç•¶ get_price æˆ– get_price_before ç‚º None æ™‚
        print(f"âŒ éŒ¯èª¤: {result['day_mmdd']} åƒ¹æ ¼è³‡æ–™ç¼ºå¤± (None)ï¼Œè·³éæ¼²è·Œå¹…è¨ˆç®—ã€‚")

    # ------------------ 4. ç²å–ä¸‰å¤§æ³•äººè²·è³£è¶… (å·²ä¿®æ­£ NoneType éŒ¯èª¤) ------------------
    
    # å‡è¨­ get_stock_net_volume è¿”å› pd.Series æˆ– None
    net_volume_data_series = get_stock_net_volume(csv_volume_path, target_stock_name)
    
    # >>> é—œéµä¿®æ­£å€å¡Šï¼šé˜²æ­¢ net_volume_data_series ç‚º None å°è‡´ astype éŒ¯èª¤
    if net_volume_data_series is not None and not net_volume_data_series.empty:
        try:
            # 1. å­—ä¸²æ¸…ç†ï¼šå°‡ Series è½‰æ›ç‚ºå­—ä¸²ï¼Œç§»é™¤é€—è™Ÿå’Œè² è™Ÿ (ç¢ºä¿åªå‰©æ•¸å­—å’Œå¯èƒ½çš„å°æ•¸é»)
            cleaned_volume_str = net_volume_data_series.astype(str).str.replace(',', '', regex=False).str.replace('-', '', regex=False).str.strip()
            
            # 2. æ•¸å€¼è½‰æ›ï¼šè½‰æ›ç‚º floatï¼Œç„¶å¾Œé™¤ä»¥ 1000 æ›ç®—æˆã€Œå¼µã€
            net_volume_in_lots = pd.to_numeric(cleaned_volume_str, errors='coerce') / 1000
            
            # 3. å››æ¨äº”å…¥ä¸¦è½‰æ›ç‚ºæ•´æ•¸
            rounded_lots = net_volume_in_lots.round(0).astype('Int64') # ä½¿ç”¨ Int64 è™•ç† NaN/None
            
            # 4. æå–ç´”æ•¸å€¼ä¸¦æ ¼å¼åŒ–
            # ç”±æ–¼ Series ä¸­åªæœ‰ä¸€å€‹å€¼ï¼Œæˆ‘å€‘å¯ä»¥ç›´æ¥å–ç¬¬ä¸€å€‹å€¼ï¼ˆæˆ–ä½¿ç”¨ to_stringï¼Œä½†å–å€¼æ›´å®‰å…¨ï¼‰
            if not rounded_lots.empty:
                volume_int = rounded_lots.iloc[0]
                
                # æ ¼å¼åŒ–ä¸¦å„²å­˜ï¼Œä½¿ç”¨åƒä½åˆ†éš”ç¬¦
                if pd.notna(volume_int):
                    # ä½¿ç”¨ f-string æ ¼å¼åŒ–ï¼Œè‡ªå‹•åŠ ä¸Šåƒä½åˆ†éš”ç¬¦
                    result['net_volume_data'] = f"{int(volume_int):,d}"
                else:
                    # å¦‚æœè½‰æ›å¾Œæ˜¯ NaN/Noneï¼Œå‰‡è¨­ç‚º 0
                    result['net_volume_data'] = "0"
            else:
                 # é›–ç„¶ Series ä¸ç‚º emptyï¼Œä½†æ•¸å€¼è½‰æ›å¾Œå¯èƒ½ç‚ºç©º
                 result['net_volume_data'] = "0"

        except Exception as e:
            # æ•ç²æ‰€æœ‰è½‰æ›éŒ¯èª¤
            print(f"âŒ éŒ¯èª¤: {result['day_mmdd']} è²·è³£è¶…è³‡æ–™è½‰æ›å¤±æ•— ({e})ï¼Œè¨­å®šç‚º 'è³‡æ–™éŒ¯èª¤'ã€‚")
            result['net_volume_data'] = "è³‡æ–™éŒ¯èª¤"
            
    else:
        # net_volume_data_series is None æˆ– empty (get_stock_net_volume å¤±æ•—æˆ–æ‰¾ä¸åˆ°è‚¡ç¥¨)
        print(f"æ‰¾ä¸åˆ° {target_stock_name} åœ¨ {result['day_mmdd']} çš„è²·è³£è¶…è‚¡æ•¸è³‡æ–™ã€‚")
        result['net_volume_data'] = "0"

    # ------------------ 5. ç²å–å€‹è‚¡æŒ‡æ¨™ ------------------
    
    stock_indicators_df = get_stock_indicators(csv_price_path, target_stock_name)
    
    if stock_indicators_df is not None and not stock_indicators_df.empty:
        try:
            # ç¢ºä¿æ¬„ä½å­˜åœ¨ï¼Œä¸¦æå–æ•¸æ“š
            result['pa_ratio'] = stock_indicators_df.iloc[0]['æ®–åˆ©ç‡(%)']
            result['pe_ratio'] = stock_indicators_df.iloc[0]['æœ¬ç›Šæ¯”']
            result['pb_ratio'] = stock_indicators_df.iloc[0]['è‚¡åƒ¹æ·¨å€¼æ¯”']
        except KeyError:
            print(f"âš ï¸ è­¦å‘Š: {result['day_mmdd']} å€‹è‚¡æŒ‡æ¨™ CSV æ¬„ä½åç¨±ä¸æ­£ç¢ºæˆ–æ•¸æ“šç¼ºå¤±ã€‚")
            # ä¿æŒé è¨­çš„ "-"

    return result


# è®€å– CSV æª”æ¡ˆï¼Œç¯©é¸å‡ºæŒ‡å®šè­‰åˆ¸åç¨±çš„æ•¸æ“šï¼Œä¸¦è¿”å›å…¶æŒ‡æ¨™è³‡æ–™ã€‚
def get_stock_indicators(file_path: str, target_name: str) -> Optional[pd.DataFrame]:
    """
    è®€å– CSV æª”æ¡ˆï¼Œç¯©é¸å‡ºæŒ‡å®šè­‰åˆ¸åç¨±çš„æ•¸æ“šï¼Œä¸¦è¿”å›å…¶æŒ‡æ¨™è³‡æ–™ã€‚
    
    Args:
        file_path (str): CSV æª”æ¡ˆçš„å®Œæ•´è·¯å¾‘ã€‚
        target_name (str): è¦ç¯©é¸çš„è­‰åˆ¸åç¨± (e.g., 'å°ç»')ã€‚
        
    Returns:
        pd.DataFrame or None: åŒ…å«ç›®æ¨™è­‰åˆ¸æŒ‡æ¨™æ•¸æ“šçš„ DataFrameï¼Œå¦‚æœå¤±æ•—å‰‡è¿”å› Noneã€‚
    """
    #base_dir = pathlib.Path(base_dir)
    file_path = pathlib.Path(file_path)
    
    print(f"ğŸ”„ æ­£åœ¨è®€å–æª”æ¡ˆï¼š{file_path}")
    print(f"ğŸ¯ æœå°‹ç›®æ¨™è­‰åˆ¸ï¼šã€{target_name}ã€‘çš„æŒ‡æ¨™æ•¸æ“š")

    # 1. è®€å– CSV æª”æ¡ˆ (å¤šç·¨ç¢¼å˜—è©¦)
    try:
        try:
            df = pd.read_csv(file_path, encoding='utf-8-sig')
        except UnicodeDecodeError:
            try:
                df = pd.read_csv(file_path, encoding='utf-8')
            except:
                df = pd.read_csv(file_path, encoding='big5')
    except FileNotFoundError:
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æŒ‡å®šçš„è¼¸å…¥æª”æ¡ˆè·¯å¾‘ -> {file_path}")
        return None
    except Exception as e:
        print(f"âŒ ç™¼ç”Ÿå…¶ä»–éŒ¯èª¤æˆ–ç·¨ç¢¼å•é¡Œï¼š{e}")
        return None

    # 2. æª¢æŸ¥é—œéµæ¬„ä½æ˜¯å¦å­˜åœ¨
    # æ ¹æ“š TWSE/BWIBBU æª”æ¡ˆå¸¸è¦‹çµæ§‹ï¼Œæ¬„ä½åç¨±å¯èƒ½ç•¥æœ‰ä¸åŒï¼Œé€™è£¡æ²¿ç”¨ä¸Šä¸€æ¬¡çš„æ¬„ä½åç¨±ï¼Œ
    # ä½†è«‹æ ¹æ“šå¯¦éš›æª”æ¡ˆæƒ…æ³èª¿æ•´ï¼Œä¾‹å¦‚ï¼š'æœ¬ç›Šæ¯”' å¯èƒ½ç‚º 'PE Ratio'
    required_cols = ['è­‰åˆ¸åç¨±', 'æ®–åˆ©ç‡(%)', 'æœ¬ç›Šæ¯”', 'è‚¡åƒ¹æ·¨å€¼æ¯”']
    
    if not all(col in df.columns for col in required_cols):
        missing_cols = [col for col in required_cols if col not in df.columns]
        print(f"âš ï¸ éŒ¯èª¤ï¼šæª”æ¡ˆä¸­ç¼ºå°‘å¿…è¦çš„æ¬„ä½ï¼š{missing_cols}ã€‚")
        print(f"æª”æ¡ˆå¯¦éš›æ¬„ä½åç¨±ï¼š{list(df.columns)}")
        # ç”±æ–¼ BWIBBU æª”æ¡ˆæ ¼å¼å¯èƒ½è¼ƒç‚ºè¤‡é›œï¼Œé€™è£¡å…ˆå‡è¨­æ¬„ä½åç¨±æ˜¯æ­£ç¢ºçš„ã€‚
        # å¦‚æœåŸ·è¡Œæ™‚å ±éŒ¯ï¼Œè«‹æª¢æŸ¥å¯¦éš› CSV æª”æ¡ˆä¸­çš„æ¬„ä½åç¨±ã€‚
        return None

    # 3. æ•¸æ“šæ¸…ç†èˆ‡ç¯©é¸
    # æ¸…ç† 'è­‰åˆ¸åç¨±' å…©å´ç©ºç™½ï¼Œç¢ºä¿ç²¾ç¢ºåŒ¹é…
    df['è­‰åˆ¸åç¨±'] = df['è­‰åˆ¸åç¨±'].astype(str).str.strip()

    # ç¯©é¸å‡ºç›®æ¨™è­‰åˆ¸åç¨±çš„æ•¸æ“š
    target_data = df[df['è­‰åˆ¸åç¨±'] == target_name]

    if target_data.empty:
        print(f"\nâ„¹ï¸ æç¤ºï¼šåœ¨æª”æ¡ˆä¸­æ‰¾ä¸åˆ°è­‰åˆ¸åç¨±ç‚º ã€{target_name}ã€‘ çš„æ•¸æ“šã€‚")
        return pd.DataFrame()
    
    # 4. æå–ç›®æ¨™æ¬„ä½æ•¸æ“š
    indicator_cols = ['è­‰åˆ¸åç¨±', 'æ®–åˆ©ç‡(%)', 'æœ¬ç›Šæ¯”', 'è‚¡åƒ¹æ·¨å€¼æ¯”']
    result_df = target_data[indicator_cols].copy() 

    # 5. è¼¸å‡ºçµæœ
    print(f"\nâœ… æˆåŠŸæ‰¾åˆ° ã€{target_name}ã€‘ çš„æŒ‡æ¨™æ•¸æ“šï¼š")
    print("=" * 40)
    
    # ä½¿ç”¨ to_string é€²è¡Œæ ¼å¼åŒ–è¼¸å‡º
    print(
        result_df.to_string(
            index=False,
            justify='left' # è®“æ–‡å­—é å·¦å°é½Š
        )
    )
    print("=" * 40)
    
    print("æ¸¬è©¦-------------")
    return result_df


# è®€å– CSV æª”æ¡ˆï¼Œç¯©é¸å‡ºæŒ‡å®šè­‰åˆ¸åç¨±çš„è³‡æ–™ï¼Œä¸¦åªè¿”å›ã€Œè²·è³£è¶…è‚¡æ•¸ã€æ•¸æ“šã€‚
def get_stock_net_volume(file_path, target_name, target_column="ä¸‰å¤§æ³•äººè²·è³£è¶…è‚¡æ•¸"):
    """
    è®€å– CSV æª”æ¡ˆï¼Œç¯©é¸å‡ºæŒ‡å®šè­‰åˆ¸åç¨±çš„è³‡æ–™ï¼Œä¸¦åªè¿”å›ã€Œè²·è³£è¶…è‚¡æ•¸ã€æ•¸æ“šã€‚
    Args:
        file_path (str): CSVæª”æ¡ˆçš„å®Œæ•´è·¯å¾‘ã€‚
        target_name (str): è¦ç¯©é¸çš„è­‰åˆ¸åç¨±ã€‚
        target_column (str): è¦å–å‡ºçš„æ¬„ä½åç¨± (é è¨­ç‚º 'è²·è³£è¶…è‚¡æ•¸')ã€‚
    Returns:
        pd.Series or None: åŒ…å«ç›®æ¨™è²·è³£è¶…è‚¡æ•¸çš„ Seriesï¼Œå¦‚æœè®€å–æˆ–ç¯©é¸å¤±æ•—å‰‡è¿”å› Noneã€‚
    """
    print(f"ğŸ”„ æ­£åœ¨è®€å–æª”æ¡ˆï¼š{file_path}")
    print(f"ğŸ¯ æœå°‹ç›®æ¨™ï¼šã€{target_name}ã€‘ï¼Œä¸¦å–å‡ºã€{target_column}ã€‘æ•¸æ“š")

    # 1. è®€å–CSVæª”æ¡ˆ (å¤šç·¨ç¢¼å˜—è©¦ï¼Œç¢ºä¿è¼¸å…¥æ­£ç¢º)
    try:
        try:
            df = pd.read_csv(file_path, encoding='utf-8-sig')
            print("â„¹ï¸ æˆåŠŸä½¿ç”¨ 'utf-8-sig' ç·¨ç¢¼è®€å–ã€‚")
        except UnicodeDecodeError:
            try:
                df = pd.read_csv(file_path, encoding='utf-8')
                print("â„¹ï¸ ä½¿ç”¨ 'utf-8' ç·¨ç¢¼è®€å–ã€‚")
            except:
                df = pd.read_csv(file_path, encoding='big5')
                print("â„¹ï¸ ä½¿ç”¨ 'big5' ç·¨ç¢¼è®€å–ã€‚")
    except FileNotFoundError:
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æŒ‡å®šçš„è¼¸å…¥æª”æ¡ˆè·¯å¾‘ -> {file_path}")
        return None
    except Exception as e:
        print(f"âŒ ç™¼ç”Ÿå…¶ä»–éŒ¯èª¤æˆ–ç·¨ç¢¼å•é¡Œï¼š{e}")
        return None
    
    # 2. æª¢æŸ¥é—œéµæ¬„ä½æ˜¯å¦å­˜åœ¨
    required_cols = ['è­‰åˆ¸åç¨±', target_column]
    if not all(col in df.columns for col in required_cols):
        missing_cols = [col for col in required_cols if col not in df.columns]
        print(f"âš ï¸ éŒ¯èª¤ï¼šæª”æ¡ˆä¸­ç¼ºå°‘å¿…è¦çš„æ¬„ä½ï¼š{missing_cols}ã€‚")
        print(f"æª”æ¡ˆå¯¦éš›æ¬„ä½åç¨±ï¼š{list(df.columns)}")
        return None

    # 3. æ•¸æ“šæ¸…ç†èˆ‡ç¯©é¸
    # æ¸…ç† 'è­‰åˆ¸åç¨±' å…©å´ç©ºç™½ï¼Œç¢ºä¿ç²¾ç¢ºåŒ¹é…
    df['è­‰åˆ¸åç¨±'] = df['è­‰åˆ¸åç¨±'].astype(str).str.strip()

    # â­ æ ¸å¿ƒä¿®æ”¹é» A: æ¸…ç† 'è²·è³£è¶…è‚¡æ•¸' æ¬„ä½ï¼Œç§»é™¤å¼•è™Ÿä¸¦æ¸…ç†ç©ºç™½ï¼Œç‚ºæ•¸å€¼è½‰æ›åšæº–å‚™
    try:
        df[target_column] = df[target_column].astype(str).str.replace('"', '', regex=False).str.strip()
        # print(f"âœ… æˆåŠŸç§»é™¤ {target_column} æ¬„ä½ä¸­çš„é›™å¼•è™Ÿã€‚")
    except Exception as e:
        print(f"âš ï¸ è­¦å‘Šï¼šå˜—è©¦æ¸…ç† {target_column} æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

    target_data = df[df['è­‰åˆ¸åç¨±'] == target_name]

    # 4. å–å‡ºç›®æ¨™æ¬„ä½æ•¸æ“š
    if target_data.empty:
        print(f"\nâ„¹ï¸ æç¤ºï¼šåœ¨æª”æ¡ˆä¸­æ‰¾ä¸åˆ°è­‰åˆ¸åç¨±ç‚º ã€{target_name}ã€‘ çš„æ•¸æ“šã€‚")
        # çµ±ä¸€è¿”å› Noneï¼Œè®“å¤–éƒ¨ç¨‹å¼ç¢¼åªéœ€æª¢æŸ¥ None
        return None
    else:
        # å–å‡º 'è²·è³£è¶…è‚¡æ•¸' æ¬„ä½ï¼Œé€™æ˜¯ä¸€å€‹ pandas.Series å°è±¡
        net_volume_series = target_data[target_column]
        
        print(f"\nâœ… æˆåŠŸæ‰¾åˆ° ã€{target_name}ã€‘ çš„ {len(net_volume_series)} ç­†ã€{target_column}ã€‘æ•¸æ“šã€‚")
        print("-" * 60)
        # é€™è£¡ä¸é¡¯ç¤º Series åŸå§‹å…§å®¹ï¼Œè®“æœ€çµ‚è¼¸å‡ºæ›´èšç„¦
        
    #print("æ¸¬è©¦1",net_volume_series)
    #sys.exit(1)  # æš«åœåŸ·è¡Œï¼Œè«‹ç¢ºèªæ—¥æœŸç„¡èª¤å¾Œå†ç§»é™¤æ­¤è¡Œ
        
    return net_volume_series

def send_stock_notification(user_id, message_text):
        try:
            push_message_request = PushMessageRequest(
                to=user_id,
                messages=[TextMessage(text=message_text)]
            )
            # æ³¨æ„ï¼šé€™è£¡ä½¿ç”¨å…¨åŸŸè®Šæ•¸ messaging_apiï¼Œå¦‚æœåˆå§‹åŒ–å¤±æ•—ï¼Œé€™è£¡æœƒå ±éŒ¯
            messaging_api.push_message(push_message_request) 
            print(f"è¨Šæ¯å·²æˆåŠŸç™¼é€çµ¦ {user_id}")
        except Exception as e:
            print(f"å…¶ä»–éŒ¯èª¤: {e}")
            
def _read_local_csv(file_path: pathlib.Path) -> Optional[pd.DataFrame]:
    """
    è®€å–æœ¬åœ° CSV æª”æ¡ˆï¼Œä¸¦è™•ç†ä¸å­˜åœ¨çš„æƒ…æ³ã€‚
    """
    if not file_path.exists():
        # print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æª”æ¡ˆ {file_path}")
        return None
    try:
        # å‡è¨­æœ¬åœ°å„²å­˜çš„ CSV å·²ç¶“æ˜¯ UTF-8-SIG ç·¨ç¢¼
        df = pd.read_csv(file_path, encoding='utf-8-sig')
        # æ¸…é™¤æ¬„ä½åç¨±å‰å¾Œçš„ç©ºç™½
        df.columns = df.columns.str.strip()
        return df
    except Exception as e:
        print(f"âŒ éŒ¯èª¤ï¼šè®€å–æœ¬åœ° CSV æª”æ¡ˆ {file_path} æ™‚å¤±æ•—: {e}")
        return None