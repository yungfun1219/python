import pandas as pd
from pathlib import Path
import re
from datetime import datetime, timedelta
import os
import sys
import mplfinance as mpf
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

# =============================================================
# ğŸ¯ è¨­å®šå€å¡Šï¼šè«‹æ ¹æ“šæ‚¨çš„æª”æ¡ˆçµæ§‹å’Œè‚¡ç¥¨è³‡è¨Šä¿®æ”¹
# =============================================================
STOCK_CODE = "8110"
STOCK_NAME = "è¯æ±"
#STOCK_CODE = "2344"
#STOCK_NAME = "è¯é‚¦é›»"



# ------------------------------------
# ğŸ“Œ 1. è·¯å¾‘è¨­å®š (ä¿æŒä¸è®Š)
# ------------------------------------
if getattr(sys, 'frozen', False):
    BASE_DIR = Path(sys.executable).parent
else:
    BASE_DIR = Path(os.path.dirname(os.path.abspath(__file__))) 
    
BASE_RAW_DIR = BASE_DIR / "datas" / "raw" / "1_STOCK_DAY"
INPUT_DIR = BASE_RAW_DIR / STOCK_CODE

# è¼¸å‡ºè·¯å¾‘
# è«‹ç¢ºä¿æ­¤è·¯å¾‘å­˜åœ¨æˆ–ç¨‹å¼æœ‰æ¬Šé™å»ºç«‹
OUTPUT_DIR = Path("D:/Python_repo/python/Jason_Stock_Project/datas/processed/stock_all") 
OUTPUT_FILE = f"{STOCK_CODE}_{STOCK_NAME}_stocks_data.csv"
OUTPUT_PATH = OUTPUT_DIR / OUTPUT_FILE

# ------------------------------------
# ğŸ“Œ 2. æ¬„ä½èˆ‡æŒ‡æ¨™è¨­å®š (ä¿æŒä¸è®Š)
# ------------------------------------
ENCODINGS_TO_TRY = ['utf-8-sig', 'big5', 'utf-8', 'cp950']

# ğŸ¯ éœ€è¦ä¿ç•™çš„æ‰€æœ‰åŸå§‹æ¬„ä½
RAW_COL_NAMES = ['æ—¥æœŸ', 'æˆäº¤è‚¡æ•¸', 'æˆäº¤é‡‘é¡', 'é–‹ç›¤åƒ¹', 'æœ€é«˜åƒ¹', 'æœ€ä½åƒ¹', 'æ”¶ç›¤åƒ¹', 'æ¼²è·Œåƒ¹å·®', 'æˆäº¤ç­†æ•¸']

# åƒ¹æ ¼æ¬„ä½ (ç”¨æ–¼æ•¸å€¼è½‰æ›å’Œ MACD/MA è¨ˆç®—)
PRICE_COLS = ['é–‹ç›¤åƒ¹', 'æœ€é«˜åƒ¹', 'æœ€ä½åƒ¹', 'æ”¶ç›¤åƒ¹']

# MACD åƒæ•¸è¨­å®š
SHORT_WINDOW = 12
LONG_WINDOW = 26
SIGNAL_WINDOW = 9

# KDJ åƒæ•¸è¨­å®š
KDJ_N = 9 # KDJ é€±æœŸ (é€šå¸¸æ˜¯ 9 å¤©)
KDJ_M1 = 3 # K çš„å¹³æ»‘é€±æœŸ (é€šå¸¸æ˜¯ 3 å¤©)
KDJ_M2 = 3 # D çš„å¹³æ»‘é€±æœŸ (é€šå¸¸æ˜¯ 3 å¤©)

# RSI åƒæ•¸è¨­å®š
RSI_PERIODS = [5, 10] # è¦æ±‚çš„ RSI é€±æœŸ

# VOL åƒæ•¸è¨­å®š
VOL_PERIODS = [5, 10]

# MA ç·šçš„é¡è‰²å®šç¾© (ç”¨æ–¼ mplfinance å’Œ MACD åœ–ä¾‹)
MA_COLORS = {
    'MA5': 'purple', 
    'MA10': 'darkgreen', 
    'MA20': 'gold'
}
MAV_PERIODS = [5, 10, 20]
MAV_COLORS_LIST = list(MA_COLORS.values())
# =============================================================

# -----------------------------------------------------------
# ã€è³‡æ–™è™•ç†å‡½å¼ - ä¿æŒä¸è®Šã€‘
# -----------------------------------------------------------

def convert_roc_to_gregorian(date_str):
    """å°‡å¤šç¨®æ—¥æœŸæ ¼å¼è½‰ç‚º YYYY/MM/DD æ ¼å¼å­—ä¸²ã€‚"""
    if pd.isna(date_str) or not isinstance(date_str, str):
        return None
    s = date_str.strip()
    trans_table = str.maketrans('ï¼Œã€‚ï¼ï¼ï¼šï¼', ',./-:.')
    s = s.translate(trans_table)
    s = s.replace('å¹´', '/').replace('æœˆ', '/').replace('æ—¥', '')
    m = re.search(r'(\d{2,4})\D+(\d{1,2})\D+(\d{1,2})', s)
    if not m:
        return None
    year_str = m.group(1)
    mon_str = m.group(2)
    day_str = m.group(3)
    try:
        year = int(year_str)
        month = int(mon_str)
        day = int(day_str)
    except ValueError:
        return None
        
    if year > 1911:
        greg_year = year
    else:
        greg_year = year + 1911
        
    try:
        d = datetime(greg_year, month, day)
        return f"{d.year}/{d.month:02d}/{d.day:02d}"
    except ValueError:
        return None

def try_read_csv(filepath, encodings):
    """å˜—è©¦ä½¿ç”¨å¤šç¨®ç·¨ç¢¼è®€å– CSV æª”æ¡ˆã€‚"""
    for enc in encodings:
        try:
            df = pd.read_csv(filepath, encoding=enc, header=0)
            return df, enc
        except UnicodeDecodeError:
            continue
        except Exception as e:
            print(f"âŒ {filepath.name} ä½¿ç”¨ {enc} è®€å–æ™‚ç™¼ç”Ÿéç·¨ç¢¼éŒ¯èª¤: {e}")
            return None, None
    print(f"âš ï¸ {filepath.name} ç„¡æ³•ç”¨æŒ‡å®šç·¨ç¢¼è®€å–ã€‚")
    return None, None

def clean_dataframe(df, required_raw_cols, price_cols):
    """å°å–®ä¸€ DataFrame é€²è¡Œæ¬„ä½æ¸…ç†ã€æ—¥æœŸè½‰æ›å’Œåƒ¹æ ¼æ•¸å€¼åŒ–ã€‚ä¿ç•™æ‰€æœ‰æŒ‡å®šçš„åŸå§‹æ¬„ä½ï¼Œä¸¦ç¢ºä¿é—œéµæ¬„ä½å­˜åœ¨ã€‚"""
    df.columns = df.columns.str.strip()
    
    col_mapping = {}
    missing_cols = []
    
    for col in required_raw_cols:
        found = False
        for df_col in df.columns:
            # å¯¬é¬†åŒ¹é…: å¿½ç•¥ç©ºæ ¼ã€ç‰¹æ®Šç¬¦è™Ÿï¼ŒåªåŒ¹é…é—œéµä¸­æ–‡åç¨±
            cleaned_df_col = re.sub(r'[^a-zA-Z0-9\u4e00-\u9fa5]', '', df_col)
            cleaned_std_col = re.sub(r'[^a-zA-Z0-9\u4e00-\u9fa5]', '', col)
            
            if cleaned_df_col == cleaned_std_col:
                col_mapping[df_col] = col
                found = True
                break
        
        if not found:
            missing_cols.append(col)
            
    if missing_cols:
        raise KeyError(f"è³‡æ–™ç¼ºå°‘é—œéµæ¬„ä½: {missing_cols}")
        
    df = df.rename(columns=col_mapping)
    df = df[required_raw_cols].copy()
    
    # æ—¥æœŸè½‰æ›
    df['æ—¥æœŸ'] = df['æ—¥æœŸ'].astype(str).apply(convert_roc_to_gregorian)
    df = df.dropna(subset=['æ—¥æœŸ']).copy()
    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], format='%Y/%m/%d', errors='coerce')
    df = df.dropna(subset=['æ—¥æœŸ']).copy()
    
    # æ•¸å€¼æ¬„ä½æ¸…ç†
    for col in required_raw_cols:
        if col == 'æ—¥æœŸ':
            continue
            
        df[col] = df[col].astype(str).str.replace('ï¼Œ', ',', regex=False).str.replace('ï¼', '-', regex=False)
        df[col] = df[col].astype(str).str.replace(r'[^0-9\.\-]', '', regex=True)
        df[col] = df[col].replace({'': pd.NA, 'nan': pd.NA, 'NaN': pd.NA})
        df[col] = pd.to_numeric(df[col], errors='coerce')
        
    # ç¢ºä¿åƒ¹æ ¼æ¬„ä½ä¸æ˜¯ NaN (é€™æ˜¯è¨ˆç®—æŠ€è¡“æŒ‡æ¨™çš„åŸºç¤)
    df = df.dropna(subset=price_cols).copy() 
    
    return df[required_raw_cols].copy()

def calculate_moving_averages(df, close_col='æ”¶ç›¤åƒ¹'):
    """è¨ˆç®— MA5, MA10, MA20ã€‚"""
    df['MA5'] = df[close_col].rolling(window=5, min_periods=1).mean().round(2)
    df['MA10'] = df[close_col].rolling(window=10, min_periods=1).mean().round(2)
    df['MA20'] = df[close_col].rolling(window=20, min_periods=1).mean().round(2)
    return df

def calculate_macd(df, close_col='æ”¶ç›¤åƒ¹', short=12, long=26, signal=9):
    """è¨ˆç®— MACD ä¸‰é …æŒ‡æ¨™ (DIF, DEA, OSC)ã€‚"""
    df['EMA_12'] = df[close_col].ewm(span=short, adjust=False).mean()
    df['EMA_26'] = df[close_col].ewm(span=long, adjust=False).mean()
    df['DIF'] = df['EMA_12'] - df['EMA_26']
    df['DEA'] = df['DIF'].ewm(span=signal, adjust=False).mean()
    df['OSC'] = df['DIF'] - df['DEA']
    
    df.drop(columns=['EMA_12', 'EMA_26'], inplace=True, errors='ignore')
    return df
    
def calculate_kdj(df, n=9, m1=3, m2=3, high_col='æœ€é«˜åƒ¹', low_col='æœ€ä½åƒ¹', close_col='æ”¶ç›¤åƒ¹'):
    """è¨ˆç®— KDJ ä¸‰é …æŒ‡æ¨™ (K, D, J)ã€‚"""
    # 1. è¨ˆç®— N æ—¥å…§çš„æœ€é«˜åƒ¹ (HHV) å’Œæœ€ä½åƒ¹ (LLV)
    df['LLV'] = df[low_col].rolling(window=n, min_periods=1).min()
    df['HHV'] = df[high_col].rolling(window=n, min_periods=1).max()

    # 2. è¨ˆç®— RSV (æœªæˆç†Ÿéš¨æ©Ÿå€¼)
    denominator = df['HHV'] - df['LLV']
    df['RSV'] = ((df[close_col] - df['LLV']) / denominator)
    df['RSV'] = df['RSV'].replace([float('inf'), -float('inf')], 1).fillna(0) * 100
    df['RSV'] = df['RSV'].clip(0, 100) 

    # 3. è¨ˆç®— K ç·šå’Œ D ç·š (ä½¿ç”¨ç¶“å…¸å¹³æ»‘ç§»å‹•å¹³å‡æ³•)
    k_list = []
    d_list = []
    
    k_prev = 50.0 # åˆå§‹å€¼
    d_prev = 50.0 # åˆå§‹å€¼
    
    rsv_values = df['RSV'].values
    m1_float = float(m1)
    m2_float = float(m2)
    
    for rsv in rsv_values:
        # K = (M1-1)/M1 * K_prev + 1/M1 * RSV_current
        k_curr = (k_prev * (m1_float - 1) + rsv) / m1_float
        
        # D = (M2-1)/M2 * D_prev + 1/M2 * K_current
        d_curr = (d_prev * (m2_float - 1) + k_curr) / m2_float
        
        k_list.append(round(k_curr, 2))
        d_list.append(round(d_curr, 2))
        
        k_prev = k_curr
        d_prev = d_curr

    df['K'] = k_list
    df['D'] = d_list
    
    # 4. è¨ˆç®— J ç·š
    df['J'] = (3 * df['K'] - 2 * df['D']).round(2)

    # åˆªé™¤è¨ˆç®—ä¸­é–“éç¨‹æ¬„ä½
    df.drop(columns=['LLV', 'HHV', 'RSV'], inplace=True, errors='ignore')
    return df

def calculate_rsi(df, periods, close_col='æ”¶ç›¤åƒ¹'):
    """è¨ˆç®— RSI æŒ‡æ¨™åŠ RSI_DIF (RSI5 - RSI10)ã€‚"""
    # è¨ˆç®—åƒ¹æ ¼è®ŠåŒ–
    df['Change'] = df[close_col].diff()
    
    # åˆ†é›¢ä¸Šæ¼² (Gain) å’Œä¸‹è·Œ (Loss)
    df['Gain'] = df['Change'].apply(lambda x: x if x > 0 else 0).round(2)
    df['Loss'] = df['Change'].apply(lambda x: abs(x) if x < 0 else 0).round(2)
    
    for period in periods:
        # ä½¿ç”¨ ewm (æŒ‡æ•¸ç§»å‹•å¹³å‡) é€²è¡Œå¹³æ»‘
        avg_gain = df['Gain'].ewm(span=period, adjust=False).mean()
        avg_loss = df['Loss'].ewm(span=period, adjust=False).mean()
        
        # è¨ˆç®— RS (ç›¸å°å¼·åº¦)ï¼Œé¿å…é™¤ä»¥é›¶
        rs = avg_gain / avg_loss.replace(0, 1e-10) 
        
        # è¨ˆç®— RSI
        rsi = 100 - (100 / (1 + rs))
        df[f'RSI{period}'] = rsi.round(2)

    # åˆªé™¤ä¸­é–“è¨ˆç®—éç¨‹æ¬„ä½
    df.drop(columns=['Change', 'Gain', 'Loss'], inplace=True, errors='ignore')
    
    # è¨ˆç®— RSI_DIF = RSI5 - RSI10
    if 'RSI5' in df.columns and 'RSI10' in df.columns:
        df['RSI_DIF'] = (df['RSI5'] - df['RSI10']).round(2)
    else:
        print("âš ï¸ è­¦å‘Šï¼šç¼ºå°‘ RSI5 æˆ– RSI10 æ¬„ä½ï¼ŒRSI_DIF è¨ˆç®—å¤±æ•—ã€‚")

    return df

def calculate_volume_moving_averages(df, volume_col='æˆäº¤è‚¡æ•¸', periods=VOL_PERIODS):
    """è¨ˆç®—æˆäº¤è‚¡æ•¸çš„ç§»å‹•å¹³å‡ (VOL5, VOL10)ã€‚"""
    for period in periods:
        # æˆäº¤é‡ç§»å‹•å¹³å‡é€šå¸¸å–æ•´æ•¸
        df[f'VOL{period}'] = df[volume_col].rolling(window=period, min_periods=1).mean().round(0)
    return df

def filter_recent_data(df, days=90):
    """å¾ DataFrame ä¸­ç¯©é¸å‡ºæœ€è¿‘ N å¤©çš„æ•¸æ“šã€‚"""
    if df.empty:
        return df
    latest_date = df['æ—¥æœŸ'].max()
    start_date = latest_date - timedelta(days=days) 
    final_df = df[df['æ—¥æœŸ'] >= start_date].copy() 
    return final_df

def output_to_csv(df, output_path, raw_cols):
    """å°‡ DataFrame è¼¸å‡ºç‚º CSV æª”æ¡ˆ (big5 ç·¨ç¢¼)ã€‚"""
    # å°‡æ—¥æœŸæ ¼å¼åŒ–ç‚ºå­—ä¸²
    df['æ—¥æœŸ'] = df['æ—¥æœŸ'].dt.strftime('%Y/%m/%d')
    df = df.rename(columns={'æ—¥æœŸ': 'æ—¥æœŸ_str'})
    
    # ç¢ºå®šè¼¸å‡ºçš„æ¬„ä½é †åºï¼šæ—¥æœŸ_str + æ‰€æœ‰åŸå§‹æ¬„ä½ (æ’é™¤æ—¥æœŸ) + æŠ€è¡“æŒ‡æ¨™
    tech_cols = ['MA5', 'MA10', 'MA20', 'DIF', 'DEA', 'OSC', 'K', 'D', 'J', 'RSI5', 'RSI10', 'RSI_DIF', 'VOL5', 'VOL10']
    
    output_cols = ['æ—¥æœŸ_str'] + [col for col in raw_cols if col != 'æ—¥æœŸ'] + tech_cols
    
    df_output = df.reindex(columns=output_cols).copy()
    
    try:
        df_output.to_csv(output_path, index=False, encoding='big5')
        print(f"âœ… å·²è¼¸å‡º CSVï¼ˆbig5ï¼ŒåŒ…å«æ‰€æœ‰åŸå§‹æ¬„ä½/MA/MACD/KDJ/RSI/VOLï¼‰åˆ°ï¼š{output_path}")
        return True
    except Exception as e:
        print(f"âŒ è¼¸å‡º CSV å¤±æ•—: {e}")
        return False

# -----------------------------------------------------------
# ã€ğŸŒŸ æœ€çµ‚ä¿®æ­£å¾Œçš„ç¹ªåœ–å‡½å¼ï¼šåŠ å…¥å…¨è¢å¹•/æœ€å¤§åŒ–é¡¯ç¤ºé‚è¼¯ & ç§»é™¤ VOL ç§‘å­¸è¨˜è™Ÿã€‘
# -----------------------------------------------------------
def plot_charts_four_panels(df, code, name, output_dir):
    """
    ç¹ªè£½ K ç·šåœ–ã€MACDã€KDJã€RSIã€VOL çš„ 5x1 åœ–è¡¨ã€‚
    - VOL åœ–ï¼šVOL5/VOL10 æ›²ç·š + æˆäº¤è‚¡æ•¸æŸ±ç‹€åœ– (é¡è‰²ä¾æ¼²è·Œåƒ¹å·®æ±ºå®š)ã€‚
    - ç§»é™¤ VOL åœ– Y è»¸çš„ç§‘å­¸è¨˜è™Ÿ (1e8)ã€‚
    - åœ–è¡¨åœ¨ plt.show() æ™‚ï¼Œè¦–çª—å˜—è©¦æœ€å¤§åŒ–ã€‚
    """
    if df.empty:
        print("âŒ ç¹ªåœ–å¤±æ•—ï¼šæ•¸æ“šä¸è¶³ã€‚")
        return

    # 1. æº–å‚™ mplfinance K ç·šåœ–è³‡æ–™
    df_ohlc = df.rename(columns={'é–‹ç›¤åƒ¹': 'Open', 'æœ€é«˜åƒ¹': 'High', 'æœ€ä½åƒ¹': 'Low', 'æ”¶ç›¤åƒ¹': 'Close'}).set_index('æ—¥æœŸ').copy()
    required_cols = ['DIF', 'DEA', 'OSC', 'K', 'D', 'J', 'RSI5', 'RSI10', 'VOL5', 'VOL10', 'æˆäº¤è‚¡æ•¸', 'æ¼²è·Œåƒ¹å·®']
    df_tech = df_ohlc.dropna(subset=[col for col in required_cols if col in df_ohlc.columns]).copy()
    
    if df_tech.empty:
        print("âŒ ç¹ªåœ–å¤±æ•—ï¼šæ•¸æ“šä¸è¶³ä»¥ç¹ªè£½æŠ€è¡“æŒ‡æ¨™åœ–è¡¨ã€‚")
        return
        
    # --- å­—é«”è¨­å®š ---
    try:
        plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'Microsoft YaHei', 'SimHei', 'Apple LiGothic', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False 
    except Exception:
        pass

    # --- ç¹ªåœ–æ¨£å¼ ---
    mc = mpf.make_marketcolors(up='r', down='g', edge='inherit', wick='inherit', inherit=True)
    style = mpf.make_mpf_style(base_mpf_style='yahoo', marketcolors=mc)
    
    # --- å‰µå»º Figure å’Œ Axes (5x1 ä½ˆå±€) ---
    fig, axes = plt.subplots(5, 1, figsize=(16, 22), 
                             gridspec_kw={'height_ratios': [3, 1, 1, 1, 1]}) 
    
    fig.subplots_adjust(left=0.06, right=0.97, top=0.94, bottom=0.04, hspace=0.3)
    
    ax_kline = axes[0] 
    ax_macd = axes[1]  
    ax_kdj = axes[2]   
    ax_rsi = axes[3]   
    ax_vol = axes[4]   
    
    start_date = df_ohlc.index.min().date()
    end_date = df_ohlc.index.max().date()
    fig.suptitle(f'{code} ({name}) æŠ€è¡“åˆ†æç¸½è¦½ ({start_date} ~ {end_date})', fontsize=20, y=0.98)
    
    # --- 1. K ç·šåœ– (ç¬¬ä¸€è¡Œ) ---
    mpf.plot(
        df_ohlc, 
        ax=ax_kline, 
        type='candle', 
        mav=MAV_PERIODS, 
        mavcolors=MAV_COLORS_LIST, 
        volume=False, 
        style=style,
        ylabel='è‚¡åƒ¹ (TWD)',
        xrotation=0,
        show_nontrading=False,
        datetime_format='%Y/%m/%d',
    )
    
    legend_handles = []
    ma_labels = [f'MA{p}' for p in MAV_PERIODS]
    for color, label in zip(MAV_COLORS_LIST, ma_labels):
        legend_handles.append(plt.Line2D([0], [0], color=color, linewidth=1.5, label=label))
    
    ax_kline.legend(handles=legend_handles, loc='upper left', fontsize=10) 
    ax_kline.set_title('1. è‚¡åƒ¹ K ç·šåœ–èˆ‡ç§»å‹•å¹³å‡ç·š (MA)', fontsize=14, loc='left')
    ax_kline.set_xlabel('')
    
    # --- 2. MACD æŒ‡æ¨™åœ– (ç¬¬äºŒè¡Œ) ---
    ax_macd.plot(df_tech.index, df_tech['DIF'], color='blue', linewidth=1.5, label='DIF (å·®é›¢å€¼)')
    ax_macd.plot(df_tech.index, df_tech['DEA'], color='orange', linewidth=1.5, label='DEA (è¨Šè™Ÿç·š)')
    osc_colors = ['r' if val >= 0 else 'g' for val in df_tech['OSC']]
    ax_macd.bar(df_tech.index, df_tech['OSC'], color=osc_colors, alpha=0.6, label='OSC (æŸ±)') 
    
    ax_macd.set_title('2. MACD æŒ‡æ¨™ (DIF, DEA, OSC)', fontsize=14, loc='left')
    ax_macd.axhline(0, color='gray', linestyle='--', linewidth=1) 
    ax_macd.legend(loc='upper left', fontsize=10) 
    ax_macd.grid(True, linestyle='--', alpha=0.6)
    ax_macd.set_xlabel('')

    # --- 3. KDJ æŒ‡æ¨™ç·šåœ– (ç¬¬ä¸‰è¡Œ) ---
    ax_kdj.plot(df_tech.index, df_tech['K'], color='red', linewidth=1.5, label='K ç·š')
    ax_kdj.plot(df_tech.index, df_tech['D'], color='green', linewidth=1.5, label='D ç·š')
    ax_kdj.plot(df_tech.index, df_tech['J'], color='blue', linewidth=1.5, label='J ç·š')
    
    ax_kdj.set_title('3. éš¨æ©ŸæŒ‡æ¨™ KDJ ç·šåœ–', fontsize=14, loc='left')
    ax_kdj.axhline(80, color='red', linestyle=':', linewidth=1) 
    ax_kdj.axhline(20, color='green', linestyle=':', linewidth=1) 
    ax_kdj.set_ylim(0, 100) 
    ax_kdj.legend(loc='upper left', fontsize=10) 
    ax_kdj.grid(True, linestyle='--', alpha=0.6)
    ax_kdj.set_xlabel('') 

    # --- 4. RSI æŒ‡æ¨™ç·šåœ– (ç¬¬å››è¡Œ) ---
    ax_rsi.plot(df_tech.index, df_tech['RSI5'], color='darkorange', linewidth=1.5, label='RSI5')
    ax_rsi.plot(df_tech.index, df_tech['RSI10'], color='purple', linewidth=1.5, label='RSI10')
    
    ax_rsi.set_title('4. ç›¸å°å¼·å¼±æŒ‡æ¨™ RSI ç·šåœ–', fontsize=14, loc='left')
    ax_rsi.axhline(70, color='red', linestyle=':', linewidth=1) 
    ax_rsi.axhline(30, color='green', linestyle=':', linewidth=1) 
    ax_rsi.set_ylim(0, 100) 
    ax_rsi.legend(loc='upper left', fontsize=10) 
    ax_rsi.grid(True, linestyle='--', alpha=0.6)
    ax_rsi.set_xlabel('') 
    
    # --- 5. VOL æˆäº¤é‡åœ– (ç¬¬äº”è¡Œ) ---
    vol_colors = ['r' if val > 0 else 'g' for val in df_tech['æ¼²è·Œåƒ¹å·®']]
    
    ax_vol.bar(df_tech.index, df_tech['æˆäº¤è‚¡æ•¸'], color=vol_colors, alpha=0.6, label='æˆäº¤è‚¡æ•¸ (VOL)')
    
    ax_vol_curve = ax_vol.twinx()
    ax_vol_curve.plot(df_tech.index, df_tech['VOL5'], color='yellow', linewidth=1.5, label='VOL5')
    ax_vol_curve.plot(df_tech.index, df_tech['VOL10'], color='orange', linewidth=1.5, label='VOL10')
    
    ax_vol.set_title('5. æˆäº¤é‡æŒ‡æ¨™ (VOL5/VOL10 æ›²ç·šèˆ‡æˆäº¤è‚¡æ•¸æŸ±ç‹€åœ–)', fontsize=14, loc='left')
    
    # ğŸŒŸ æ ¸å¿ƒä¿®æ­£ 1ï¼šç§»é™¤ä¸» Y è»¸ (å·¦å´ï¼Œæˆäº¤è‚¡æ•¸) çš„ç§‘å­¸è¨˜è™Ÿ
    ax_vol.ticklabel_format(style='plain', axis='y') 
    
    # ğŸŒŸ æ ¸å¿ƒä¿®æ­£ 2ï¼šç§»é™¤æ¬¡ Y è»¸ (å³å´ï¼ŒVOL5/10) çš„ç§‘å­¸è¨˜è™Ÿ
    ax_vol_curve.ticklabel_format(style='plain', axis='y')
    
    handles1, labels1 = ax_vol.get_legend_handles_labels()
    handles2, labels2 = ax_vol_curve.get_legend_handles_labels()
    ax_vol.legend(handles1 + handles2, labels1 + labels2, loc='upper left', fontsize=10) 
    
    ax_vol.grid(True, linestyle='--', alpha=0.6)
    ax_vol.set_xlabel('æ—¥æœŸ', fontsize=12) 

    # --- çµ±ä¸€è™•ç† X è»¸ï¼šéš±è—å‰å››å¼µåœ–çš„ X è»¸åˆ»åº¦å’Œæ¨™ç±¤ ---
    for i in range(len(axes) - 1): 
        axes[i].tick_params(axis='x', labelbottom=False) 
        
    ax_vol.tick_params(axis='x', rotation=0) 
    ax_vol.xaxis.set_major_locator(plt.MaxNLocator(10))

    # --- å„²å­˜èˆ‡é¡¯ç¤º ---
    chart_filename = f"{code}_{name}_KLine_5Panel_90Days.png"
    save_path = output_dir / chart_filename
    try:
        fig.savefig(save_path)
        print(f"ğŸ“ˆ æ•´åˆåœ–è¡¨ (5 åœ–é¢æ¿) å·²å„²å­˜åˆ°ï¼š{save_path}")
    except Exception as e:
        print(f"âŒ æ•´åˆåœ–è¡¨å„²å­˜å¤±æ•—: {e}")
        
    # æ ¸å¿ƒä¿®æ”¹å€ï¼šå˜—è©¦æœ€å¤§åŒ–é¡¯ç¤ºè¦–çª—
    try:
        fig_manager = plt.get_current_fig_manager()
        
        # 1. å˜—è©¦é‡å°ä¸åŒå¾Œç«¯é€²è¡Œæœ€å¤§åŒ– (æ”¯æ´ TkAgg, QtAgg ç­‰)
        try:
            # é©ç”¨æ–¼ TkAgg å¾Œç«¯ (Windows/Linux ä¸Šå¸¸è¦‹)
            fig_manager.window.state('zoomed') 
            print("è¦–çª—å·²å˜—è©¦æœ€å¤§åŒ– (TkAgg æ¨¡å¼)ã€‚")
        except AttributeError:
            try:
                # é©ç”¨æ–¼ QtAgg/MacOSX ç­‰å¾Œç«¯
                fig_manager.frame.Maximize(True)
                print("è¦–çª—å·²å˜—è©¦æœ€å¤§åŒ– (Qt/Wx æ¨¡å¼)ã€‚")
            except AttributeError:
                # å›é€€åˆ°è¨­å®šä¸€å€‹è¼ƒå¤§çš„å°ºå¯¸ï¼Œä»¥é”åˆ°æ¥è¿‘å…¨è¢å¹•çš„æ•ˆæœ
                target_width = 1600
                target_height = 1200
                start_x = 0 
                start_y = 0
                geometry_string = f"{target_width}x{target_height}+{start_x}+{start_y}"
                fig_manager.window.wm_geometry(geometry_string)
                print("è¦–çª—æœ€å¤§åŒ–åŠŸèƒ½å¤±æ•—ï¼Œå·²å›é€€è¨­ç½®ç‚ºè¼ƒå¤§å°ºå¯¸ã€‚")
        except Exception as e:
            print(f"âš ï¸ è¦–çª—æœ€å¤§åŒ–åŠŸèƒ½å¤±æ•—ï¼ŒåŸå› : {e}")
            
        plt.show()
    except Exception as e:
        print(f"âŒ é¡¯ç¤ºåœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

# -----------------------------
# ä¸»æµç¨‹ï¼šæµç¨‹æ‰å¹³åŒ– (ä¿æŒä¸è®Š)
# -----------------------------
def main():
    # 0. æª¢æŸ¥è³‡æ–™å¤¾ä¸¦ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    if not INPUT_DIR.exists():
        print(f"âŒ æŒ‡å®šçš„åŸå§‹è³‡æ–™å¤¾ä¸å­˜åœ¨ï¼š{INPUT_DIR}")
        return
    
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True) 
    
    file_list = sorted([p for p in INPUT_DIR.iterdir() if p.suffix.lower() == '.csv'])
    if not file_list:
        print("âš ï¸ è³‡æ–™å¤¾å…§æ²’æœ‰ csv æª”æ¡ˆã€‚")
        return

    # 1. è®€å–ã€æ¸…ç†å–®å€‹æª”æ¡ˆä¸¦æ”¶é›†
    all_data_frames = []
    for filepath in file_list:
        print(f"\n--- è™•ç†æª”æ¡ˆ: {filepath.name} ---")
        df_raw, used_encoding = try_read_csv(filepath, ENCODINGS_TO_TRY)
        if df_raw is None:
            continue
        print(f"    ä½¿ç”¨ç·¨ç¢¼: {used_encoding}")
        try:
            df_clean = clean_dataframe(df_raw, RAW_COL_NAMES, PRICE_COLS) 
            all_data_frames.append(df_clean)
        except Exception as e:
            print(f"âŒ æª”æ¡ˆ {filepath.name} æ¸…ç†å¤±æ•—: {e}")
            continue

    if not all_data_frames:
        print("\nâš ï¸ éŒ¯èª¤ï¼šæ²’æœ‰å¯ç”¨çš„è³‡æ–™ã€‚")
        return

    # 2. åˆä½µã€æ’åºèˆ‡å»é‡ (å…¨é‡æ•¸æ“š)
    combined_df = pd.concat(all_data_frames, ignore_index=True)
    combined_df = combined_df.drop_duplicates(subset=['æ—¥æœŸ']).copy()
    combined_df = combined_df.sort_values(by='æ—¥æœŸ', ascending=True).reset_index(drop=True)
    full_combined_df = combined_df.copy()
    print("\n--- è³‡æ–™åˆä½µèˆ‡æ’åºå®Œæˆ ---")
    print(f"å…¨é‡è³‡æ–™å€é–“: {full_combined_df['æ—¥æœŸ'].min().date()} ~ {full_combined_df['æ—¥æœŸ'].max().date()}ï¼Œå…± {len(full_combined_df)} ç­†")

    # 3. è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ (MA/MACD/KDJ/RSI/VOL)
    full_combined_df = calculate_moving_averages(full_combined_df, close_col='æ”¶ç›¤åƒ¹')
    full_combined_df = calculate_macd(
        full_combined_df, 
        close_col='æ”¶ç›¤åƒ¹', 
        short=SHORT_WINDOW, 
        long=LONG_WINDOW, 
        signal=SIGNAL_WINDOW
    )
    full_combined_df = calculate_kdj(
        full_combined_df,
        n=KDJ_N,
        m1=KDJ_M1,
        m2=KDJ_M2
    )
    full_combined_df = calculate_rsi(
        full_combined_df,
        periods=RSI_PERIODS
    )
    full_combined_df = calculate_volume_moving_averages(
        full_combined_df,
        volume_col='æˆäº¤è‚¡æ•¸',
        periods=VOL_PERIODS
    )
    print("--- MA/MACD/KDJ/RSI/VOL è¨ˆç®—å®Œæˆ ---")

    # 4. ç¯©é¸ï¼šåªä¿ç•™æœ€è¿‘ 90 å¤©ï¼ˆä¸‰å€‹æœˆï¼‰çš„è³‡æ–™ç”¨æ–¼ç¹ªåœ– (CSV è¼¸å‡ºä½¿ç”¨å…¨é‡)
    final_df = filter_recent_data(full_combined_df, days=90)
    
    if final_df.empty:
        print(f"\nâŒ éŒ¯èª¤ï¼šç¯©é¸å¾Œæ²’æœ‰è³‡æ–™ã€‚")
        output_to_csv(full_combined_df.copy(), OUTPUT_PATH, RAW_COL_NAMES) 
        return
    print(f"\n--- æœ€çµ‚åˆ†æç¯„åœç¯©é¸å®Œæˆ ---")
    print(f"ç¯©é¸å¾Œæ—¥æœŸå€é–“: {final_df['æ—¥æœŸ'].min().date()} ~ {final_df['æ—¥æœŸ'].max().date()}ï¼Œå…± {len(final_df)} ç­†")


    # 5. è¼¸å‡º CSV (ä½¿ç”¨æ‰€æœ‰åŸå§‹æ¬„ä½å’Œå…¨é‡æ•¸æ“š)
    output_to_csv(full_combined_df.copy(), OUTPUT_PATH, RAW_COL_NAMES) 

    # 6. ç¹ªåœ–ï¼šæ•´åˆ K ç·šã€MACDã€KDJã€RSIã€VOL æŒ‡æ¨™åœ–è¡¨ (ä½¿ç”¨ 90 å¤©è³‡æ–™)
    plot_charts_four_panels(final_df.copy(), STOCK_CODE, STOCK_NAME, OUTPUT_DIR)
        
    print("\nğŸ‰ ä»»å‹™å®Œæˆã€‚")

# åŸ·è¡Œ
if __name__ == '__main__':
    main()