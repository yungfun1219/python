import pandas as pd
import requests
import io
import os
from typing import Optional

# [ ... fetch_and_combine_stock_data_v2 å‡½å¼çš„å…§å®¹ä¿æŒä¸è®Š ... ] 
# ç‚ºäº†é¿å…å†—é•·ï¼Œé€™è£¡çœç•¥å‡½å¼ä¸»é«”ï¼Œå‡è¨­æ‚¨ä½¿ç”¨ä¸Šä¸€å€‹å›è¦†ä¸­å·²ä¿®æ­£çš„ V2 ç¨‹å¼ç¢¼ã€‚

def fetch_and_combine_stock_data_v2(
    stock_no: str, 
    trade_date: str, 
    bwibbu_date: str
) -> Optional[pd.DataFrame]:
    """
    å¾å°ç£è­‰åˆ¸äº¤æ˜“æ‰€æŠ“å–ç‰¹å®šè‚¡ç¥¨çš„æ¯æ—¥æˆäº¤è³‡è¨Šï¼Œä¸¦èˆ‡ BWIBBU è³‡æ–™åˆä½µï¼Œ
    ä¸¦æŒ‰ç…§æŒ‡å®šé †åºé‡æ–°æ’åˆ—æ¬„ä½ã€‚(æ­¤è™•ä½¿ç”¨ä¸Šä¸€å€‹å›è¦†ä¸­å·²ä¿®æ­£çš„ç¨‹å¼ç¢¼)
    """
    
    # ç¢ºä¿ required_bwibbu_cols åœ¨ä»»ä½•æƒ…æ³ä¸‹éƒ½å·²å®šç¾©ï¼Œè§£æ±º UnboundLocalError
    required_bwibbu_cols = ['è­‰åˆ¸ä»£è™Ÿ', 'è­‰åˆ¸åç¨±', 'æ”¶ç›¤åƒ¹(BWIBBU)', 'æ®–åˆ©ç‡(%)', 'è‚¡åˆ©å¹´åº¦', 'æœ¬ç›Šæ¯”', 'è‚¡åƒ¹æ·¨å€¼æ¯”', 'è²¡å ±å¹´/å­£']
    bwibbu_target = pd.DataFrame(columns=required_bwibbu_cols)
    
    # 1. æŠ“å–æ¯æ—¥æˆäº¤è³‡è¨Š (STOCK_DAY)
    stock_day_url = f"https://www.twse.com.tw/exchangeReport/STOCK_DAY?response=html&date={trade_date}&stockNo={stock_no}"
    print(f"-> æ­£åœ¨æŠ“å–è‚¡ç¥¨ {stock_no} æ–¼ {trade_date} çš„æ¯æ—¥æˆäº¤è³‡è¨Š...")
    
    try:
        stock_dfs = pd.read_html(stock_day_url)
        daily_trade_df = stock_dfs[0]
        
        # æ•¸æ“šæ¸…æ´—ï¼šè¨­å®šæ­£ç¢ºçš„æ¬„ä½åç¨±
        daily_trade_df.columns = daily_trade_df.iloc[0] 
        daily_trade_df = daily_trade_df[1:].copy() 
        
        # é‡æ–°å‘½åæ¬„ä½
        daily_trade_df.rename(columns={
            'æ—¥æœŸ': 'äº¤æ˜“æ—¥æœŸ', 
            'æˆäº¤è‚¡æ•¸': 'è‚¡æ•¸(å¼µ)'
        }, inplace=True)
        
        # æ¸…ç†å­—ä¸²æ•¸æ“šä¸­çš„é€—è™Ÿ
        for col in daily_trade_df.columns:
            if daily_trade_df[col].dtype == 'object':
                daily_trade_df[col] = daily_trade_df[col].astype(str).str.replace(',', '', regex=False)
                
        print("-> æ¯æ—¥æˆäº¤è³‡è¨ŠæŠ“å–å®Œæˆã€‚")
        
    except Exception as e:
        print(f"Error fetching STOCK_DAY data: {e}")
        return None

    # 2. æŠ“å– BWIBBU è³‡æ–™
    bwibbu_url = f"https://www.twse.com.tw/exchangeReport/BWIBBU_d?response=html&date={bwibbu_date}&selectType=ALL"
    print(f"-> æ­£åœ¨æŠ“å– BWIBBU æ–¼ {bwibbu_date} çš„é¡è‚¡å ±é…¬ç‡è³‡è¨Š...")
    
    try:
        bwibbu_dfs = pd.read_html(bwibbu_url)
        bwibbu_df = bwibbu_dfs[0]
        
        # æ•¸æ“šæ¸…æ´—ï¼šè™•ç†å…©å±¤ Header
        new_columns = [col[1] for col in bwibbu_df.columns]
        bwibbu_df.columns = new_columns
        
        # é‡æ–°å‘½åä¸¦ç¯©é¸ç›®æ¨™è‚¡ç¥¨
        bwibbu_df.rename(columns={
            bwibbu_df.columns[0]: 'è­‰åˆ¸ä»£è™Ÿ', 
            bwibbu_df.columns[1]: 'è­‰åˆ¸åç¨±',
            'æ”¶ç›¤åƒ¹': 'æ”¶ç›¤åƒ¹(BWIBBU)'
        }, inplace=True)
        
        # ç¯©é¸ç›®æ¨™è‚¡ç¥¨
        filtered_bwibbu = bwibbu_df[bwibbu_df['è­‰åˆ¸ä»£è™Ÿ'] == stock_no]
        
        if not filtered_bwibbu.empty:
            # åªæœ‰ç•¶ç¯©é¸çµæœéç©ºæ™‚ï¼Œæ‰å–ç¬¬ä¸€è¡Œ
            bwibbu_target = filtered_bwibbu.iloc[[0]].copy()
        else:
            print(f"Warning: BWIBBU è³‡æ–™ä¸­æ‰¾ä¸åˆ°è‚¡ç¥¨ {stock_no} çš„è³‡è¨Šã€‚")

        # ç¢ºä¿ BWIBBU ç›¸é—œæ¬„ä½éƒ½å­˜åœ¨
        for col in required_bwibbu_cols:
            if col not in bwibbu_target.columns:
                bwibbu_target[col] = None

        bwibbu_target = bwibbu_target[required_bwibbu_cols] 
        
        print("-> BWIBBU è³‡è¨ŠæŠ“å–å®Œæˆã€‚")
        
    except Exception as e:
        print(f"Error fetching BWIBBU data: {e}")
        pass 


    # 3. åˆä½µè³‡æ–™ (Cross Join)
    print("-> æ­£åœ¨åˆä½µè³‡æ–™...")
    
    if not bwibbu_target.empty:
        # æå–è‚¡ç¥¨åç¨±ï¼Œä»¥ä¾›å¾ŒçºŒä½¿ç”¨
        stock_name = bwibbu_target['è­‰åˆ¸åç¨±'].iloc[0] if 'è­‰åˆ¸åç¨±' in bwibbu_target.columns else stock_no
        
        bwibbu_data_to_append = bwibbu_target.drop(columns=['è­‰åˆ¸ä»£è™Ÿ']).iloc[0]
        
        rows_to_append = [bwibbu_data_to_append.to_dict()] * len(daily_trade_df)
        bwibbu_merged_df = pd.DataFrame(rows_to_append, index=daily_trade_df.index)
        
        daily_trade_df.insert(0, 'è­‰åˆ¸ä»£è™Ÿ', stock_no) 
        
        final_df = pd.concat([daily_trade_df, bwibbu_merged_df], axis=1)
    else:
        print(f"Warning: BWIBBU è³‡æ–™ç‚ºç©ºï¼Œåƒ…å›å‚³æ¯æ—¥æˆäº¤è³‡è¨Šã€‚")
        stock_name = stock_no # å¦‚æœæ‰¾ä¸åˆ°åç¨±ï¼Œå°±ç”¨ä»£è™Ÿ
        final_df = daily_trade_df.rename(columns={'äº¤æ˜“æ—¥æœŸ': 'æ—¥æœŸ', 'è‚¡æ•¸(å¼µ)': 'æˆäº¤è‚¡æ•¸'})
        final_df.insert(0, 'è­‰åˆ¸ä»£è™Ÿ', stock_no)


    # 4. é‡æ–°æ’åˆ—æ¬„ä½é †åº
    if 'æ”¶ç›¤åƒ¹' in final_df.columns and 'æ”¶ç›¤åƒ¹(BWIBBU)' in final_df.columns:
        final_df.rename(columns={'æ”¶ç›¤åƒ¹': 'æ”¶ç›¤åƒ¹_STOCK_DAY'}, inplace=True)
        final_df.rename(columns={'æ”¶ç›¤åƒ¹(BWIBBU)': 'æ”¶ç›¤åƒ¹_BWIBBU'}, inplace=True)
    
    final_target_columns = [
        'äº¤æ˜“æ—¥æœŸ', 'è‚¡æ•¸(å¼µ)', 'æˆäº¤é‡‘é¡', 'é–‹ç›¤åƒ¹', 'æœ€é«˜åƒ¹', 'æœ€ä½åƒ¹', 
        'æ”¶ç›¤åƒ¹_STOCK_DAY', 'æ¼²è·Œåƒ¹å·®', 'æˆäº¤ç­†æ•¸', 'è­‰åˆ¸ä»£è™Ÿ', 'è­‰åˆ¸åç¨±', 
        'æ”¶ç›¤åƒ¹_BWIBBU', 'æ®–åˆ©ç‡(%)', 'è‚¡åˆ©å¹´åº¦', 'æœ¬ç›Šæ¯”', 
        'è‚¡åƒ¹æ·¨å€¼æ¯”', 'è²¡å ±å¹´/å­£'
    ]
    
    existing_final_cols = [col for col in final_target_columns if col in final_df.columns]
    final_df = final_df[existing_final_cols]
    
    final_df.rename(columns={
        'äº¤æ˜“æ—¥æœŸ': 'æ—¥æœŸ', 
        'è‚¡æ•¸(å¼µ)': 'æˆäº¤è‚¡æ•¸',
        'è­‰åˆ¸ä»£è™Ÿ': 'åˆ¸ä»£è™Ÿ',
        'æ”¶ç›¤åƒ¹_STOCK_DAY': 'æ”¶ç›¤åƒ¹',
        'æ”¶ç›¤åƒ¹_BWIBBU': 'æ”¶ç›¤åƒ¹'
    }, inplace=True)

    print("-> è³‡æ–™åˆä½µåŠæ¬„ä½æ•´ç†å®Œæˆï¼")
    # å°‡è‚¡ç¥¨åç¨±ä¸€ä½µå›å‚³ï¼Œä»¥ä¾¿åœ¨ä¸»ç¨‹å¼ä¸­ç”¨ä¾†å‘½åæª”æ¡ˆ
    return final_df, stock_name


# --- åŸ·è¡Œèˆ‡è¼¸å‡ºç¯„ä¾‹ (å·²ä¿®æ­£æª”å) ---
# è¨­å®šåƒæ•¸
stock = '1101'
trade_d = '20250101'
bwibbu_d = '20250108'

# å‘¼å«å‡½å¼ï¼Œæ¥æ”¶æ•¸æ“šå’Œè‚¡ç¥¨åç¨±
result = fetch_and_combine_stock_data_v2(stock, trade_d, bwibbu_d)

if result is not None:
    combined_data, stock_name = result
    
    if not combined_data.empty:
        # ğŸ¯ ä¾æ“šæ‚¨çš„è¦æ±‚ï¼Œå›ºå®šè¼¸å‡ºæª”åæ ¼å¼ç‚ºï¼š[è‚¡ç¥¨ä»£è™Ÿ]_[è‚¡ç¥¨åç¨±]_stock.csv
        # é€™è£¡å°‡ 'å°æ³¥' ä½œç‚ºç¯„ä¾‹åç¨±ï¼Œå¦‚æœæ‚¨å¸Œæœ›ç¨‹å¼ç¢¼æ›´è‡ªå‹•åŒ–ï¼Œ
        # å‰‡æ‡‰ä½¿ç”¨ BWIBBU æŠ“å–åˆ°çš„ 'è­‰åˆ¸åç¨±' è®Šæ•¸ (å·²åœ¨å‡½å¼å…§éƒ¨è™•ç†)ã€‚
        # ç”±æ–¼æ‚¨æ˜ç¢ºæŒ‡å®š '1101_å°æ³¥_stock.csv'ï¼Œæˆ‘å€‘ä½¿ç”¨è©²å›ºå®šåç¨±ã€‚
        output_filename = f'{stock}_{stock_name}_stock.csv' # e.g., '1101_å°æ³¥_stock.csv'
        
        # è¼¸å‡º CSV æª”æ¡ˆ
        combined_data.to_csv(output_filename, index=False, encoding='utf-8-sig')

        print("\n" + "="*50)
        print(f"âœ… è‚¡ç¥¨åˆ†ææ•¸æ“šå·²æˆåŠŸè¼¸å‡ºè‡³æª”æ¡ˆ: {output_filename}")
        print("\n[æª”æ¡ˆå…§å®¹é è¦½ (å‰ 5 ç­†è³‡æ–™)]")
        print(combined_data.head().to_markdown(index=False))
        print("="*50)
    else:
        print("\n[åŸ·è¡Œå¤±æ•—] æ•¸æ“šè¡¨ç‚ºç©ºã€‚")
else:
    print("\n[åŸ·è¡Œå¤±æ•—] ç„¡æ³•å–å¾—æ¯æ—¥æˆäº¤è³‡è¨Šã€‚è«‹æª¢æŸ¥ç¶²è·¯é€£ç·šæˆ–è‚¡ç¥¨ä»£è™Ÿæ˜¯å¦æ­£ç¢ºã€‚")
