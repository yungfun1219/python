import pandas as pd
import pathlib
import re
from typing import Union, List, Tuple
from datetime import date, datetime, time, timedelta
import os

# --- åƒæ•¸è¨­å®š ---
# è‚¡ç¥¨è³‡æ–™æª”æ¡ˆçš„è·¯å¾‘åŸºç¤
BASE_STOCK_DATA_PATH = pathlib.Path(r"D:\Python_repo\python\Jason_Stock_Analyzer\datas\raw\20251114_T86_InstitutionalTrades.csv")
FILE_NAME_TEMPLATE = "_{}_T86_InstitutionalTrades.csv" # æª”æ¡ˆåç¨±æ¨¡æ¿
VOLUME_COL = "ä¸‰å¤§æ³•äººè²·è³£è¶…è‚¡æ•¸"
CODE_COL = "è­‰åˆ¸ä»£è™Ÿ"
N_DAYS = 5
TRADING_DAY_FILE = pathlib.Path(__file__).resolve().parent / "datas" / "processed" / "get_holidays" / "trading_day_2021-2025.csv"

# --- è¼”åŠ©å‡½å¼ï¼šå–å¾—æœ€è¿‘ N å€‹äº¤æ˜“æ—¥ ---
# ä¿æŒæ‚¨åŸæœ‰çš„å‡½å¼é‚è¼¯ï¼Œä½†ç‚ºäº†æ•´åˆï¼Œæˆ‘å€‘è®“å®ƒç›´æ¥è¿”å›æ—¥æœŸæ¸…å–®
def find_last_n_trading_days_with_time_check(file_path: pathlib.Path, n: int = 5) -> Union[List[str], None]:
    """
    å¾äº¤æ˜“æ—¥æª”æ¡ˆä¸­ï¼Œæ‰¾å‡ºä»Šå¤©å¾€å‰æ•¸ N å€‹äº¤æ˜“æ—¥ï¼Œä¸¦æ ¹æ“šç•¶å‰æ™‚é–“ (15:00) åˆ¤æ–·æ˜¯å¦ç´å…¥ä»Šå¤©ã€‚
    :return: åŒ…å«æœ€è¿‘ N å€‹äº¤æ˜“æ—¥æ—¥æœŸå­—ä¸² (YYYY/MM/DD) çš„æ¸…å–®ï¼Œæˆ– Noneã€‚
    """
    now = datetime.now()
    today_date = now.date()
    cutoff_time = time(15, 0, 0)
    is_after_cutoff = now.time() >= cutoff_time

    print(f"ç•¶å‰æ—¥æœŸ: {today_date.strftime('%Y/%m/%d')}, ç•¶å‰æ™‚é–“æ˜¯å¦åœ¨ 15:00 ä¹‹å¾Œ: {is_after_cutoff}")
    
    try:
        df = pd.read_csv(file_path, encoding='utf-8')
    except Exception as e:
        print(f"âŒ éŒ¯èª¤ï¼šç„¡æ³•è®€å–äº¤æ˜“æ—¥æª”æ¡ˆ {file_path}: {e}")
        return None

    date_column = 'æ—¥æœŸ' 
    if date_column not in df.columns and 'Date' in df.columns:
        date_column = 'Date'
    elif date_column not in df.columns:
        print(f"âŒ éŒ¯èª¤ï¼šäº¤æ˜“æ—¥æª”æ¡ˆä¸­æ‰¾ä¸åˆ°æ—¥æœŸæ¬„ä½ã€‚")
        return None
        
    df[date_column] = pd.to_datetime(df[date_column], errors='coerce').dt.normalize()
    df.dropna(subset=[date_column], inplace=True)
    all_trading_dates = set(df[date_column].dt.date)
    is_today_trading_day = today_date in all_trading_dates
    
    print(f"ä»Šå¤© ({today_date.strftime('%Y/%m/%d')}) æ˜¯å¦ç‚ºäº¤æ˜“æ—¥: {is_today_trading_day}")

    inclusion_date = today_date - timedelta(days=1)
    
    if is_today_trading_day and is_after_cutoff:
        inclusion_date = today_date
        print("-> åˆ¤æ–·ï¼šç´å…¥ä»Šå¤©çš„äº¤æ˜“æ—¥ã€‚")
    else:
        inclusion_date = today_date - timedelta(days=1)
        print("-> åˆ¤æ–·ï¼šæ’é™¤ä»Šå¤©çš„äº¤æ˜“æ—¥ï¼Œåªå–æ˜¨å¤©åŠæ›´æ—©çš„æ—¥æœŸã€‚")

    df_past = df[df[date_column].dt.date <= inclusion_date]
    df_past = df_past.sort_values(by=date_column, ascending=False)
    last_n_days = df_past.head(n)

    if last_n_days.empty:
        print(f"âš ï¸ è­¦å‘Šï¼šäº¤æ˜“æ—¥è³‡æ–™ä¸è¶³ï¼Œç„¡æ³•æ‰¾åˆ°å¾€å‰ {n} å€‹äº¤æ˜“æ—¥ã€‚")
        return None

    # è¿”å› YYYY/MM/DD æ ¼å¼çš„æ¸…å–®
    date_list = last_n_days[date_column].dt.strftime('%Y/%m/%d').tolist()
    
    print(f"\nâœ… æˆåŠŸæ‰¾åˆ°ä»Šå¤©å¾€å‰ {n} å€‹äº¤æ˜“æ—¥ã€‚")
    return date_list

# --- æ ¸å¿ƒç¯©é¸å‡½å¼ (èˆ‡å‰ç‰ˆç›¸åŒï¼Œç”¨æ–¼è®€å– T86 æª”æ¡ˆ) ---
def find_positive_institutional_trades(file_path: pathlib.Path, volume_col: str, code_col: str) -> pd.DataFrame:
    """è®€å–ã€æ¸…æ´—ä¸¦æ‰¾å‡ºè²·è¶…ä¸”ä»£è™Ÿç‚º 4 ç¢¼çš„è‚¡ç¥¨ã€‚"""
    
    try:
        try:
            df = pd.read_csv(file_path, encoding='big5')
        except UnicodeDecodeError:
             df = pd.read_csv(file_path, encoding='utf-8')
    except FileNotFoundError:
        return pd.DataFrame()
    except Exception:
        return pd.DataFrame()

    required_cols = [volume_col, code_col, 'è­‰åˆ¸åç¨±']
    if not all(col in df.columns for col in required_cols):
        return pd.DataFrame()

    try:
        df[volume_col] = df[volume_col].astype(str).str.replace('"', '', regex=False).str.replace(',', '', regex=False).str.strip()
        df[volume_col] = pd.to_numeric(df[volume_col], errors='coerce')
        df[code_col] = df[code_col].astype(str).str.strip()
        df.dropna(subset=[volume_col], inplace=True)
    except Exception:
        return pd.DataFrame()

    # 1. ç¯©é¸ä»£è™Ÿç‚º 4 ç¢¼æ•¸å­—
    df_filtered_code = df[df[code_col].str.match(r'^\d{4}$')]
    if df_filtered_code.empty:
        return pd.DataFrame()

    # 2. ç¯©é¸è²·è¶… > 0
    df_positive = df_filtered_code[df_filtered_code[volume_col] > 0].copy()
    if df_positive.empty:
        return pd.DataFrame()
        
    # 3. æ’åº
    df_sorted = df_positive.sort_values(by=volume_col, ascending=False)
    
    return df_sorted

# --- ä¸»æ§å‡½æ•¸ï¼šæŸ¥è©¢å¤šæ—¥è³‡æ–™ ---
def main_get_recent_buy_in_data() -> str:
    """
    æŸ¥è©¢æœ€è¿‘ N å€‹äº¤æ˜“æ—¥çš„è²·è¶…å‰ 30 åè‚¡ç¥¨ï¼Œä¸¦å½™æ•´æˆæ¸…å–®å­—ä¸²ã€‚
    """
    final_report = "ğŸ“ˆ è¿‘æœŸä¸‰å¤§æ³•äººè²·è¶…æ¸…å–® (å‰ {} å)ï¼š\n\n".format(N_DAYS * 30)
    all_dates_data = []
    
    # 1. å–å¾—æœ€è¿‘ N å€‹äº¤æ˜“æ—¥æ¸…å–®
    recent_dates = find_last_n_trading_days_with_time_check(TRADING_DAY_FILE, N_DAYS)
    
    if recent_dates is None:
        return "âŒ éŒ¯èª¤ï¼šç„¡æ³•å–å¾—æœ€è¿‘äº¤æ˜“æ—¥æ¸…å–®ï¼Œè«‹æª¢æŸ¥ trading_day æª”æ¡ˆè·¯å¾‘å’Œå…§å®¹ã€‚"
    
    # å°‡æ—¥æœŸç”±èˆŠåˆ°æ–°æ’åº (é›–ç„¶ find_last_n_trading_days_with_time_check å·²ç¶“é€™æ¨£åšäº†)
    recent_dates.sort() 
    
    # 2. è¿­ä»£æ¯å€‹æ—¥æœŸï¼Œé€²è¡Œè‚¡ç¥¨ç¯©é¸
    for date_str_slash in recent_dates:
        # å°‡ YYYY/MM/DD è½‰æ›ç‚º YYYYMMDD æ§‹é€ æª”å
        date_str_clean = date_str_slash.replace('/', '')
        file_name = date_str_clean + FILE_NAME_TEMPLATE.format(date_str_clean)
        file_path = BASE_STOCK_DATA_PATH / file_name
        
        print(f"\nè™•ç†æª”æ¡ˆ: {file_path.name}")
        
        # å‘¼å«æ ¸å¿ƒç¯©é¸å‡½å¼
        buy_in_df = find_positive_institutional_trades(file_path, VOLUME_COL, CODE_COL)
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æ•¸æ“š
        if buy_in_df.empty:
            all_dates_data.append(f"----- ã€æ—¥æœŸ: {date_str_slash}ã€‘ âŒ ç„¡è²·è¶…æˆ–æª”æ¡ˆéºå¤± -----\n")
            continue

        # 3. å–å‡ºå‰ 30 åæ•¸æ“š
        TOTAL_STOCKS_TO_DISPLAY = 30
        top_30_display = buy_in_df.head(TOTAL_STOCKS_TO_DISPLAY).copy()
        
        # 4. æ ¼å¼åŒ–è¼¸å‡º
        
        top_30_display['è²·è¶…å¼µæ•¸'] = top_30_display[VOLUME_COL].apply(
            lambda x: f"{int(x/1000):,}"
        )
        
        # æ§‹é€ å–®æ—¥å ±å‘Šæ¨™é¡Œ
        report_title = f"----- ã€æ—¥æœŸ: {date_str_slash}ã€‘ è²·è¶…å‰ {len(top_30_display)} å -----\n"
        
        # æ§‹é€ æ¸…å–®å­—ä¸² (ä»£è™Ÿ | è­‰åˆ¸åç¨± | è²·è¶…å¼µæ•¸)
        daily_list = ""
        for _, rol in top_30_display.iterrows():
            code = rol[CODE_COL]
            # ç¢ºä¿åç¨±è¢«æ¸…ç†å’Œå¡«å……
            name = rol['è­‰åˆ¸åç¨±'].strip().ljust(8) 
            volume = rol['è²·è¶…å¼µæ•¸']
            
            daily_list += f"{code} | {name} | ({volume}å¼µ)\n"

        all_dates_data.append(report_title + daily_list)

    # 5. å½™ç¸½æ‰€æœ‰æ—¥æœŸçš„å ±å‘Š
    final_report += "\n".join(all_dates_data)
    final_report += "\n\n=== å ±å‘ŠçµæŸ ==="
    
    return final_report

# --- åŸ·è¡Œä¸»å‡½æ•¸ä¸¦è¼¸å‡ºçµæœ ---
if __name__ == "__main__":
    report = main_get_recent_buy_in_data()
    print(report)