import requests
import pandas as pd
from io import StringIO
import urllib3
import re
from datetime import date, datetime
from typing import Optional, Tuple, List
from pathlib import Path
import os
import utils.jason_utils as jutils
import get_stocks_company_all 
import time
import pathlib

# æŠ‘åˆ¶ç•¶ verify=False æ™‚å½ˆå‡ºçš„ InsecureRequestWarning è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ==========================================================
# åƒæ•¸è¨­å®š  --- é…ç½® (Configuration) ---
# ==========================================================
LOG_FETCH_DATE_FILENAME = "last_get_date.log" # å®šç¾©è¨˜éŒ„ä¸Šæ¬¡æˆåŠŸæŠ“å–æ—¥æœŸçš„æ—¥èªŒæª”æ¡ˆåç¨±
SUMMARY_LOG_FILENAME_PREFIX = "fetch_summary" # å®šç¾©æ‘˜è¦æ—¥èªŒæª”æ¡ˆå‰ç¶´

def get_past_dates_in_yyyymmdd(file_path, date_column_name='æ—¥æœŸ'):
    """
    è®€å– CSV æª”æ¡ˆï¼Œç¯©é¸å‡ºåœ¨ä»Šå¤©æˆ–ä»Šå¤©ä¹‹å‰çš„æ‰€æœ‰æ—¥æœŸï¼Œä¸¦ä»¥ YYYYMMDD å­—ä¸²æ ¼å¼è¿”å›ã€‚

    Args:
        file_path (str): CSV æª”æ¡ˆçš„è·¯å¾‘ã€‚
        date_column_name (str): CSV ä¸­åŒ…å«æ—¥æœŸçš„æ¬„ä½åç¨±ã€‚é è¨­ç‚º 'Date'ã€‚

    Returns:
        list: åŒ…å«æ‰€æœ‰éå»æ—¥æœŸçš„ YYYYMMDD æ ¼å¼å­—ä¸²åˆ—è¡¨ï¼Œå¦‚æœå‡ºéŒ¯å‰‡è¿”å›ç©ºåˆ—è¡¨ã€‚
    """
    try:
        # 1. è®€å– CSV æª”æ¡ˆ
        df = pd.read_csv(file_path)

        # 2. ç¢ºä¿æ—¥æœŸæ¬„ä½æ˜¯ datetime æ ¼å¼
        # errors='coerce' æœƒå°‡ç„¡æ³•è§£æçš„å€¼è¨­ç‚º NaT
        df[date_column_name] = pd.to_datetime(df[date_column_name], errors='coerce')

        # 3. ç²å–ä»Šå¤©çš„æ—¥æœŸ (åªå–å¹´æœˆæ—¥éƒ¨åˆ†)
        # ä»Šå¤©çš„æ—¥æœŸç‚º 2025-11-01
        today = pd.to_datetime(datetime.now().date()) 
        
        # 4. ç¯©é¸å‡ºä»Šå¤©ä¹‹å‰ (å³ <= ä»Šå¤©) çš„æ—¥æœŸè³‡æ–™
        # ç¯©é¸æ¢ä»¶æ˜¯ï¼šæ—¥æœŸæ¬„ä½å€¼ <= ä»Šå¤©çš„æ—¥æœŸ
        past_dates_df = df[df[date_column_name] <= today]

        # 5. ç§»é™¤æ—¥æœŸç‚º NaT çš„åˆ—
        past_dates_df = past_dates_df.dropna(subset=[date_column_name])
        
        # 6. æ’åº (å¯é¸ï¼Œé€šå¸¸æ—¥æœŸè³‡æ–™æŒ‰æ™‚é–“é †åºæ’åˆ—è¼ƒå¥½)
        past_dates_df = past_dates_df.sort_values(by=date_column_name)
        
        # 7. **ã€é—œéµã€‘æ ¼å¼åŒ–ä¸¦è¿”å›æ—¥æœŸåˆ—è¡¨**
        # ä½¿ç”¨ .dt.strftime('%Y%m%d') å°‡ datetime ç‰©ä»¶è½‰æ›ç‚º YYYYMMDD æ ¼å¼çš„å­—ä¸²
        yyyymmdd_list = past_dates_df[date_column_name].dt.strftime('%Y%m%d').tolist()
        
        return yyyymmdd_list

    except FileNotFoundError:
        print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æª”æ¡ˆåœ¨è·¯å¾‘ï¼š{file_path}")
        return []
    except KeyError:
        print(f"éŒ¯èª¤ï¼šCSV æª”æ¡ˆä¸­æ‰¾ä¸åˆ°åç‚º '{date_column_name}' çš„æ—¥æœŸæ¬„ä½ã€‚")
        return []
    except Exception as e:
        print(f"ç™¼ç”Ÿå…¶ä»–éŒ¯èª¤ï¼š{e}")
        return []

# æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨ä¸”ç¢ºå¯¦æ˜¯ä¸€å€‹æª”æ¡ˆ (éè³‡æ–™å¤¾)
def check_folder_and_create(folder_path: str):
    """
    åƒæ•¸:
        file_path (str): è¦æª¢æŸ¥çš„æª”æ¡ˆè·¯å¾‘ã€‚
    å›å‚³:
        bool: æª”æ¡ˆå­˜åœ¨æ™‚å›å‚³ Trueï¼›å¦å‰‡å›å‚³ Falseã€‚
    """
    OUTPUT_DIR, filename_new = jutils.get_path_to_folder_file(folder_path)
    jutils.check_and_create_folder(OUTPUT_DIR)
    jutils.check_file_exists(filename_new)
    return True

# å…±ç”¨çš„è¼”åŠ©å‡½å¼ï¼Œç”¨æ–¼è™•ç† TWSE çš„ Big5 ç·¨ç¢¼å’Œ Pandas è®€å–é‚è¼¯ã€‚
def _read_twse_csv(response_text: str, header_row: int) -> Optional[pd.DataFrame]:
    """
    Args:
        response_text: HTTP è«‹æ±‚å›å‚³çš„æ–‡å­—å…§å®¹ (Big5 ç·¨ç¢¼)ã€‚
        header_row: CSV æª”æ¡ˆä¸­è³‡æ–™è¡¨é ­æ‰€åœ¨çš„è¡Œæ•¸ (0-indexed)ã€‚
    Returns:
        Optional[pd.DataFrame]: è™•ç†å¾Œçš„ DataFrameã€‚
    """
    try:
        csv_data = StringIO(response_text)
        # å˜—è©¦è®€å– CSV
        df = pd.read_csv(
            csv_data, 
            header=header_row,          # è³‡æ–™è¡¨é ­æ‰€åœ¨çš„è¡Œæ•¸
            skipinitialspace=True,      # è·³éåˆ†éš”ç¬¦å¾Œçš„ç©ºæ ¼
            on_bad_lines='skip',        # è·³éæ ¼å¼ä¸æ­£ç¢ºçš„è¡Œ
            encoding='Big5'             # ä½¿ç”¨ Big5 ç·¨ç¢¼è®€å–
        )
        # TWSE çš„ CSV æ¬„ä½åç¨±å¸¸æœ‰éš±è—ç©ºæ ¼ï¼Œå°è‡´ df.columns ç„¡æ³•æ­£ç¢ºåŒ¹é…ã€‚
        if not df.empty:
            df.columns = df.columns.str.strip()
        # ç§»é™¤æ‰€æœ‰æ¬„ä½çš†ç‚ºç©ºçš„è¡Œ
        df = df.dropna(how='all')
        # ç§»é™¤è³‡æ–™å°¾éƒ¨å¯èƒ½å‡ºç¾çš„å½™ç¸½æˆ–å‚™è¨»è¡Œ
        if not df.empty and df.iloc[-1].astype(str).str.contains('åˆè¨ˆ|ç¸½è¨ˆ|å‚™è¨»', na=False).any():
            df = df.iloc[:-1]
        return df
    except Exception as e:
        print(f"åœ¨è®€å–æˆ–æ¸…ç† CSV æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

        return None

# å…±ç”¨çš„è¼”åŠ©å‡½å¼ï¼Œç”¨æ–¼ç™¼é€ HTTP è«‹æ±‚ä¸¦æª¢æŸ¥ç‹€æ…‹ã€‚
def _fetch_twse_data(url: str) -> Optional[str]:
    """
    Args:
        url: å®Œæ•´çš„ TWSE è³‡æ–™ URLã€‚
    Returns:
        Optional[str]: æˆåŠŸç²å–å¾Œï¼Œä»¥ Big5 è§£ç¢¼çš„æ–‡å­—å…§å®¹ã€‚
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    try:
        response = requests.get(url, headers=headers, verify=False, timeout=10)
        response.raise_for_status() 
        response.encoding = 'Big5'
        return response.text
    except requests.exceptions.HTTPError as errh:
        print(f"âŒ HTTP éŒ¯èª¤ï¼š{errh} (è©²æ—¥å¯èƒ½ç„¡äº¤æ˜“è³‡æ–™)")
    except requests.exceptions.RequestException as err:
        print(f"âŒ é€£ç·šæˆ– Requests éŒ¯èª¤: {err}")
    except Exception as e:
        print(f"âŒ ç™¼ç”Ÿå…¶ä»–éŒ¯èª¤: {e}")

    return None

# å°‡æ‰€æœ‰å ±å‘Šçš„æŠ“å–çµæœæ‘˜è¦å¯«å…¥æ—¥èªŒæª”æ¡ˆï¼Œä¸¦åŒæ™‚åˆ—å°åˆ°æ§åˆ¶å°ã€‚
def log_summary_results(results: List[Tuple[str, Optional[pd.DataFrame]]], fetch_date: str, summary_filename_prefix: str = SUMMARY_LOG_FILENAME_PREFIX):
    BASE_DIR = Path(os.path.dirname(os.path.abspath(__file__)))
    OUTPUT_DIR = BASE_DIR / "datas" / "logs"

    # ç¢ºä¿æ—¥èªŒè³‡æ–™å¤¾å­˜åœ¨
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    log_file_name = f"{summary_filename_prefix}_{fetch_date}.log"
    filename_new = OUTPUT_DIR / log_file_name 
    
    # å»ºç«‹æ‘˜è¦å…§å®¹å­—ä¸²
    summary_lines = []
    
    header = "\n" + "="*50 + "\n"
    header += f"--- {fetch_date} å ±å‘ŠæŠ“å–çµæœæ‘˜è¦ ---\n"
    header += "="*50
    summary_lines.append(header)
    
    success_count = 0
    fail_count = 0

    for name, df in results:
        if df is not None:
            line = f"\n[ğŸŸ¢ {name} (æˆåŠŸ)] æ•¸æ“šç­†æ•¸: {len(df)}"
            success_count += 1
        else:
            line = f"[ğŸ”´ {name} (å¤±æ•—)] ç„¡æ•¸æ“šæˆ–æŠ“å–éŒ¯èª¤ã€‚"
            fail_count += 1
        summary_lines.append(line)

    footer = "\n" + "="*50
    footer += f"\nç¸½çµï¼šæˆåŠŸ {success_count} å€‹å ±å‘Š, å¤±æ•— {fail_count} å€‹å ±å‘Šã€‚"
    footer += "\næ‰€æœ‰æˆåŠŸæŠ“å–çš„ CSV æª”æ¡ˆå·²å„²å­˜è‡³å°æ‡‰çš„ 'datas/raw' å­è³‡æ–™å¤¾ä¸­ã€‚"
    footer += "\n--- æ—¥èªŒè¨˜éŒ„çµæŸ ---\n"
    
    summary_lines.append(footer)
    
    log_content = "\n".join(summary_lines)

    # å¯«å…¥æ—¥èªŒæª”æ¡ˆ
    try:
        with open(filename_new, 'w', encoding='utf-8') as f:
            f.write(log_content)
        
        # åŒæ™‚åˆ—å°åˆ°æ§åˆ¶å°
        print(log_content)
        print(f"[æ—¥èªŒ] æˆåŠŸå°‡æ‘˜è¦çµæœå¯«å…¥æª”æ¡ˆï¼š{filename_new}")
    except Exception as e:
        print(f"âŒ å¯«å…¥æ‘˜è¦æ—¥èªŒæª”æ¡ˆç™¼ç”ŸéŒ¯èª¤: {e}")

# --- 10 å¤§ TWSE å ±å‘ŠæŠ“å–å‡½å¼ (åˆ†é èˆ‡å€‹è‚¡) ---
def fetch_twse_stock_day(target_date: str, stock_no: str) -> Optional[pd.DataFrame]:
    """
    (1/10) æŠ“å–æŒ‡å®šæ—¥æœŸå’Œè‚¡ç¥¨ä»£è™Ÿçš„ STOCK_DAY å ±å‘Š (æ¯æ—¥æˆäº¤è³‡è¨Š)ã€‚
    URL: https://www.twse.com.tw/rwd/zh/afterTrading/STOCK_DAY
    """
    if not re.fullmatch(r'\d{8}', target_date): return None
    base_url = "https://www.twse.com.tw/rwd/zh/afterTrading/STOCK_DAY"
    url = f"{base_url}?date={target_date}&stockNo={stock_no}&response=csv"

    OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "1_STOCK_DAY")
    filename = OUTPUT_DIR + f"\\{target_date}_{stock_no}_STOCK_DAY.csv"

    check_folder_and_create(filename)

    print(f"å˜—è©¦æŠ“å– (1/10) {stock_no} STOCK_DAY è³‡æ–™...")
    response_text = _fetch_twse_data(url)
    
    if response_text is None: return None
    
    df = _read_twse_csv(response_text, header_row=1)
    if df is not None and 'æ—¥æœŸ' in df.columns:
        df = df[df['æ—¥æœŸ'].astype(str).str.strip() != '']
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… (1/10) {filename} å„²å­˜æˆåŠŸã€‚")
        return df
    return None

def fetch_twse_mi_index(target_date: str) -> Optional[pd.DataFrame]:
    """
    (2/10) æŠ“å–æŒ‡å®šæ—¥æœŸçš„ MI_INDEX å ±å‘Š (æ‰€æœ‰é¡è‚¡æˆäº¤çµ±è¨ˆ)ã€‚
    URL: https://www.twse.com.tw/rwd/zh/afterTrading/MI_INDEX
    """
    if not re.fullmatch(r'\d{8}', target_date): return None
    base_url = "https://www.twse.com.tw/rwd/zh/afterTrading/MI_INDEX"
    url = f"{base_url}?date={target_date}&type=ALLBUT0999&response=csv"
    OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "2_MI_INDEX")
    filename = OUTPUT_DIR + f"\\{target_date}_MI_INDEX_Sector.csv"

    check_folder_and_create(filename)
    
    print(f"å˜—è©¦æŠ“å– (2/10) MI_INDEX (é¡è‚¡çµ±è¨ˆ) è³‡æ–™...")
    response_text = _fetch_twse_data(url)
    if response_text is None: return None

    # MI_INDEX å ±è¡¨çš„è¡¨é ­åœ¨ç´¢å¼• 3
    df = _read_twse_csv(response_text, header_row=1)

    if df is not None and 'æŒ‡æ•¸' in df.columns:
        df = df[df['æŒ‡æ•¸'].astype(str).str.strip() != '']
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… (2/10) {filename} å„²å­˜æˆåŠŸã€‚")
        return df
    return None

def fetch_twse_bwibbu_d(target_date: str) -> Optional[pd.DataFrame]:
    """
    (3/10) æŠ“å–æŒ‡å®šæ—¥æœŸçš„ BWIBBU_d å ±å‘Š (ç™¼è¡Œé‡åŠ æ¬Šè‚¡åƒ¹æŒ‡æ•¸é¡è‚¡æ—¥æˆäº¤é‡å€¼åŠå ±é…¬ç‡)ã€‚
    URL: https://www.twse.com.tw/rwd/zh/afterTrading/BWIBBU_d
    """
    if not re.fullmatch(r'\d{8}', target_date): return None
    base_url = "https://www.twse.com.tw/rwd/zh/afterTrading/BWIBBU_d"
    url = f"{base_url}?date={target_date}&selectType=ALL&response=csv"
    
    OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "3_BWIBBU_d")
    filename = OUTPUT_DIR + f"\\{target_date}_BWIBBU_d_IndexReturn.csv"

    check_folder_and_create(filename)
        
    print(f"å˜—è©¦æŠ“å– (3/10) BWIBBU_d (é¡è‚¡å ±é…¬ç‡) è³‡æ–™...")
    response_text = _fetch_twse_data(url)
    if response_text is None: return None

    # BWIBBU_d å ±è¡¨çš„è¡¨é ­åœ¨ç´¢å¼• 3
    df = _read_twse_csv(response_text, header_row=1)

    if df is not None and 'è­‰åˆ¸ä»£è™Ÿ' in df.columns:
        df = df[df['è­‰åˆ¸ä»£è™Ÿ'].astype(str).str.strip() != '']
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… (3/10) {filename} å„²å­˜æˆåŠŸã€‚")
        return df
    return None

def fetch_twse_mi_index20(target_date: str) -> Optional[pd.DataFrame]:
    """
    (4/10) æŠ“å–æŒ‡å®šæ—¥æœŸçš„ MI_INDEX20 å ±å‘Š (æ”¶ç›¤æŒ‡æ•¸åŠæˆäº¤é‡å€¼è³‡è¨Š)ã€‚
    URL: https://www.twse.com.tw/rwd/zh/afterTrading/MI_INDEX20
    
    **ä¿®æ­£:** è¡¨é ­ç´¢å¼•æ”¹ç‚º 2 (åŸç‚º 1)ã€‚
    """
    if not re.fullmatch(r'\d{8}', target_date): return None
    base_url = "https://www.twse.com.tw/rwd/zh/afterTrading/MI_INDEX20"
    url = f"{base_url}?date={target_date}&response=csv"
        
    OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "4_MI_INDEX20")
    filename = OUTPUT_DIR + f"\\{target_date}_MI_INDEX20_Market.csv"
    
    check_folder_and_create(filename)
    
    print(f"å˜—è©¦æŠ“å– (4/10) MI_INDEX20 è³‡æ–™...")
    response_text = _fetch_twse_data(url)
    if response_text is None: return None
    
    # MI_INDEX20 å ±è¡¨çš„è¡¨é ­åœ¨ç´¢å¼• 2
    df = _read_twse_csv(response_text, header_row=1)

    if df is not None and 'è­‰åˆ¸ä»£è™Ÿ' in df.columns:
        df = df[df['è­‰åˆ¸ä»£è™Ÿ'].astype(str).str.strip() != '']
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… (4/10) {filename} å„²å­˜æˆåŠŸã€‚")
        return df
    return None

def fetch_twse_twtasu(target_date: str) -> Optional[pd.DataFrame]:
    """
    (5/10) æŠ“å–æŒ‡å®šæ—¥æœŸçš„ TWTASU å ±å‘Š (æ¯æ—¥ç¸½æˆäº¤é‡å€¼èˆ‡å¹³å‡è‚¡åƒ¹)ã€‚
    URL: https://www.twse.com.tw/rwd/zh/afterTrading/TWTASU
    
    """
    if not re.fullmatch(r'\d{8}', target_date): return None
    base_url = "https://www.twse.com.tw/rwd/zh/afterTrading/TWTASU"
    url = f"{base_url}?date={target_date}&response=csv"
    
    OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "5_TWTASU")
    filename = OUTPUT_DIR + f"\\{target_date}_TWTASU_VolumePrice.csv"

    check_folder_and_create(filename)
    
    print(f"å˜—è©¦æŠ“å– (5/10) TWTASU (ç¸½é‡å€¼) è³‡æ–™...")
    response_text = _fetch_twse_data(url)
    if response_text is None: return None

    # TWTASU å ±è¡¨çš„è¡¨é ­åœ¨ç´¢å¼• 3
    df = _read_twse_csv(response_text, header_row=2)
   
    if df is not None and 'è­‰åˆ¸åç¨±' in df.columns: 
        df = df[df['è­‰åˆ¸åç¨±'].astype(str).str.strip() != '']
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… (5/10) {filename} å„²å­˜æˆåŠŸã€‚")
        return df
    return None

def fetch_twse_bfiamu(target_date: str) -> Optional[pd.DataFrame]:
    """
    (6/10) æŠ“å–æŒ‡å®šæ—¥æœŸçš„ BFIAMU å ±å‘Š (è‡ªç‡Ÿå•†è²·è³£è¶…å½™ç¸½è¡¨)ã€‚
    URL: https://www.twse.com.tw/rwd/zh/afterTrading/BFIAMU
    
    **ä¿®æ­£:** è¡¨é ­ç´¢å¼•æ”¹ç‚º 3 (åŸç‚º 2)ã€‚
    """
    if not re.fullmatch(r'\d{8}', target_date): return None
    base_url = "https://www.twse.com.tw/rwd/zh/afterTrading/BFIAMU"
    url = f"{base_url}?date={target_date}&response=csv"
    
    OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "6_BFIAMU")
    filename = OUTPUT_DIR + f"\\{target_date}_BFIAMU_DealerTrade.csv"

    check_folder_and_create(filename)
    
    print(f"å˜—è©¦æŠ“å– (6/10) BFIAMU (è‡ªç‡Ÿå•†è²·è³£è¶…) è³‡æ–™...")
    response_text = _fetch_twse_data(url)
    if response_text is None: return None

    # BFIAMU å ±è¡¨çš„è¡¨é ­åœ¨ç´¢å¼• 3
    df = _read_twse_csv(response_text, header_row=1)

    if df is not None and 'åˆ†é¡æŒ‡æ•¸åç¨±' in df.columns:
        df = df.dropna(how='all') 
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… (6/10) {filename} å„²å­˜æˆåŠŸã€‚")
        return df
    return None

def fetch_twse_fmtqik(target_date: str) -> Optional[pd.DataFrame]:
    """
    (7/10) æŠ“å–æŒ‡å®šæ—¥æœŸçš„ FMTQIK å ±å‘Š (æ¯æ—¥åˆ¸å•†æˆäº¤é‡å€¼ç¸½è¡¨)ã€‚
    URL: https://www.twse.com.tw/rwd/zh/afterTrading/FMTQIK
    
    """
    if not re.fullmatch(r'\d{8}', target_date): return None
    base_url = "https://www.twse.com.tw/rwd/zh/afterTrading/FMTQIK"
    url = f"{base_url}?date={target_date}&response=csv"
    
    OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "7_FMTQIK")
    filename = OUTPUT_DIR + f"\\{target_date}_FMTQIK_BrokerVolume.csv"

    check_folder_and_create(filename)
    
    print(f"å˜—è©¦æŠ“å– (7/10) FMTQIK (åˆ¸å•†æˆäº¤ç¸½è¡¨) è³‡æ–™...")
    response_text = _fetch_twse_data(url)
    if response_text is None: return None

    # FMTQIK å ±è¡¨çš„è¡¨é ­åœ¨ç´¢å¼• 2
    df = _read_twse_csv(response_text, header_row=1)

    if df is not None and 'æ—¥æœŸ' in df.columns:
        df = df[df['æ—¥æœŸ'].astype(str).str.strip() != '']
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… (7/10) {filename} å„²å­˜æˆåŠŸã€‚")
        return df
    return None

def fetch_twse_bfi82u(target_date: str) -> Optional[pd.DataFrame]:
    """
    (8/10) æŠ“å–æŒ‡å®šæ—¥æœŸçš„ BFI82U å ±å‘Š (ä¸‰å¤§æ³•äººè²·è³£è¶…å½™ç¸½è¡¨ - æ—¥)ã€‚
    URL: https://www.twse.com.tw/rwd/zh/fund/BFI82U
    
    """
    if not re.fullmatch(r'\d{8}', target_date): return None
    base_url = "https://www.twse.com.tw/rwd/zh/fund/BFI82U"
    # åªä½¿ç”¨ dayDate é€²è¡Œæ—¥æœŸåƒæ•¸æ¨¡çµ„åŒ–
    url = f"{base_url}?type=day&dayDate={target_date}&response=csv"
        
    OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "8_BFI82U")
    filename = OUTPUT_DIR + f"\\{target_date}_BFI82U_3IParty_Day.csv"

    check_folder_and_create(filename)
    
    print(f"å˜—è©¦æŠ“å– (8/10) BFI82U (ä¸‰å¤§æ³•äººæ—¥å ±) è³‡æ–™...")
    response_text = _fetch_twse_data(url)
    if response_text is None: return None

    # BFI82U å ±è¡¨çš„è¡¨é ­åœ¨ç´¢å¼• 3
    df = _read_twse_csv(response_text, header_row=1)

    if df is not None and 'å–®ä½åç¨±' in df.columns:
        df = df[df['å–®ä½åç¨±'].astype(str).str.strip() != '']
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… (8/10) {filename} å„²å­˜æˆåŠŸã€‚")
        return df
    return None

def fetch_twse_twt43u(target_date: str) -> Optional[pd.DataFrame]:
    """
    (9/10) æŠ“å–æŒ‡å®šæ—¥æœŸçš„ TWT43U å ±å‘Š (å¤–è³‡åŠé™¸è³‡è²·è³£è¶…å½™ç¸½è¡¨)ã€‚
    URL: https://www.twse.com.tw/rwd/zh/fund/TWT43U
    
    """
    if not re.fullmatch(r'\d{8}', target_date): return None
    base_url = "https://www.twse.com.tw/rwd/zh/fund/TWT43U"
    url = f"{base_url}?date={target_date}&response=csv"

    OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "9_TWT43U")
    filename = OUTPUT_DIR + f"\\{target_date}_TWT43U_ForeignTrade.csv"

    check_folder_and_create(filename)
    
    print(f"å˜—è©¦æŠ“å– (9/10) TWT43U (å¤–è³‡è²·è³£è¶…) è³‡æ–™...")
    response_text = _fetch_twse_data(url)
    if response_text is None: return None

    # TWT43U å ±è¡¨çš„è¡¨é ­åœ¨ç´¢å¼• 3
    df = _read_twse_csv(response_text, header_row=2)

    if df is not None and 'è­‰åˆ¸ä»£è™Ÿ' in df.columns:
        df = df[df['è­‰åˆ¸ä»£è™Ÿ'].astype(str).str.strip() != '']
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… (9/10) {filename} å„²å­˜æˆåŠŸã€‚")
        return df
    return None

def fetch_twse_twt44u(target_date: str) -> Optional[pd.DataFrame]:
    """
    (10/10) æŠ“å–æŒ‡å®šæ—¥æœŸçš„ TWT44U å ±å‘Š (æŠ•ä¿¡è²·è³£è¶…å½™ç¸½è¡¨)ã€‚
    URL: https://www.twse.com.tw/rwd/zh/fund/TWT44U
    """
    if not re.fullmatch(r'\d{8}', target_date): return None
    base_url = "https://www.twse.com.tw/rwd/zh/fund/TWT44U"
    url = f"{base_url}?date={target_date}&response=csv"
    
    OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "10_TWT44U")
    filename = OUTPUT_DIR + f"\\{target_date}_TWT44U_InvestmentTrust.csv"

    check_folder_and_create(filename)
    
    print(f"å˜—è©¦æŠ“å– (10/10) TWT44U (æŠ•ä¿¡è²·è³£è¶…) è³‡æ–™...")
    response_text = _fetch_twse_data(url)
    if response_text is None: return None

    df = _read_twse_csv(response_text, header_row=1)

    if df is not None and 'è­‰åˆ¸ä»£è™Ÿ' in df.columns:
        df = df[df['è­‰åˆ¸ä»£è™Ÿ'].astype(str).str.strip() != '']
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… (10/10) {filename} å„²å­˜æˆåŠŸã€‚")
        return df
    return None

def fetch_twse_t86(target_date: str) -> Optional[pd.DataFrame]:
    """
    æŠ“å–æŒ‡å®šæ—¥æœŸçš„ T86 å ±å‘Š (ä¸‰å¤§æ³•äººè²·è³£è¶…å½™ç¸½è¡¨ - ä¾é¡åˆ¥)ã€‚
    URL: https://www.twse.com.tw/rwd/zh/fund/T86
    
    :param target_date: æŸ¥è©¢æ—¥æœŸï¼Œæ ¼å¼ç‚º YYYYMMDD (ä¾‹å¦‚: 20251031)
    :return: åŒ…å«ä¸‰å¤§æ³•äººè²·è³£è¶…è³‡æ–™çš„ DataFrameï¼Œå¦‚æœå¤±æ•—å‰‡ç‚º None
    """
    
    if not re.fullmatch(r'\d{8}', target_date): 
        print("æ—¥æœŸæ ¼å¼éŒ¯èª¤ï¼Œè«‹ä½¿ç”¨ YYYYMMDD æ ¼å¼ã€‚")
        return None
        
    # å®šç¾© URL çµæ§‹
    base_url = "https://www.twse.com.tw/rwd/zh/fund/T86"
    url = f"{base_url}?date={target_date}&selectType=ALL&response=csv"
    
    # å®šç¾©æª”æ¡ˆå„²å­˜è·¯å¾‘
    # å‡è¨­ "datas/raw/10_T86" æ˜¯ç›¸å°æ–¼æ­¤è…³æœ¬çš„ä½ç½®
    OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "11_T86")
    filename = os.path.join(OUTPUT_DIR, f"{target_date}_T86_InstitutionalTrades.csv")

    check_folder_and_create(filename)
    
    print(f"å˜—è©¦æŠ“å– T86 (ä¸‰å¤§æ³•äººè²·è³£è¶… - ä¾é¡åˆ¥) è³‡æ–™ï¼Œæ—¥æœŸ: {target_date}...")
    
    # 1. æŠ“å–è³‡æ–™
    response_text = _fetch_twse_data(url)
    if response_text is None: return None

    # 2. è§£æ CSV (header_row=1 è¡¨ç¤ºæ¬„ä½åç¨±åœ¨ç¬¬äºŒè¡Œ)
    # T86 è¡¨æ ¼çš„æ¬„ä½åç¨±é€šå¸¸åœ¨å›å‚³çš„ CSV å…§å®¹çš„ç¬¬äºŒè¡Œ
    df = _read_twse_csv(response_text, header_row=1)

    # 3. æ•¸æ“šæ¸…ç†èˆ‡å„²å­˜
    if df is not None and 'è­‰åˆ¸ä»£è™Ÿ' in df.columns:
        # æ¸…é™¤æ²’æœ‰è­‰åˆ¸ä»£è™Ÿçš„ç©ºè¡Œ
        df = df[df['è­‰åˆ¸ä»£è™Ÿ'].astype(str).str.strip() != '']
        
        # æ¸…ç†å¤šé¤˜çš„æè¿°è¡Œï¼ˆä¾‹å¦‚åº•éƒ¨çš„åˆè¨ˆè¡Œï¼Œå…¶è­‰åˆ¸ä»£è™Ÿæ¬„ä½å¯èƒ½ç‚ºç©ºï¼‰
        if 'æŠ•ä¿¡è²·è³£è¶…' in df.columns:
            # ç¢ºä¿æ•¸å­—æ¬„ä½å¯ä»¥è¢«è½‰æ›
            df['æŠ•ä¿¡è²·è³£è¶…'] = pd.to_numeric(df['æŠ•ä¿¡è²·è³£è¶…'], errors='coerce')
        
        # åˆªé™¤æ‰€æœ‰æ•¸å­—æ¬„ä½çš†ç‚º NaN çš„è¡Œ (å¯èƒ½æ˜¯åˆè¨ˆæˆ–ç„¡ç”¨è¨Šæ¯)
        df.dropna(subset=df.columns[2:], how='all', inplace=True)
        
        # å„²å­˜ CSV
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… {filename} å„²å­˜æˆåŠŸã€‚")
        return df
    
    print(f"âŒ æ•¸æ“šè™•ç†å¤±æ•—ï¼Œå¯èƒ½è©²æ—¥æœŸ ({target_date}) ç‚ºéäº¤æ˜“æ—¥æˆ–ç¶²ç«™è³‡æ–™çµæ§‹æ”¹è®Šã€‚")
    return None

# è¨­å®šæ‚¨æƒ³è¦æŠ“å–çš„ç›®æ¨™æ—¥æœŸ (åªéœ€ä¿®æ”¹æ­¤è™•å³å¯æŠ“å–æ‰€æœ‰å ±å‘Šçš„è³‡æ–™)
# 1. å–å¾—ä»Šå¤©çš„æ—¥æœŸä¸¦æ ¼å¼åŒ–ç‚º YYYYMMDD

TARGET_DATE = date.today().strftime("%Y%m%d") 
#TARGET_STOCK = "2330" # å°ç£ç©é«”é›»è·¯è£½é€ 
#TARGET_DATE = "20251023"  # æ¸¬è©¦ç”¨ç‰¹å®šæ—¥æœŸ

print("\n" + "="*50)
print("--- ç¨‹å¼é–‹å§‹åŸ·è¡Œï¼šTWSE 10 å¤§å ±å‘Šæ‰¹é‡æŠ“å– ---")
#print(f"ğŸ¯ ç›®æ¨™æŸ¥è©¢æ—¥æœŸ: {TARGET_DATE} | è‚¡ç¥¨ä»£è™Ÿ: {TARGET_STOCK}")
print("="*50 + "\n")

# è¨­ç½®ä¸€å€‹åˆ—è¡¨ä¾†å„²å­˜çµæœï¼Œä¾¿æ–¼æœ€çµ‚é è¦½
results = []

# 1. STOCK_DAY (å€‹è‚¡æ—¥æˆäº¤è³‡è¨Š)
# æ”¹ä»¥å–®ç¨çš„ç¨‹å¼æŠ“å–è³‡æ–™
#results.append(("STOCK_DAY", fetch_twse_stock_day(TARGET_DATE, TARGET_STOCK)))

file_path = pathlib.Path(__file__).resolve().parent / "datas" / "processed" / "get_holidays" / "trading_day_2021-2025.csv"
# å‡è¨­æ‚¨çš„æ—¥æœŸæ¬„ä½åç¨±å°±æ˜¯ 'Date'
#past_dates_yyyymmdd = get_past_dates_in_yyyymmdd(file_path, date_column_name='æ—¥æœŸ')
past_dates_yyyymmdd = TARGET_DATE
# past_dates_yyyymmdd = ["20251031",
#                        "20251030",
#                        "20251029",
#                        "20251028",
#                        "20251027",
#                        "20251023",
#                        "20251022",
#                        "20251021",
#                        "20251020",]

for every_day in past_dates_yyyymmdd:
    
    TARGET_DATE = every_day
    # 2. MI_INDEX (æ‰€æœ‰é¡è‚¡æˆäº¤çµ±è¨ˆ)
    results.append(("MI_INDEX", fetch_twse_mi_index(TARGET_DATE))) 

    # 3. BWIBBU_d (é¡è‚¡æ—¥æˆäº¤é‡å€¼åŠå ±é…¬ç‡)
    results.append(("BWIBBU_d", fetch_twse_bwibbu_d(TARGET_DATE))) 

    # 4. MI_INDEX20 (æ”¶ç›¤æŒ‡æ•¸åŠæˆäº¤é‡å€¼è³‡è¨Š)
    results.append(("MI_INDEX20", fetch_twse_mi_index20(TARGET_DATE)))

    # 5. TWTASU (æ¯æ—¥ç¸½æˆäº¤é‡å€¼èˆ‡å¹³å‡è‚¡åƒ¹)
    results.append(("TWTASU", fetch_twse_twtasu(TARGET_DATE))) 

    # 6. BFIAMU (è‡ªç‡Ÿå•†è²·è³£è¶…å½™ç¸½è¡¨)
    results.append(("BFIAMU", fetch_twse_bfiamu(TARGET_DATE))) 

    # 7. FMTQIK (æ¯æ—¥åˆ¸å•†æˆäº¤é‡å€¼ç¸½è¡¨)
    results.append(("FMTQIK", fetch_twse_fmtqik(TARGET_DATE)) )

    # 8. BFI82U (ä¸‰å¤§æ³•äººè²·è³£è¶…å½™ç¸½è¡¨ - æ—¥)
    results.append(("BFI82U", fetch_twse_bfi82u(TARGET_DATE)))

    # 9. TWT43U (å¤–è³‡åŠé™¸è³‡è²·è³£è¶…å½™ç¸½è¡¨)
    results.append(("TWT43U", fetch_twse_twt43u(TARGET_DATE)))

    # 10. TWT44U (æŠ•ä¿¡è²·è³£è¶…å½™ç¸½è¡¨)
    results.append(("TWT44U", fetch_twse_twt44u(TARGET_DATE)))

    # 11. T86 (ä¸‰å¤§æ³•äººè²·è³£è¶…å½™ç¸½è¡¨)
    results.append(("T86", fetch_twse_t86(TARGET_DATE)))

    # 12. MI_MARGN (èè³‡èåˆ¸å½™ç¸½ (å…¨éƒ¨))
    #results.append(("TWT93U", fetch_twse_mi_margn(TARGET_DATE)))


    # --- æœ€çµ‚çµæœé è¦½ ---
    print("\n" + "="*50)
    print("--- 10 å€‹å ±å‘ŠæŠ“å–çµæœæ‘˜è¦ ---")
    print("="*50)

    for name, df in results:
        if df is not None:
            print(f"\n[ğŸŸ¢ {name} (æˆåŠŸ)] æ•¸æ“šç­†æ•¸: {len(df)}")
            # print(df.head().to_markdown(index=False)) # è¨»é‡‹æ‰é¿å…è¼¸å‡ºéå¤š
        else:
            print(f"[ğŸ”´ {name} (å¤±æ•—)] ç„¡æ•¸æ“šæˆ–æŠ“å–éŒ¯èª¤ã€‚")

    time.sleep(5) 

# å¢åŠ æ—¥èªŒå„²å­˜ï¼šè¨˜éŒ„æœ¬æ¬¡å˜—è©¦æŠ“å–çš„æ—¥æœŸ
log_summary_results(results, TARGET_DATE)

print("\næ‰€æœ‰ CSV æª”æ¡ˆå·²å„²å­˜è‡³ç¨‹å¼åŸ·è¡Œç›®éŒ„ä¸‹ã€‚")
print("--- ç¨‹å¼åŸ·è¡ŒçµæŸ ---")
#==========================================================
# # çˆ¬å–ä¸¦å„²å­˜ä¸Šå¸‚/ä¸Šæ«ƒè³‡æ–™
# FILE_TYPES = ['exchange', 'counter']
# for stock_type in FILE_TYPES:
#     get_stocks_company_all.list_stock(stock_type)
# # 2. åˆä½µæ‰€æœ‰å„²å­˜çš„æª”æ¡ˆä¸¦é€²è¡Œç¯©é¸èˆ‡æ—¥èªŒè¨˜éŒ„
# get_stocks_company_all.combine_and_save(get_stocks_company_all.OUTPUT_csv_DIR, FILE_TYPES)
#==========================================================
