import os
import re
import time
import requests
import pandas as pd
from typing import Optional, List
from io import StringIO
import sys


# æŠ‘åˆ¶ç•¶ verify=False æ™‚å½ˆå‡ºçš„ InsecureRequestWarning è­¦å‘Š
requests.packages.urllib3.disable_warnings(requests.packages.urllib3.exceptions.InsecureRequestWarning)

# --- è¨­å®šèˆ‡è·¯å¾‘ ---
# âš ï¸ è«‹ç¢ºä¿ 'datas/raw/2_MI_INDEX' è·¯å¾‘å­˜åœ¨æˆ–å¯è¢«å»ºç«‹
OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "2_MI_INDEX")
BASE_URL = "https://www.twse.com.tw/rwd/zh/afterTrading/MI_INDEX"


# --- è¼”åŠ©å‡½æ•¸ (ç‚ºä½¿ç¨‹å¼ç¢¼å¯åŸ·è¡Œè€ŒåŠ å…¥) ---
# æª¢æŸ¥ä¸¦å»ºç«‹æ‰€éœ€çš„ã€è³‡æ–™å¤¾ã€‘
def _check_folder_and_create(filepath: str):
    os.makedirs(os.path.dirname(filepath), exist_ok=True)

def _fetch_twse_data(url: str) -> Optional[str]:
    """å˜—è©¦å¾ TWSE æŠ“å–è³‡æ–™ï¼Œä¸¦è¿”å›åŸå§‹æ–‡æœ¬ã€‚"""
    try:
        # è¨­ç½® User-Agent ä»¥æ¨¡æ“¬ç€è¦½å™¨è¡Œç‚º
        headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        try:
            response = requests.get(url, headers=headers, verify=False, timeout=10)
            response.raise_for_status() 
            response.encoding = 'Big5'
            return response.text
        except requests.exceptions.HTTPError as errh:
            print(f"âŒ HTTP éŒ¯èª¤ï¼š{errh} (è©²æ—¥å¯èƒ½ç„¡äº¤æ˜“è³‡æ–™)")
        except requests.exceptions.RequestException as err:
            print(f"âŒ é€£ç·šæˆ– Requests éŒ¯èª¤: {err}")
        except Exception as e:
            print(f"âŒ ç™¼ç”Ÿå…¶ä»–éŒ¯èª¤: {e}")
        
        # æª¢æŸ¥ TWSE å›å‚³å…§å®¹æ˜¯å¦ç‚ºéŒ¯èª¤è¨Šæ¯
        if "æŸ¥è©¢æ—¥æœŸå¤§æ–¼ä»Šæ—¥" in response.text or "å¾ˆæŠ±æ­‰" in response.text:
             print("âš ï¸ TWSE ç¶²ç«™è¿”å›éŒ¯èª¤è¨Šæ¯ï¼Œè©²æ—¥å¯èƒ½ç„¡è³‡æ–™æˆ–æ—¥æœŸè¶…å‡ºç¯„åœã€‚")
             return None

        # å˜—è©¦ä½¿ç”¨æ­£ç¢ºç·¨ç¢¼è§£æï¼Œè™•ç† CSV æª”æ¡ˆå¸¸è¦‹çš„ BOM
        response.encoding = 'utf-8-sig' 
        return response.text
    except requests.exceptions.RequestException as e:
        print(f"âŒ ç¶²è·¯è«‹æ±‚å¤±æ•—æˆ–è¶…æ™‚: {e}")
        return None

def _read_twse_csv(response_text: str, header_row: int) -> Optional[pd.DataFrame]:
    """å°‡ TWSE è¿”å›çš„æ–‡æœ¬è§£æç‚º Pandas DataFrameã€‚"""
    try:
        data = StringIO(response_text)
        # header_row=1: MI_INDEX å ±è¡¨å¯¦éš›çš„è¡¨é ­åœ¨ç´¢å¼• 1 (0-based)
        df = pd.read_csv(data, 
                        header=header_row, 
                        encoding='utf-8-sig', 
                        skipinitialspace=True,
                        engine='python',
                        on_bad_lines='skip' # <-- é€™å€‹åƒæ•¸æœƒå¿½ç•¥æ¬„ä½æ•¸ä¸æ­£ç¢ºçš„è¡Œï¼Œé¿å…ç¨‹å¼å´©æ½°
        )
        if not df.empty:
            df.columns = df.columns.str.strip() # æ¸…ç†æ¬„ä½åç¨±
            
            # åˆªé™¤çµå°¾å¯èƒ½çš„ç©ºç™½è¡Œæˆ–å‚™è¨»è¡Œ
            if 'æŒ‡æ•¸' in df.columns:
                 # ç§»é™¤ 'æŒ‡æ•¸' æ¬„ä½ç‚ºç©ºå­—ä¸²æˆ–ç©ºç™½çš„è¡Œ
                 df = df[df['æŒ‡æ•¸'].astype(str).str.strip() != '']
                 
            # ç§»é™¤æ‰€æœ‰å…§å®¹ç‚ºç©ºçš„æ¬„ä½ (å¦‚ CSV çµå°¾çš„ç©ºæ¬„ä½)
            df.dropna(axis=1, how='all', inplace=True)
            
            if df.empty:
                print("âš ï¸ è§£æ CSV å¾Œ DataFrame ç‚ºç©ºï¼Œå¯èƒ½ç„¡æœ‰æ•ˆè³‡æ–™ã€‚")
                return None
                
            return df
        return None

    except Exception as e:
        print(f"âŒ è§£æ CSV æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None


# --- æ ¸å¿ƒå–®æ—¥æŠ“å–å‡½æ•¸ (Refactored from user's snippet) ---

def fetch_twse_mi_index_single(target_date: str) -> Optional[pd.DataFrame]:
    """
    æŠ“å–æŒ‡å®šæ—¥æœŸçš„ MI_INDEX å ±å‘Šã€‚

    Args:
        target_date: æ¬²æŠ“å–çš„æ—¥æœŸï¼Œæ ¼å¼ç‚º YYYYMMDDã€‚

    Returns:
        æˆåŠŸæ™‚è¿”å› DataFrameï¼Œå¤±æ•—æ™‚è¿”å› Noneã€‚
    """
    if not re.fullmatch(r'\d{8}', target_date): 
        print(f"æ—¥æœŸæ ¼å¼éŒ¯èª¤: {target_date}")
        return None
        
    url = f"{BASE_URL}?date={target_date}&type=ALLBUT0999&response=csv"
    filename = os.path.join(OUTPUT_DIR, f"{target_date}_MI_INDEX_Sector.csv")
    
    _check_folder_and_create(filename) # ç¢ºä¿ç›®éŒ„å­˜åœ¨
    
    print(f"  -> å˜—è©¦æŠ“å– {target_date}...")
    
    response_text = _fetch_twse_data(url)
    if response_text is None: 
        return None
    
    df = _read_twse_csv(response_text, header_row=1)

    if df is not None and 'æŒ‡æ•¸' in df.columns:
        # æ¸…ç† 'æŒ‡æ•¸' æ¬„ä½ä¸­çš„ç©ºç™½ï¼Œä¸¦ç§»é™¤ç©ºåˆ—
        df = df[df['æŒ‡æ•¸'].astype(str).str.strip() != '']
        
        # å„²å­˜è³‡æ–™
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"  âœ… {target_date} è³‡æ–™å„²å­˜æˆåŠŸ: {filename}")
        return df
        
    return None

# --- æ‰¹æ¬¡è™•ç†èˆ‡é‡è©¦å‡½æ•¸ (æ»¿è¶³ä½¿ç”¨è€… 2/3/4/5 é»éœ€æ±‚) ---

def batch_fetch_twse_mi_index(date_list: List[str]):
    """
    é‡å°æä¾›çš„æ—¥æœŸæ¸…å–®ï¼Œé€ä¸€æŠ“å– TWSE MI_INDEX è³‡æ–™ï¼Œä¸¦åœ¨å¤±æ•—æ™‚å¯¦ä½œé‡è©¦æ©Ÿåˆ¶ã€‚
    Args:
        date_list: åŒ…å« YYYYMMDD æ ¼å¼æ—¥æœŸçš„å­—ä¸²åˆ—è¡¨ã€‚
    """
    print("--- é–‹å§‹æ‰¹æ¬¡æŠ“å– TWSE MI_INDEX è³‡æ–™ ---")
    
    for target_date in date_list:
        max_attempts = 4  # é¦–æ¬¡å˜—è©¦ (1) + 3 æ¬¡é‡è©¦ = æœ€å¤š 4 æ¬¡æ©Ÿæœƒ
        
        for attempt in range(1, max_attempts + 1):
            
            # åŸ·è¡ŒæŠ“å–
            df = fetch_twse_mi_index_single(target_date)
            
            if df is not None:
                # æˆåŠŸ
                print(f"ğŸŒŸ {target_date} è³‡æ–™å·²å®Œæˆã€‚")
                break  # æˆåŠŸï¼Œè·³å‡ºé‡è©¦è¿´åœˆ
            
            # å¤±æ•—è™•ç†
            if attempt < max_attempts:
                # éå¢å»¶é²æ™‚é–“: ç¬¬ä¸€æ¬¡å¤±æ•—å»¶é² 1 å°æ™‚, ç¬¬äºŒæ¬¡ 2 å°æ™‚, ...
                # (attempt - 1) ä»£è¡¨ç¬¬å¹¾æ¬¡é‡è©¦ (1, 2, 3...)
                delay_hours = attempt 
                
                # âš ï¸ å¯¦éš›ç”Ÿç”¢ç’°å¢ƒè«‹ä½¿ç”¨: delay_seconds = delay_hours * 3600
                # æ¸¬è©¦ç’°å¢ƒç”¨:
                delay_seconds = delay_hours * 5 

                print(f"ğŸš¨ {target_date} æŠ“å–å¤±æ•— (ç¬¬ {attempt} æ¬¡å˜—è©¦)ã€‚å°‡åœ¨ {delay_seconds} ç§’å¾Œé‡è©¦ (ä¸‹æ¬¡ç­‰å¾… {delay_hours} å°æ™‚)...")
                time.sleep(delay_seconds)
            else:
                # è¶…éæœ€å¤§å˜—è©¦æ¬¡æ•¸
                print(f"âŒ {target_date} è³‡æ–™ç¶“é {max_attempts} æ¬¡å˜—è©¦å¾Œä»ç„¶å¤±æ•—ï¼Œè·³éæ­¤æ—¥æœŸã€‚")


# --- åŸ·è¡Œç¯„ä¾‹ ---

if __name__ == "__main__":
    # ç¯„ä¾‹æ—¥æœŸæ¸…å–®ã€‚è«‹æ›¿æ›ç‚ºæ‚¨è¦æŠ“å–çš„å¯¦éš›æ—¥æœŸã€‚
    # å»ºè­°åŒ…å«ä¸€äº›å·²çŸ¥æœ‰è³‡æ–™çš„æ—¥æœŸä¾†æ¸¬è©¦æˆåŠŸæ¡ˆä¾‹ã€‚
    DATE_LIST_TO_FETCH = [
        "20251114", # æˆåŠŸç¯„ä¾‹ 1
        "20251115", # æˆåŠŸç¯„ä¾‹ 2
        "99991231"  # å¤±æ•—ç¯„ä¾‹ (æœªä¾†æ—¥æœŸï¼Œå°‡è§¸ç™¼é‡è©¦)
    ]
    
    # æé†’ï¼šè«‹å…ˆç¢ºä¿æ‚¨çš„ç’°å¢ƒå·²å®‰è£æ‰€éœ€çš„å‡½å¼åº«ï¼š
    # pip install requests pandas

    batch_fetch_twse_mi_index(DATE_LIST_TO_FETCH)

# TEST_OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "test_datas", "raw" , "2_MI_INDEX","test_output.csv" )
# print(TEST_OUTPUT_DIR)
# _check_folder_and_create(TEST_OUTPUT_DIR)
    