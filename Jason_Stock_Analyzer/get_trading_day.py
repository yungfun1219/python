import pathlib
import pandas as pd
import requests
import os
from io import StringIO
from typing import Optional
import datetime
from datetime import date, timedelta
import re
import sys #--æ¸¬è©¦ç¨‹å¼ä¸­æ–·ç”¨sys.exit(0) #ä¸­æ–·ç¨‹å¼
import urllib3

# ç¦ç”¨ urllib3 çš„ InsecureRequestWarning 
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- å‡½å¼æ•´ç† --- 

# å¾å°ç£è­‰åˆ¸äº¤æ˜“æ‰€ç¶²ç«™æŠ“å–æŒ‡å®šå¹´ä»½çš„ä¼‘å¸‚æ—¥æœŸè³‡æ–™ã€‚
def fetch_twse_holidays(year: int) -> Optional[pd.DataFrame]:
    """
    å¾å°ç£è­‰åˆ¸äº¤æ˜“æ‰€ç¶²ç«™æŠ“å–æŒ‡å®šå¹´ä»½çš„ä¼‘å¸‚æ—¥æœŸè³‡æ–™ã€‚
    TWSE çš„ CSV æ ¼å¼é€šå¸¸åœ¨é–‹é ­æœ‰å¹¾è¡Œæè¿°ï¼Œéœ€è¦ç‰¹åˆ¥è™•ç†ã€‚
    Args:
        year (int): è¦æŠ“å–çš„å¹´ä»½ (ä¾‹å¦‚ 2024)ã€‚
    Returns:
        Optional[pd.DataFrame]: åŒ…å«ä¼‘å¸‚æ—¥æœŸçš„ DataFrameï¼Œå¦‚æœæŠ“å–å¤±æ•—å‰‡å›å‚³ Noneã€‚
    """
    # TWSE ç¶²å€çµæ§‹ï¼šæˆ‘å€‘ä½¿ç”¨è©²å¹´ä»½çš„ç¬¬ä¸€å¤©ä½œç‚ºæŸ¥è©¢åŸºæº–é»
    twse_url = (
        f"https://www.twse.com.tw/rwd/zh/holidaySchedule/holidaySchedule"
        f"?date={year}0101&response=csv"
    )
    
    print(f"ğŸ“¡ å˜—è©¦æŠ“å– {year} å¹´ TWSE ä¼‘å¸‚è³‡æ–™...")
 
    try:
        # ä½¿ç”¨ requests ç²å–å…§å®¹
        # *** è§£æ±º SSLCertVerificationError éŒ¯èª¤ï¼šåŠ å…¥ verify=False ***
        response = requests.get(twse_url, verify=False)
        
        # æª¢æŸ¥ HTTP ç‹€æ…‹ç¢¼
        if response.status_code != 200:
            print(f"âŒ ç¶²è·¯è«‹æ±‚å¤±æ•—ï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
            return None
        
        # å°‡å…§å®¹å¾ cp950 (Big5 æ“´å……) è§£ç¢¼ç‚ºå­—ä¸²ï¼Œä»¥ä¾¿ Pandas è®€å–
        csv_data_string = response.content.decode('cp950', errors='ignore')
        
        # ä½¿ç”¨ StringIO æ¨¡æ“¬æª”æ¡ˆï¼Œè®“ Pandas è®€å–å­—ä¸²
        data_io = StringIO(csv_data_string)

        # è®€å– CSVã€‚TWSE CSV é€šå¸¸ç¬¬ä¸€è¡Œæ˜¯æè¿°ï¼Œç¬¬äºŒè¡Œæ‰æ˜¯çœŸæ­£çš„æ¬„ä½åç¨± (Header)
        df = pd.read_csv(data_io, header=1, encoding='cp950')
        
        # æ•¸æ“šæ¸…ç†æ­¥é©Ÿï¼š
        
        # 1. ç§»é™¤æœ€å¾Œå¹¾è¡Œå¯èƒ½å‡ºç¾çš„ç©ºç™½æˆ–è¨»é‡‹è¡Œ (é€šå¸¸æœƒä»¥ NaN å‘ˆç¾)
        df.dropna(how='all', inplace=True)
        
        # 2. é‡æ–°å‘½åæ¬„ä½ç‚ºä¸­æ–‡ (å‡è¨­å‰å››å€‹æ¬„ä½åˆ†åˆ¥æ˜¯æ—¥æœŸã€åç¨±ã€èªªæ˜ã€å‚™è¨»)
        if len(df.columns) >= 4:
            df.columns = ['æ—¥æœŸ', 'åç¨±', 'èªªæ˜', 'å‚™è¨»']
        
        # 3. ç¢ºä¿æ—¥æœŸæ¬„ä½ç‚ºæ¨™æº–æ ¼å¼ (å¦‚æœéœ€è¦)
        # df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')

        print(f"âœ… æˆåŠŸæŠ“å– {len(df)} ç­†ä¼‘å¸‚è³‡æ–™ã€‚")
        return df

    except Exception as e:
        print(f"âŒ æŠ“å–æˆ–è™•ç†è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

# æª¢æŸ¥æŒ‡å®šè³‡æ–™å¤¾å…§æ‰€æœ‰æª”æ¡ˆåç¨±æ˜¯å¦åŒ…å«ç‰¹å®šçš„é—œéµå­—ã€‚
def check_files_for_keyword(folder_path: pathlib.Path, keyword: str):
    """
    æª¢æŸ¥æŒ‡å®šè³‡æ–™å¤¾å…§æ‰€æœ‰æª”æ¡ˆåç¨±æ˜¯å¦åŒ…å«ç‰¹å®šçš„é—œéµå­—ã€‚
    Args:
        folder_path: ç›®æ¨™è³‡æ–™å¤¾çš„ Path ç‰©ä»¶ã€‚
        keyword: è¦å°‹æ‰¾çš„å­—ä¸²ã€‚
    Returns:
        bool: å¦‚æœæœ‰ä»»ä½•æª”æ¡ˆåç¨±åŒ…å«é—œéµå­—å‰‡å›å‚³ Trueï¼Œå¦å‰‡å›å‚³ Falseã€‚
    """
    #print(f"--- é–‹å§‹æª¢æŸ¥è³‡æ–™å¤¾: {folder_path} ---")
    # æª¢æŸ¥è³‡æ–™å¤¾æ˜¯å¦å­˜åœ¨
    if not folder_path.is_dir():
        print(f"éŒ¯èª¤ï¼šæŒ‡å®šçš„è·¯å¾‘ä¸æ˜¯ä¸€å€‹æœ‰æ•ˆçš„è³‡æ–™å¤¾æˆ–ä¸å­˜åœ¨ï¼š{folder_path}")
        return

    found_count = 0
    
    # ä½¿ç”¨ iterdir() è¿­ä»£è³‡æ–™å¤¾å…§å®¹
    for item in folder_path.iterdir():
        if item.is_file():
            file_name = item.name  # å–å¾—æª”æ¡ˆåç¨± (Pathlib çš„å±¬æ€§)
            
            # åˆ¤æ–·æª”æ¡ˆåç¨±æ˜¯å¦åŒ…å«é—œéµå­—
            if keyword in file_name:
                #print(f"[âœ… åŒ…å«] æª”æ¡ˆåç¨±ï¼š{file_name}")
                found_count += 1
            #else:
                #print(f"[âŒ ä¸å«] æª”æ¡ˆåç¨±ï¼š{file_name}")

    if found_count > 0:
        return False
    else:
        return True

# å°‡ DataFrame å„²å­˜ç‚ºæœ¬åœ° CSV æª”æ¡ˆçš„å‡½å¼
def save_dataframe_to_csv(df: pd.DataFrame, year: int, filename: str = None):
    """
    å°‡ DataFrame å„²å­˜ç‚ºæœ¬åœ° CSV æª”æ¡ˆã€‚
    *** ä¿®æ­£ç·¨ç¢¼ç‚º cp950 ä»¥è§£æ±ºæœ¬åœ°é–‹å•Ÿäº‚ç¢¼å•é¡Œ ***
    """
    if filename is None:
        filename = pathlib.Path(os.path.dirname(os.path.abspath(__file__)), "datas", "twse_holidays" , f"twse_holidays_{year}.csv")
    
    try:
        # ä½¿ç”¨ cp950 å„²å­˜ï¼Œä»¥ç¢ºä¿åœ¨å‚³çµ±ä¸­æ–‡ä½œæ¥­ç³»çµ±ä¸Šé–‹å•Ÿæ™‚ä¸æœƒäº‚ç¢¼
        df.to_csv(filename, index=False, encoding='cp950')
        print(f"ğŸ’¾ è³‡æ–™å·²æˆåŠŸå„²å­˜è‡³ {filename}")
    except Exception as e:
        print(f"âŒ å„²å­˜æª”æ¡ˆå¤±æ•—: {e}")

#     è™•ç†åŒ…å« 'æœˆæ—¥' æ ¼å¼æ—¥æœŸçš„ DataFrameï¼Œå°‡å…¶è½‰æ›ç‚ºè¥¿å…ƒå¹´ä»½æ ¼å¼ï¼Œä¸¦è¿”å›æ–°çš„ DataFrameã€‚
def transform_twse_holiday_dates(df: pd.DataFrame, year: int) -> pd.DataFrame:
    """
    è™•ç†åŒ…å« 'æœˆæ—¥' æ ¼å¼æ—¥æœŸçš„ DataFrameï¼Œå°‡å…¶è½‰æ›ç‚ºè¥¿å…ƒå¹´ä»½æ ¼å¼ï¼Œä¸¦è¿”å›æ–°çš„ DataFrameã€‚

    åƒæ•¸:
        df (pd.DataFrame): åŒ…å« 'æ—¥æœŸ' æ¬„ä½çš„ DataFrame (ä¾‹å¦‚: '1æœˆ1æ—¥')ã€‚
        year (int): ç”¨æ–¼æ—¥æœŸè½‰æ›çš„è¥¿å…ƒå¹´ä»½ã€‚

    è¿”å›:
        pd.DataFrame: åŒ…å« 'åŸå§‹æ—¥æœŸ'ã€'åç¨±' å’Œ 'è¥¿å…ƒæ—¥æœŸ' æ¬„ä½çš„æ–° DataFrameã€‚
                      è¥¿å…ƒæ—¥æœŸæ ¼å¼ç‚º 'YYYY/MM/DD'ã€‚
    """
    
    # æª¢æŸ¥ DataFrame æ˜¯å¦æœ‰æ•ˆ
    if df is None or df.empty:
        print(f"âš ï¸ è­¦å‘Š: è¼¸å…¥çš„ DataFrame ç‚ºç©ºæˆ– Noneï¼Œè¿”å›ä¸€å€‹ç©ºçš„ DataFrameã€‚")
        # ç‚ºäº†ä¿æŒå‡½å¼è¿”å›å‹åˆ¥ä¸€è‡´ï¼Œè¿”å›ä¸€å€‹åŒ…å«é æœŸæ¬„ä½çš„ç©º DataFrame
        return pd.DataFrame(columns=['åŸå§‹æ—¥æœŸ', 'åç¨±', 'è¥¿å…ƒæ—¥æœŸ'])
    
    print(f"debug: é–‹å§‹è™•ç† {year} å¹´çš„è³‡æ–™...")
    
    # ä½¿ç”¨ .copy() é¿å…ä¿®æ”¹å‚³å…¥çš„åŸå§‹ DataFrame
    df_transformed = df.copy()
    
    dates_md = df_transformed['æ—¥æœŸ']
    start_year_str = str(year)
    
    # å®šç¾©æ­£å‰‡è¡¨é”å¼ï¼Œç”¨æ–¼æå–æœˆä»½å’Œæ—¥æœŸ (ä¾‹å¦‚ï¼š10æœˆ10æ—¥)
    # (\d+)æœˆ(\d+)æ—¥
    pattern = r"(\d+)æœˆ(\d+)æ—¥"
    
    dates_gregorian_list = []
    
    # éæ­·æ—¥æœŸæ¬„ä½ï¼Œé€²è¡Œè½‰æ›
    for index, date_string in dates_md.items():
        print(f"debug: ç´¢å¼• {index}ï¼ŒåŸå§‹å­—ä¸²: {date_string}")

        match = re.search(pattern, date_string)
        if match:
            # æ“·å–æœˆä»½å’Œæ—¥æœŸï¼Œä¸¦ä½¿ç”¨ zfill(2) è£œé›¶ï¼Œç¢ºä¿æ ¼å¼ç‚º MM å’Œ DD
            month_str = match.group(1).zfill(2)
            day_str = match.group(2).zfill(2)
            
            # è½‰æ›ç‚ºè¥¿å…ƒæ—¥æœŸæ ¼å¼ YYYY/MM/DD
            dates_gregorian = f"{start_year_str}/{month_str}/{day_str}"
            print(f" Â è½‰æ›ç‚ºè¥¿å…ƒæ—¥æœŸ: {dates_gregorian}")
        else:
            dates_gregorian = None # å¦‚æœæ ¼å¼ä¸ç¬¦ï¼Œå‰‡è¨­å®šç‚º None
            print("âŒ éŒ¯èª¤ï¼šå­—ä¸²æ ¼å¼èˆ‡é æœŸä¸ç¬¦ï¼Œæœªæ‰¾åˆ°æœˆä»½å’Œæ—¥æœŸæ•¸å­—ã€‚")
        
        dates_gregorian_list.append(dates_gregorian)

    # å°‡è½‰æ›å¾Œçš„æ—¥æœŸæ–°å¢è‡³ DataFrame çš„æ–°æ¬„ä½
    df_transformed['æ—¥æœŸ'] = dates_gregorian_list
    
    # é‡æ–°å‘½ååŸå§‹æ¬„ä½ï¼Œä½¿è¼¸å‡ºçš„ DataFrame çµæ§‹æ›´æ¸…æ™°
    df_transformed.rename(columns={'æ—¥æœŸ': 'æ—¥æœŸ', 'åç¨±': 'å‡æ—¥åç¨±'}, inplace=True)
    
    print("\nâœ… æ—¥æœŸè½‰æ›å®Œæˆã€‚")
    return df_transformed

# æ–°å¢ï¼šå„²å­˜æ—¥æœŸæ¸…å–®åˆ° CSV æª”æ¡ˆçš„å‡½å¼
def save_dates_to_csv(dates_list: list[str], year: int, filename: str = 'weekend_dates.csv'):
    """
    å°‡æ—¥æœŸæ¸…å–®å„²å­˜ç‚º CSV æª”æ¡ˆã€‚
    Args:
        dates_list (list[str]): è¦å„²å­˜çš„æ—¥æœŸæ¸…å–®ã€‚
        year (int): ç”Ÿæˆæ—¥æœŸçš„å¹´ä»½ (ç”¨æ–¼æª”æ¡ˆå‘½åæˆ–æ—¥èªŒ)ã€‚
        filename (str): å„²å­˜çš„æª”æ¡ˆåç¨± (é è¨­ç‚º 'weekend_dates.csv')ã€‚
    """
    if not dates_list:
        print("ã€è­¦å‘Šã€‘æ—¥æœŸæ¸…å–®ç‚ºç©ºï¼Œä¸åŸ·è¡Œå„²å­˜æ“ä½œã€‚")
        return

    try:
        # å»ºç«‹ DataFrame
        # é€™è£¡å‡è¨­æ‚¨å¸Œæœ› CSV æª”æ¡ˆåªæœ‰ä¸€æ¬„ï¼Œæ¬„ä½åç¨±ç‚º 'Date'
        df = pd.DataFrame({
            'æ—¥æœŸ': dates_list,
            'å‡æ—¥åç¨±': ['é€±æœ«'] * len(dates_list)
            })
        
        # å®šç¾©æª”æ¡ˆè·¯å¾‘ï¼Œå„²å­˜åœ¨ç•¶å‰ç›®éŒ„
        file_path = pathlib.Path(os.path.dirname(os.path.abspath(__file__)), "datas", "processed" , "get_holidays" , f"{year}_{filename}")
        # å„²å­˜ç‚º CSV æª”æ¡ˆ
        # index=False è¡¨ç¤ºä¸å¯«å…¥è¡Œç´¢å¼•
        # encoding='utf-8-sig' å¯ç¢ºä¿ä¸­æ–‡æˆ–ç‰¹æ®Šå­—å…ƒåœ¨ Excel ä¸­æ­£ç¢ºé¡¯ç¤º
        df.to_csv(file_path, index=False, encoding='utf-8-sig')
        
        print(f"\nğŸ’¾ æˆåŠŸå°‡ {len(dates_list)} ç­†é€±æœ«æ—¥æœŸå„²å­˜åˆ° CSV æª”æ¡ˆã€‚")
        print(f"æª”æ¡ˆè·¯å¾‘: {file_path}")
        
    except Exception as e:
        print(f"ã€éŒ¯èª¤ã€‘å„²å­˜ CSV æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

# --- å‡½å¼ï¼šç”Ÿæˆå…¨å¹´åº¦é€±æœ«æ—¥æœŸæ¸…å–® ---
def generate_full_year_weekend_dates(year: int) -> list[str]:
    """
    ç”ŸæˆæŒ‡å®šå¹´ä»½çš„æ‰€æœ‰é€±æœ«æ—¥æœŸæ¸…å–® (æ˜ŸæœŸå…­å’Œæ˜ŸæœŸæ—¥)ã€‚
    Args:
        year (int): è¦ç”Ÿæˆæ—¥æœŸçš„å¹´ä»½ (ä¾‹å¦‚ 2024)ã€‚
    Returns:
        list[str]: åŒ…å«æ‰€æœ‰é€±æœ«æ—¥æœŸçš„åˆ—è¡¨ï¼Œæ ¼å¼ç‚º 'YYYY/MM/DD'ã€‚
    """
    print(f"\nğŸ“… æ­£åœ¨ç”Ÿæˆ {year} å¹´çš„å…¨å¹´åº¦é€±æœ«æ—¥æœŸæ¸…å–®...")
    try:
        # è¨­ç½®èµ·å§‹æ—¥å’ŒçµæŸæ—¥
        start_date = f"{year}-01-01"
        end_date = f"{year}-12-31"

        # ä½¿ç”¨ Pandas date_range ç”¢ç”Ÿæ‰€æœ‰æ—¥æœŸï¼Œé »ç‡è¨­ç‚º 'D' (Day)
        all_dates = pd.date_range(start=start_date, end=end_date, freq='D')
        
        # éæ¿¾æ—¥æœŸï¼šä¿ç•™æ˜ŸæœŸå…­ (5) å’Œæ˜ŸæœŸæ—¥ (6)ã€‚ (æ˜ŸæœŸä¸€=0, æ˜ŸæœŸæ—¥=6)
        all_dates = all_dates[all_dates.dayofweek.isin([5, 6])]

        # å°‡æ—¥æœŸæ ¼å¼åŒ–ç‚º 'YYYY/MM/DD' å­—ä¸²åˆ—è¡¨
        dates_list = all_dates.strftime('%Y/%m/%d').tolist()
        print(f"âœ… æˆåŠŸç”Ÿæˆ {len(dates_list)} ç­†æ—¥æœŸ (åƒ…åŒ…å«é€±æœ«)ã€‚")
        return dates_list
    except Exception as e:
        print(f"âŒ ç”Ÿæˆæ—¥æœŸæ¸…å–®æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return []

#  è®€å– CSV æª”æ¡ˆï¼Œå¾ç¬¬äºŒè¡Œ (å³æ•¸æ“šè¡Œ) é–‹å§‹æå–æŒ‡å®šçš„æ¬„ä½è³‡æ–™ã€‚
def extract_columns_from_second_row(file_path: str, columns_to_extract: list = [0, 1]) -> pd.DataFrame:
    """
    è®€å– CSV æª”æ¡ˆï¼Œå¾ç¬¬äºŒè¡Œ (å³æ•¸æ“šè¡Œ) é–‹å§‹æå–æŒ‡å®šçš„æ¬„ä½è³‡æ–™ã€‚
    Args:
        file_path (str): CSV æª”æ¡ˆçš„å®Œæ•´è·¯å¾‘ã€‚
        columns_to_extract (list): è¦æå–çš„æ¬„ä½ç´¢å¼•æ¸…å–® (å¾ 0 é–‹å§‹è¨ˆç®—)ã€‚
                                  é è¨­ç‚º [0, 1]ï¼Œå³ç¬¬ 1 æ¬„å’Œç¬¬ 2 æ¬„ã€‚
    Returns:
        pd.DataFrame: åŒ…å«æå–å‡ºçš„ç¬¬ 1 å’Œç¬¬ 2 æ¬„è³‡æ–™çš„ DataFrameã€‚
    """
    try:
        # å˜—è©¦ä½¿ç”¨ UTF-8-sig è®€å–ï¼Œè‹¥å¤±æ•—å‰‡å˜—è©¦ cp950
        try:
            df = pd.read_csv(
            file_path,
            header=None,         # å°‡æ‰€æœ‰è¡Œéƒ½è¦–ç‚ºæ•¸æ“šè¡Œ (åŒ…æ‹¬åŸå§‹çš„ç¬¬ä¸€è¡Œ)
            usecols=columns_to_extract, # åƒ…è®€å–æŒ‡å®šçš„æ¬„ä½
            encoding='UTF-8' # ç¢ºä¿æ­£ç¢ºè§£ç¢¼ä¸­æ–‡
        )
            
        except UnicodeDecodeError:
            df = pd.read_csv(
            file_path,
            header=None,         # å°‡æ‰€æœ‰è¡Œéƒ½è¦–ç‚ºæ•¸æ“šè¡Œ (åŒ…æ‹¬åŸå§‹çš„ç¬¬ä¸€è¡Œ)
            usecols=columns_to_extract, # åƒ…è®€å–æŒ‡å®šçš„æ¬„ä½
            encoding='cp950' # ç¢ºä¿æ­£ç¢ºè§£ç¢¼ä¸­æ–‡
        )

        # 2. ç”±æ–¼ 'header=None' æœƒå°‡åŸå§‹æª”æ¡ˆçš„ç¬¬ä¸€è¡Œ (é€šå¸¸æ˜¯è¡¨é ­) è¦–ç‚ºæ•¸æ“šï¼Œ
        #    è¦å¾ç¬¬äºŒè¡Œé–‹å§‹ï¼Œå¯¦éš›ä¸Šå°±æ˜¯ç§»é™¤ DataFrame çš„ç¬¬ 0 è¡Œã€‚
        #    æˆ‘å€‘ä½¿ç”¨ .iloc[1:] ä¾†å–å¾—å¾ç´¢å¼• 1 é–‹å§‹çš„æ‰€æœ‰è¡Œã€‚
        data_df = df.iloc[1:]
        
        # 3. é‡æ–°å‘½åæ¬„ä½ (å¯é¸ï¼Œä½†è®“è¼¸å‡ºæ›´æ¸…æ™°)
        # é€™è£¡å‡è¨­åŸå§‹ CSV çš„ç¬¬ä¸€è¡Œæœ‰è¡¨é ­ï¼Œæˆ‘å€‘å–å…¶å€¼ä¾†ç•¶ä½œæ–°çš„æ¬„ä½åç¨±
        # ç”±æ–¼æˆ‘å€‘å·²ç¶“è®€å…¥äº†æ‰€æœ‰è³‡æ–™ï¼ŒåŸå§‹çš„æ¬„ä½åç¨±ä½æ–¼ df.iloc[0]
        column_names = df.iloc[0].tolist() 
        data_df.columns = column_names
        
        # 4. é‡è¨­ç´¢å¼•ï¼Œä½¿å…¶å¾ 0 é–‹å§‹é€£çºŒ
        data_df = data_df.reset_index(drop=True)
        
        print(f"âœ… æˆåŠŸæå–æª”æ¡ˆ {os.path.basename(file_path)} çš„ç¬¬ 1 å’Œç¬¬ 2 æ¬„è³‡æ–™" ,f"ç¸½å…±æå– {len(data_df)} ç­†æ•¸æ“šè¡Œ (å¾ç¬¬äºŒè¡Œé–‹å§‹)ã€‚")
        
        return data_df

    except FileNotFoundError:
        print(f"ã€éŒ¯èª¤ã€‘æª”æ¡ˆæœªæ‰¾åˆ°: {file_path}")
        return pd.DataFrame()
    except Exception as e:
        print(f"ã€éŒ¯èª¤ã€‘è®€å–æˆ–è™•ç†æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return pd.DataFrame()

# è®€å– holidays_all.csv æª”æ¡ˆï¼Œç§»é™¤ 'æ—¥æœŸ' æ¬„ä½çš„é‡è¤‡é …ï¼Œä¸¦è¦†å¯«åŸæª”æ¡ˆã€‚
def remove_duplicate_dates():
    """
    è®€å– holidays_all.csv æª”æ¡ˆï¼Œç§»é™¤ 'æ—¥æœŸ' æ¬„ä½çš„é‡è¤‡é …ï¼Œä¸¦è¦†å¯«åŸæª”æ¡ˆã€‚
    """
    print(f"\n--- æ­£åœ¨æ¸…ç†é‡è¤‡æ—¥æœŸ: {CLEAN_FILE_NAME} ---")

    if not FILE_PATH.exists():
        print(f"ã€éŒ¯èª¤ã€‘æ‰¾ä¸åˆ°æª”æ¡ˆ: {FILE_PATH.relative_to(BASE_DIR_get_holidays)}")
        print("è«‹ç¢ºèªæª”æ¡ˆè·¯å¾‘å’Œåç¨±æ˜¯å¦æ­£ç¢ºã€‚")
        return

    try:
        # å˜—è©¦ä½¿ç”¨ UTF-8 (å¸¶ BOM) æˆ– Big5 è®€å–ï¼Œä»¥è™•ç†å¯èƒ½çš„ç·¨ç¢¼å•é¡Œ
        try:
            df = pd.read_csv(FILE_PATH, encoding='utf-8-sig')
        except UnicodeDecodeError:
            df = pd.read_csv(FILE_PATH, encoding='big5')

        # æ¸…ç†æ¬„ä½åç¨±ï¼Œç§»é™¤å¯èƒ½å­˜åœ¨çš„éš±è—ç©ºæ ¼
        df.columns = df.columns.str.strip()

        if 'æ—¥æœŸ' not in df.columns:
            print(f"ã€éŒ¯èª¤ã€‘æª”æ¡ˆä¸­æ‰¾ä¸åˆ° 'æ—¥æœŸ' æ¬„ä½ã€‚æª”æ¡ˆæ¬„ä½ç‚º: {df.columns.tolist()}")
            return
        
        original_count = len(df)
        
        # åŸ·è¡Œé‡è¤‡é …ç§»é™¤ï¼Œåƒ…ä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç¾çš„è¨˜éŒ„
        df_cleaned = df.drop_duplicates(subset=['æ—¥æœŸ'], keep='first')
        
        cleaned_count = len(df_cleaned)
        removed_count = original_count - cleaned_count

        if removed_count > 0:
            # å„²å­˜æ¸…ç†å¾Œçš„æª”æ¡ˆ
            # è¦†å¯«åŸæª”æ¡ˆï¼Œä½¿ç”¨ UTF-8 é™„å¸¶ BOM
            df_cleaned.to_csv(FILE_PATH, index=False, encoding='utf-8-sig')
            
            print(f"âœ… æ¸…ç†å®Œæˆï¼")
            print(f" åŸå§‹ç­†æ•¸: {original_count}")
            print(f" ç§»é™¤é‡è¤‡ç­†æ•¸: {removed_count}")
            print(f" æ¸…ç†å¾Œç­†æ•¸: {cleaned_count}")
            print(f" æª”æ¡ˆå·²æ›´æ–°: {FILE_PATH.relative_to(BASE_DIR_get_holidays)}")
        else:
            print(f"â„¹ï¸ æª”æ¡ˆä¸­æ²’æœ‰ç™¼ç¾é‡è¤‡çš„æ—¥æœŸï¼Œç„¡éœ€æ¸…ç†ã€‚")
            
    except Exception as e:
        print(f"ã€é‡å¤§éŒ¯èª¤ã€‘æ¸…ç†æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

# æ ¹æ“šä¼‘å‡æ—¥ CSV æª”æ¡ˆï¼Œæ•´ç†å‡ºè©²å¹´åº¦çš„éä¼‘å‡æ—¥ï¼ˆå·¥ä½œæ—¥ï¼‰ã€‚
def get_non_holidays(file_path):
    """
    æ ¹æ“šä¼‘å‡æ—¥ CSV æª”æ¡ˆï¼Œæ•´ç†å‡ºè©²å¹´åº¦çš„éä¼‘å‡æ—¥ï¼ˆå·¥ä½œæ—¥ï¼‰ã€‚
    
    :param file_path: ä¼‘å‡æ—¥ CSV æª”æ¡ˆè·¯å¾‘
    :return: åŒ…å«éä¼‘å‡æ—¥è³‡è¨Š (æ—¥æœŸ, æ˜ŸæœŸ, å‡æ—¥èªªæ˜) çš„ DataFrame
    """
    
    # 1. è®€å–ä¼‘å‡æ—¥æª”æ¡ˆ
    try:
        df_holidays = pd.read_csv(file_path)
    except FileNotFoundError:
        print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æª”æ¡ˆ {file_path}")
        return None
    except Exception as e:
        print(f"è®€å–æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

    # å‡è¨­ä¼‘å‡æ—¥æ—¥æœŸæ¬„ä½åç‚º 'æ—¥æœŸ'ï¼Œä¸”æ ¼å¼ç‚º YYYY/MM/DD æˆ– YYYY-MM-DD
    # è«‹æ ¹æ“šæ‚¨çš„å¯¦éš›æª”æ¡ˆä¿®æ”¹æ¬„ä½åç¨±
    date_column = 'æ—¥æœŸ' 
    if date_column not in df_holidays.columns:
        print(f"éŒ¯èª¤ï¼šCSV æª”æ¡ˆä¸­æœªæ‰¾åˆ°æ¬„ä½ '{date_column}'ã€‚è«‹æª¢æŸ¥æ¬„ä½åç¨±ã€‚")
        return None

    # å°‡æ—¥æœŸè½‰æ›ç‚º datetime ç‰©ä»¶ï¼Œä¸¦è™•ç†å¯èƒ½çš„æ ¼å¼å•é¡Œ
    df_holidays[date_column] = pd.to_datetime(df_holidays[date_column], errors='coerce')
    df_holidays.dropna(subset=[date_column], inplace=True)
    
    # 2. ç¢ºå®šè©²å¹´åº¦çš„èµ·å§‹å’ŒçµæŸæ—¥æœŸ
    if df_holidays[date_column].empty:
        print("éŒ¯èª¤ï¼šä¼‘å‡æ—¥è³‡æ–™ç‚ºç©ºæˆ–æ—¥æœŸæ ¼å¼ä¸æ­£ç¢ºã€‚")
        return None
        
    start_year = df_holidays[date_column].min().year
    end_year = df_holidays[date_column].max().year

    # ç‚ºäº†ç°¡åŒ–ï¼Œæˆ‘å€‘åªè™•ç†ç¬¬ä¸€å€‹åµæ¸¬åˆ°çš„å¹´åº¦
    target_year = start_year
    
    # è©²å¹´åº¦çš„èµ·å§‹æ—¥å’ŒçµæŸæ—¥
    start_date = date(target_year, 1, 1)
    end_date = date(target_year, 12, 31)

    # 3. å»ºç«‹è©²å¹´åº¦æ‰€æœ‰æ—¥æœŸçš„åˆ—è¡¨
    all_dates = []
    current_date = start_date
    while current_date <= end_date:
        all_dates.append(current_date)
        current_date += timedelta(days=1)

    # 4. å»ºç«‹ä¼‘å‡æ—¥é›†åˆ (åªå–æ—¥æœŸéƒ¨åˆ†ï¼Œå¿½ç•¥æ™‚é–“)
    holiday_set = set(df_holidays[date_column].dt.date)

    # 5. æ‰¾å‡ºéä¼‘å‡æ—¥
    non_holidays_data = []
    for d in all_dates:
        # éä¼‘å‡æ—¥ AND ä¸æ˜¯é€±æœ« (æ˜ŸæœŸå…­=5, æ˜ŸæœŸæ—¥=6)
        if d not in holiday_set and d.weekday() < 5: 
            # æ˜ŸæœŸå¹¾çš„ä¸­æ–‡é¡¯ç¤º
            day_of_week = d.strftime('%a') # %a é¡¯ç¤ºæ˜ŸæœŸå¹¾çš„ç¸®å¯«
            
            # å‡æ—¥èªªæ˜æ¬„ä½å¡«å¯«ç‚ºã€Œå·¥ä½œæ—¥ã€æˆ–ã€Œäº¤æ˜“æ—¥ã€
            description = "å·¥ä½œæ—¥"
            
            non_holidays_data.append({
                'æ—¥æœŸ': d.strftime('%Y-%m-%d'),
                'æ˜ŸæœŸ': day_of_week,
                'å‡æ—¥èªªæ˜': description
            })

    # 6. å»ºç«‹çµæœ DataFrame
    df_non_holidays = pd.DataFrame(non_holidays_data, columns=['æ—¥æœŸ', 'æ˜ŸæœŸ', 'å‡æ—¥èªªæ˜'])
    
    print(f"âœ… å·²æ•´ç†å‡º {target_year} å¹´çš„éä¼‘å‡æ—¥ã€‚")
    return df_non_holidays

# æ ¹æ“šä¼‘å‡æ—¥ CSV æª”æ¡ˆï¼Œæ•´ç†å‡ºæª”æ¡ˆä¸­æ‰€æœ‰å¹´åº¦çš„éä¼‘å‡æ—¥ï¼ˆå·¥ä½œæ—¥ï¼‰ï¼Œä¸¦è¼¸å‡ºç‚ºæ–°çš„ CSV æª”æ¡ˆã€‚ 
def get_non_holidays_all_years(file_path, output_directory=None):
    """
    æ ¹æ“šä¼‘å‡æ—¥ CSV æª”æ¡ˆï¼Œæ•´ç†å‡ºæª”æ¡ˆä¸­æ‰€æœ‰å¹´åº¦çš„éä¼‘å‡æ—¥ï¼ˆå·¥ä½œæ—¥ï¼‰ï¼Œ
    ä¸¦è¼¸å‡ºç‚ºæ–°çš„ CSV æª”æ¡ˆã€‚

    :param file_path: ä¼‘å‡æ—¥ CSV æª”æ¡ˆè·¯å¾‘
    :param output_directory: è¼¸å‡ºæª”æ¡ˆçš„è³‡æ–™å¤¾è·¯å¾‘ (å¦‚æœç‚º Noneï¼Œå‰‡èˆ‡è¼¸å…¥æª”æ¡ˆåœ¨åŒä¸€è³‡æ–™å¤¾)
    :return: åŒ…å«æ‰€æœ‰éä¼‘å‡æ—¥è³‡è¨Šçš„ DataFrame (æˆ– None if failed)
    """
    
    # 1. è®€å–ä¼‘å‡æ—¥æª”æ¡ˆ
    try:
        # å˜—è©¦è®€å–æª”æ¡ˆï¼Œå»ºè­°ä½¿ç”¨ 'utf-8'ï¼Œå¦‚æœä¸­æ–‡äº‚ç¢¼å¯å˜—è©¦ 'big5'
        df_holidays = pd.read_csv(file_path, encoding='utf-8')
    except FileNotFoundError:
        print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æª”æ¡ˆ {file_path}")
        return None
    except Exception as e:
        print(f"è®€å–æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹æª¢æŸ¥æª”æ¡ˆè·¯å¾‘å’Œç·¨ç¢¼: {e}")
        return None

    # å‡è¨­ä¼‘å‡æ—¥æ—¥æœŸæ¬„ä½åç‚º 'æ—¥æœŸ'ï¼Œè«‹ä¾æ‚¨çš„æª”æ¡ˆå¯¦éš›åç¨±ä¿®æ”¹
    date_column = 'æ—¥æœŸ' 
    if date_column not in df_holidays.columns:
        print(f"éŒ¯èª¤ï¼šCSV æª”æ¡ˆä¸­æœªæ‰¾åˆ°æ¬„ä½ '{date_column}'ã€‚è«‹æª¢æŸ¥æ¬„ä½åç¨±ã€‚")
        return None

    # å°‡æ—¥æœŸè½‰æ›ç‚º datetime ç‰©ä»¶
    df_holidays[date_column] = pd.to_datetime(df_holidays[date_column], errors='coerce')
    df_holidays.dropna(subset=[date_column], inplace=True)
    
    if df_holidays[date_column].empty:
        print("éŒ¯èª¤ï¼šä¼‘å‡æ—¥è³‡æ–™ç‚ºç©ºæˆ–æ—¥æœŸæ ¼å¼ä¸æ­£ç¢ºã€‚")
        return None

    # 2. ç¢ºå®šæ‰€æœ‰æ¶‰åŠçš„å¹´åº¦
    min_year = df_holidays[date_column].min().year
    max_year = df_holidays[date_column].max().year
    # å»ºç«‹æ‰€æœ‰å¹´åº¦çš„ç¯„åœ (ä¾‹å¦‚ 2024, 2025)
    all_years = range(min_year, max_year + 1)

    # 3. å»ºç«‹ä¼‘å‡æ—¥é›†åˆ (åªå–æ—¥æœŸéƒ¨åˆ†ï¼Œæ–¹ä¾¿å¿«é€ŸæŸ¥æ‰¾)
    # æ­¤è™•é›†åˆåŒ…å« CSV å…§æ‰€æœ‰è¢«å®šç¾©ç‚ºä¼‘å¸‚çš„æ—¥æœŸ
    holiday_set = set(df_holidays[date_column].dt.date)

    # æ˜ŸæœŸå¹¾çš„ä¸­æ–‡å°ç…§è¡¨ (0=æ˜ŸæœŸä¸€, 6=æ˜ŸæœŸæ—¥)
    weekday_map = {
        0: 'æ˜ŸæœŸä¸€', 1: 'æ˜ŸæœŸäºŒ', 2: 'æ˜ŸæœŸä¸‰', 3: 'æ˜ŸæœŸå››', 
        4: 'æ˜ŸæœŸäº”', 5: 'æ˜ŸæœŸå…­', 6: 'æ˜ŸæœŸæ—¥'
    }

    all_non_holidays_data = []

    # 4. é‡å°æ¯å€‹å¹´åº¦æ‰¾å‡ºéä¼‘å‡æ—¥ (å·¥ä½œæ—¥)
    print(f"é–‹å§‹è™•ç†å¹´åº¦ç¯„åœ: {min_year} å¹´åˆ° {max_year} å¹´...")
    
    for year in all_years:
        start_date = date(year, 1, 1)
        end_date = date(year, 12, 31)
        
        current_date = start_date
        while current_date <= end_date:
            
            # åˆ¤æ–·æ˜¯å¦ç‚ºã€Œéä¼‘å‡æ—¥ã€ (å·¥ä½œæ—¥å¿…é ˆæ»¿è¶³å…©å€‹æ¢ä»¶)
            # 1. å¿…é ˆæ˜¯é€±ä¸€åˆ°é€±äº” (å·¥ä½œæ—¥)
            # 2. å¿…é ˆä¸åœ¨ CSV åˆ—è¡¨ä¸­çš„ä¼‘å‡æ—¥é›†åˆè£¡
            
            is_weekday = current_date.weekday() < 5 # 0-4 æ˜¯é€±ä¸€åˆ°é€±äº”
            is_holiday_in_list = current_date in holiday_set
            
            if is_weekday and not is_holiday_in_list:
                day_of_week = weekday_map[current_date.weekday()]
                description = "å·¥ä½œæ—¥" # å‡æ—¥èªªæ˜æ¬„ä½å¡«å¯«ç‚ºã€Œå·¥ä½œæ—¥ã€
                
                all_non_holidays_data.append({
                    'æ—¥æœŸ': current_date.strftime('%Y/%m/%d'), 
                    'æ˜ŸæœŸ': day_of_week,
                    'å‡æ—¥èªªæ˜': description
                })
            
            current_date += timedelta(days=1)

    # 5. å»ºç«‹çµæœ DataFrame
    df_non_holidays = pd.DataFrame(all_non_holidays_data, columns=['æ—¥æœŸ', 'æ˜ŸæœŸ', 'å‡æ—¥èªªæ˜'])
    
    # 6. è¼¸å‡ºè‡³ CSV æª”æ¡ˆ
    
    # æ±ºå®šè¼¸å‡ºè·¯å¾‘
    input_dir = os.path.dirname(file_path)
    output_path = output_directory if output_directory else input_dir
    
    # æª”æ¡ˆåç¨±æ ¼å¼ï¼š trading_day_YYYY-YYYY.csv
    output_filename = f'trading_day_{min_year}-{max_year}.csv'
    output_file_path = os.path.join(output_path, output_filename)
    
    # ä½¿ç”¨ 'utf-8-sig' ç·¨ç¢¼ä»¥ç¢ºä¿ Excel é–‹å•Ÿæ™‚ä¸­æ–‡ä¸æœƒäº‚ç¢¼
    df_non_holidays.to_csv(output_file_path, index=False, encoding='utf-8-sig')

    print(f"âœ… æˆåŠŸæ•´ç†å‡º {min_year} åˆ° {max_year} å¹´åº¦çš„éä¼‘å‡æ—¥ (å…± {len(df_non_holidays)} ç­†è³‡æ–™)ã€‚")
    print(f"æª”æ¡ˆå·²å„²å­˜è‡³: {output_file_path}")
    
    return df_non_holidays, min_year, max_year

# --- ä¸»ç¨‹å¼åŸ·è¡Œå€ ---
if __name__ == '__main__':
    
    # æŠ“å– TWSE ä¼‘å¸‚æ—¥æœŸï¼Œå¾2021å¹´(110å¹´é–‹å§‹)ï¼Œå› ç‚ºTWSEåƒ…æä¾›è¿‘å¹¾å¹´çš„è³‡æ–™
    start_year = 2021
    end_year = datetime.datetime.today().year
    
    BASE_DIR_get_twse = pathlib.Path(__file__).resolve().parent / "datas" / "twse_holidays"
    BASE_DIR_get_holidays = pathlib.Path(__file__).resolve().parent / "datas" / "processed" / "get_holidays"
    BASE_DIR_trading_day = pathlib.Path(__file__).resolve().parent / "datas" / "processed"
    
    TARGET_FILE_NAME = "holidays_all.csv"
    TWSE_DATE_COLUMN = 'æ—¥æœŸ'
    
    # æ ¹æ“šæ‚¨çš„è¦æ±‚ï¼Œæ¸…ç†æª”æ¡ˆåç‚º holidays_all.csv
    CLEAN_FILE_NAME = "holidays_all.csv" 
    # æª”æ¡ˆå®Œæ•´è·¯å¾‘: datas/processed/get_holidays/holidays_all.csv
    FILE_PATH = BASE_DIR_get_holidays / CLEAN_FILE_NAME
    
    for get_year in range(start_year, end_year+1):
        # ----------------------------------------------------
        # æŠ“å–ä¸¦å„²å­˜ TWSE ä¼‘å¸‚æ—¥æœŸè³‡æ–™ï¼Œæ¯å¹´ä¸€æ¬¡ 
        print(f"\n-----é–‹å§‹æŠ“å– {get_year} å¹´åº¦ä¼‘å¸‚æ—¥æœŸè³‡æ–™-----")

        TARGET_KEYWORD = f"twse_holidays_{get_year}"
        if check_files_for_keyword(BASE_DIR_get_twse, TARGET_KEYWORD):
            holidays_df = fetch_twse_holidays(get_year)
            save_dataframe_to_csv(holidays_df, get_year)
            
            holidays_df = transform_twse_holiday_dates(holidays_df, get_year)
            filename = pathlib.Path(os.path.dirname(os.path.abspath(__file__)), "datas", "processed" , "get_holidays" , f"twse_holidays_only_day{get_year}.csv")
            save_dataframe_to_csv(holidays_df, get_year, filename=filename)
        else:
            print(f"è·³é {get_year} å¹´çš„TWSEä¼‘å¸‚æ—¥æœŸè³‡æ–™ï¼Œå› ç‚ºå·²å­˜åœ¨ç›¸é—œæª”æ¡ˆã€‚")

        #sys.exit(0) #ä¸­æ–·ç¨‹å¼
        
        # ç”Ÿæˆä¸¦å–å¾—å…¨å¹´åº¦é€±æœ«æ—¥æœŸæ¸…å–®
        TARGET_KEYWORD = f"{get_year}_weekend_calendar"
        if check_files_for_keyword(BASE_DIR_get_holidays, TARGET_KEYWORD):
            full_year_weekend_list = generate_full_year_weekend_dates(get_year)
            save_dates_to_csv(full_year_weekend_list, get_year, filename='weekend_calendar.csv')
        else:
            print(f"è·³é {get_year} å¹´çš„å…¨å¹´åº¦é€±æœ«æ—¥æœŸæ¸…å–®ï¼Œå› ç‚ºå·²å­˜åœ¨ç›¸é—œæª”æ¡ˆã€‚")
        
        
    print("\n--- æ‰€æœ‰å¹´åº¦è³‡æ–™è™•ç†å®Œæˆ ---")
    
        
    extracted_data_combined = pd.DataFrame()


    for file_path in BASE_DIR_get_holidays.glob("*.csv"):

        if file_path.name == TARGET_FILE_NAME:
            print(f"â© ç•¥éç›®æ¨™å„²å­˜æª”æ¡ˆ: {TARGET_FILE_NAME}")
            continue
    # å‘¼å«å‡½å¼

        extracted_data = extract_columns_from_second_row(file_path, columns_to_extract=[0, 1])

        extracted_data_combined = pd.concat([extracted_data_combined,extracted_data], ignore_index=True)

        print(extracted_data_combined)
        print("***"*50)
    df_sorted = extracted_data_combined.sort_values(by='æ—¥æœŸ', ascending=True).reset_index(drop=True)

    print("---- åˆä½µå¾Œä¸¦è½‰æ›æ—¥æœŸæ ¼å¼ ----")
    print(df_sorted)

    file_path = pathlib.Path(os.path.dirname(os.path.abspath(__file__)), "datas", "processed" , "get_holidays" , 'holidays_all.csv')
        
    df_sorted.to_csv(file_path, index=False, encoding='utf-8-sig')
    
    remove_duplicate_dates()
    

# å¦‚æœæ‚¨å¸Œæœ›è¼¸å‡ºæª”æ¡ˆå„²å­˜åœ¨ç‰¹å®šè³‡æ–™å¤¾ï¼Œè«‹ä¿®æ”¹ output_dir
# é è¨­ç‚º Noneï¼Œæœƒå„²å­˜åœ¨è¼¸å…¥æª”æ¡ˆçš„åŒä¸€è³‡æ–™å¤¾
output_dir = None 

result_df, min_year, max_year = get_non_holidays_all_years(file_path, output_dir)

if result_df is not None:
    print(f"\n--- {min_year} åˆ° {max_year} è‚¡ç¥¨äº¤æ˜“æ—¥æ•´ç†å®Œæˆ ---")
    