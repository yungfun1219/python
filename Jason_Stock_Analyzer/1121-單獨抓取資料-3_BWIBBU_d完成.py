import os
import re
import time
import requests
import pandas as pd
from typing import Optional, List
from io import StringIO
import sys
from datetime import datetime, timedelta
import pathlib     # as pathlib

# æŠ‘åˆ¶ç•¶ verify=False æ™‚å½ˆå‡ºçš„ InsecureRequestWarning è­¦å‘Š
requests.packages.urllib3.disable_warnings(requests.packages.urllib3.exceptions.InsecureRequestWarning)

# --- è¨­å®šèˆ‡è·¯å¾‘ ---
# âš ï¸ è«‹ç¢ºä¿ 'datas/raw/3_BWIBBU_d' è·¯å¾‘å­˜åœ¨æˆ–å¯è¢«å»ºç«‹
OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "3_BWIBBU_d")
BASE_URL = "https://www.twse.com.tw/rwd/zh/afterTrading/BWIBBU_d"

Now_time_year = datetime.now().strftime("%Y")  #å–å¾—ç›®å‰ç³»çµ±æ™‚é–“çš„ã€Œå¹´ã€
CSV_FILE_PATH = pathlib.Path(__file__).resolve().parent / "datas" / "processed" / "get_holidays" / f"trading_day_2021-{Now_time_year}.csv"

def get_date_list_based_on_time(file_path: str) -> Optional[List[str]]:
    """
    1. è®€å– CSV æª”æ¡ˆå…§çš„æ—¥æœŸ (å‡å®šç‚ºäº¤æ˜“æ—¥æ¸…å–®)ã€‚
    2. æ ¹æ“šç•¶å‰æ™‚é–“ (21:00 å‰/å¾Œ) ç¢ºå®šæˆªæ­¢æ—¥æœŸ (æ˜¨å¤©/ä»Šå¤©)ã€‚
    3. è¼¸å‡ºå¾æª”æ¡ˆç¬¬ä¸€å€‹æ—¥æœŸåˆ°æˆªæ­¢æ—¥æœŸçš„æ—¥æœŸæ¸…å–®ã€‚
    """
    
    # 1. è®€å– CSV æª”æ¡ˆ
    try:
        # è®€å– CSVï¼Œå‡è¨­æ—¥æœŸåœ¨ç¬¬ä¸€æ¬„
        df = pd.read_csv(file_path, encoding='utf-8-sig')
        
        # å˜—è©¦æ‰¾å‡ºåŒ…å«æ—¥æœŸçš„æ¬„ä½ (å‡è¨­æ˜¯ç¬¬ä¸€æ¬„)
        date_column = df.columns[0]
        
        # éæ¿¾ç©ºå€¼ä¸¦è½‰æ›ç‚ºå·²æ’åºçš„å­—ä¸²åˆ—è¡¨ (æ ¼å¼ç‚º YYYYMMDD)
        all_dates_list = df[date_column].astype(str).str.strip().tolist()
        all_dates_list = sorted(list(set(all_dates_list)))

        if not all_dates_list:
            print(f"éŒ¯èª¤: æª”æ¡ˆ {file_path} ä¸­æ‰¾ä¸åˆ°ä»»ä½•æ—¥æœŸæ•¸æ“šã€‚")
            return None

    except FileNotFoundError:
        print(f"éŒ¯èª¤: æ‰¾ä¸åˆ°æª”æ¡ˆ {file_path}ï¼Œè«‹ç¢ºèªè·¯å¾‘æˆ–å…ˆé‹è¡Œæ¨¡æ“¬åˆå§‹åŒ–ã€‚")
        return None
    except Exception as e:
        print(f"éŒ¯èª¤: è®€å–æˆ–è™•ç†æª”æ¡ˆ {file_path} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

    # 2. åˆ¤æ–·ç¾åœ¨çš„æ™‚é–“ä¾†æ±ºå®šæˆªæ­¢æ—¥æœŸ
    now = datetime.now()
    current_time = now.time()
    
    # å®šç¾© 21:00 (æ™šä¸Š 9 é») çš„æˆªæ­¢æ™‚é–“
    cutoff_time = datetime.strptime("21:00:00", "%H:%M:%S").time()
    
    if current_time >= cutoff_time:
        # 21é»ä»¥å¾Œ (å« 21:00:00): æˆªæ­¢æ—¥ç‚ºä»Šå¤©
        end_date = now.date()
        print(f"ã€æ™‚é–“åˆ¤æ–·ã€‘ç•¶å‰æ™‚é–“ ({now.strftime('%H:%M:%S')}) æ™šæ–¼ 21:00ï¼Œæˆªæ­¢æ—¥ç‚ºä»Šå¤© ({end_date.strftime('%Y/%m/%d')})ã€‚")
    else:
        # 21é»ä»¥å‰: æˆªæ­¢æ—¥ç‚ºæ˜¨å¤©
        end_date = (now - timedelta(days=1)).date()
        print(f"ã€æ™‚é–“åˆ¤æ–·ã€‘ç•¶å‰æ™‚é–“ ({now.strftime('%H:%M:%S')}) æ—©æ–¼ 21:00ï¼Œæˆªæ­¢æ—¥ç‚ºæ˜¨å¤© ({end_date.strftime('%Y/%m/%d')})ã€‚")

    # 3. ç¢ºå®šæ—¥æœŸç¯„åœ
    start_date_str = all_dates_list[0]
    end_date_str = end_date.strftime("%Y%m%d")
    
    # 4. ç¯©é¸ CSV å…§çš„æ—¥æœŸæ¸…å–®
    # åªä¿ç•™ä»‹æ–¼ [èµ·å§‹æ—¥æœŸ, æˆªæ­¢æ—¥æœŸ] ä¹‹é–“çš„æ‰€æœ‰æ—¥æœŸ
    filtered_dates = [
        date_str for date_str in all_dates_list 
        if start_date_str <= date_str <= end_date_str
    ]

    if not filtered_dates:
        print(f"è­¦å‘Š: åœ¨ç¯„åœ [{start_date_str} - {end_date_str}] å…§æ‰¾ä¸åˆ°ä»»ä½•æ—¥æœŸã€‚")
        return []
        
    print(f"\n--- æœ€çµ‚æ—¥æœŸæ¸…å–® (å…± {len(filtered_dates)} å¤©) ---")
    print(f"èµ·å§‹æ—¥æœŸ: {filtered_dates[0]}")
    print(f"æˆªæ­¢æ—¥æœŸ: {filtered_dates[-1]}")
    
    return filtered_dates
# --- è¼”åŠ©å‡½æ•¸ (ç‚ºä½¿ç¨‹å¼ç¢¼å¯åŸ·è¡Œè€ŒåŠ å…¥) ---
# æª¢æŸ¥ä¸¦å»ºç«‹æ‰€éœ€çš„ã€è³‡æ–™å¤¾ã€‘
def _check_folder_and_create(filepath: str):
    os.makedirs(os.path.dirname(filepath), exist_ok=True)

def _fetch_twse_data(url: str) -> Optional[str]:
    """å˜—è©¦å¾ TWSE æŠ“å–è³‡æ–™ï¼Œä¸¦è¿”å›åŸå§‹æ–‡æœ¬ã€‚"""
    try:
        # è¨­ç½® User-Agent ä»¥æ¨¡æ“¬ç€è¦½å™¨è¡Œç‚º
        headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        try:
            response = requests.get(url, headers=headers, verify=False, timeout=10)
            response.raise_for_status() 
            response.encoding = 'Big5'
            return response.text
        except requests.exceptions.HTTPError as errh:
            print(f"âŒ HTTP éŒ¯èª¤ï¼š{errh} (è©²æ—¥å¯èƒ½ç„¡äº¤æ˜“è³‡æ–™)")
        except requests.exceptions.RequestException as err:
            print(f"âŒ é€£ç·šæˆ– Requests éŒ¯èª¤: {err}")
        except Exception as e:
            print(f"âŒ ç™¼ç”Ÿå…¶ä»–éŒ¯èª¤: {e}")
        
        # æª¢æŸ¥ TWSE å›å‚³å…§å®¹æ˜¯å¦ç‚ºéŒ¯èª¤è¨Šæ¯
        if "æŸ¥è©¢æ—¥æœŸå¤§æ–¼ä»Šæ—¥" in response.text or "å¾ˆæŠ±æ­‰" in response.text:
             print("âš ï¸ TWSE ç¶²ç«™è¿”å›éŒ¯èª¤è¨Šæ¯ï¼Œè©²æ—¥å¯èƒ½ç„¡è³‡æ–™æˆ–æ—¥æœŸè¶…å‡ºç¯„åœã€‚")
             return None
        time.sleep(5)
        # å˜—è©¦ä½¿ç”¨æ­£ç¢ºç·¨ç¢¼è§£æï¼Œè™•ç† CSV æª”æ¡ˆå¸¸è¦‹çš„ BOM
        response.encoding = 'utf-8-sig' 
        return response.text
    except requests.exceptions.RequestException as e:
        print(f"âŒ ç¶²è·¯è«‹æ±‚å¤±æ•—æˆ–è¶…æ™‚: {e}")
        return None

def _read_twse_csv(response_text: str, header_row: int) -> Optional[pd.DataFrame]:
    """å°‡ TWSE è¿”å›çš„æ–‡æœ¬è§£æç‚º Pandas DataFrameã€‚"""
    try:
        data = StringIO(response_text)
        # header_row=1: BWIBBU_d å ±è¡¨å¯¦éš›çš„è¡¨é ­åœ¨ç´¢å¼• 1 (0-based)
        df = pd.read_csv(data, 
                        header=header_row, 
                        encoding='utf-8-sig', 
                        skipinitialspace=True,
                        engine='python',
                        on_bad_lines='skip' # <-- é€™å€‹åƒæ•¸æœƒå¿½ç•¥æ¬„ä½æ•¸ä¸æ­£ç¢ºçš„è¡Œï¼Œé¿å…ç¨‹å¼å´©æ½°
        )
        if not df.empty:
            df.columns = df.columns.str.strip() # æ¸…ç†æ¬„ä½åç¨±
            
            # åˆªé™¤çµå°¾å¯èƒ½çš„ç©ºç™½è¡Œæˆ–å‚™è¨»è¡Œ
            if 'æŒ‡æ•¸' in df.columns:
                 # ç§»é™¤ 'æŒ‡æ•¸' æ¬„ä½ç‚ºç©ºå­—ä¸²æˆ–ç©ºç™½çš„è¡Œ
                 df = df[df['æŒ‡æ•¸'].astype(str).str.strip() != '']
                 
            # ç§»é™¤æ‰€æœ‰å…§å®¹ç‚ºç©ºçš„æ¬„ä½ (å¦‚ CSV çµå°¾çš„ç©ºæ¬„ä½)
            df.dropna(axis=1, how='all', inplace=True)
            
            if df.empty:
                print("âš ï¸ è§£æ CSV å¾Œ DataFrame ç‚ºç©ºï¼Œå¯èƒ½ç„¡æœ‰æ•ˆè³‡æ–™ã€‚")
                return None
                
            return df
        return None

    except Exception as e:
        print(f"âŒ è§£æ CSV æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None


# --- æ ¸å¿ƒå–®æ—¥æŠ“å–å‡½æ•¸ (Refactored from user's snippet) ---

def fetch_twse_BWIBBU_d_single(target_date: str) -> Optional[pd.DataFrame]:
    """
    æŠ“å–æŒ‡å®šæ—¥æœŸçš„ BWIBBU_d å ±å‘Šã€‚

    Args:
        target_date: æ¬²æŠ“å–çš„æ—¥æœŸï¼Œæ ¼å¼ç‚º YYYYMMDDã€‚

    Returns:
        æˆåŠŸæ™‚è¿”å› DataFrameï¼Œå¤±æ•—æ™‚è¿”å› Noneã€‚
    """
    if not re.fullmatch(r'\d{8}', target_date): 
        print(f"æ—¥æœŸæ ¼å¼éŒ¯èª¤: {target_date}")
        return None
        
    url = f"{BASE_URL}?date={target_date}&type=ALLBUT0999&response=csv"
    filename = os.path.join(OUTPUT_DIR, f"{target_date}_BWIBBU_d_IndexReturn.csv")
    
    _check_folder_and_create(filename) # ç¢ºä¿ç›®éŒ„å­˜åœ¨
    
    print(f" Â -> å˜—è©¦æŠ“å– {target_date}...")
    
    response_text = _fetch_twse_data(url)
    if response_text is None: 
        # è³‡æ–™æŠ“å–å¤±æ•—ï¼Œ_fetch_twse_data å·²è™•ç†éŒ¯èª¤è¨Šæ¯
        return None
    
    df = _read_twse_csv(response_text, header_row=1)

    # VVVVVVVVVVVVVVVVVVVVVVVVVV
    # é—œéµä¿®æ­£ï¼šåœ¨å˜—è©¦ to_csv ä¹‹å‰ï¼Œæª¢æŸ¥ df æ˜¯å¦ç‚º None
    if df is not None:
        # åŸ·è¡Œæ•¸æ“šæ¸…ç†
        if 'è­‰åˆ¸ä»£è™Ÿ' in df.columns:
            # æ¸…ç† 'è­‰åˆ¸ä»£è™Ÿ' æ¬„ä½ä¸­çš„ç©ºç™½ï¼Œä¸¦ç§»é™¤ç©ºåˆ—
            df = df[df['è­‰åˆ¸ä»£è™Ÿ'].astype(str).str.strip() != '']

        # å„²å­˜è³‡æ–™
        # é€™ä¸€è¡Œå°±æ˜¯ä¹‹å‰ç™¼ç”ŸéŒ¯èª¤çš„åœ°æ–¹ï¼Œç¾åœ¨æœ‰ df is not None çš„ä¿è­·
        try:
            df.to_csv(filename, index=False, encoding='utf-8-sig')
            print(f" Â âœ… {target_date} è³‡æ–™å„²å­˜æˆåŠŸ: {filename}")
        except Exception as e:
            print(f"âŒ {target_date} è³‡æ–™å„²å­˜å¤±æ•—: {e}")
            return None # å„²å­˜å¤±æ•—ä¹Ÿè¿”å› None
            
        return df
    else:
        # å¦‚æœ df æ˜¯ Noneï¼Œè¡¨ç¤ºè§£ææˆ–æ•¸æ“šæœ¬èº«æœ‰å•é¡Œï¼Œç™¼å‡ºè­¦å‘Š
        print(f" Â âš ï¸ {target_date} è³‡æ–™æŠ“å–æˆåŠŸä½†è§£æå¾Œç‚ºç©ºï¼Œè·³éå„²å­˜ã€‚")
        return None

# --- æ‰¹æ¬¡è™•ç†èˆ‡é‡è©¦å‡½æ•¸ (æ»¿è¶³ä½¿ç”¨è€… 2/3/4/5 é»éœ€æ±‚) ---

def batch_fetch_twse_BWIBBU_d(date_list: List[str]):
    """
    é‡å°æä¾›çš„æ—¥æœŸæ¸…å–®ï¼Œé€ä¸€æŠ“å– TWSE BWIBBU_d è³‡æ–™ï¼Œä¸¦åœ¨å¤±æ•—æ™‚å¯¦ä½œé‡è©¦æ©Ÿåˆ¶ã€‚
    Args:
        date_list: åŒ…å« YYYYMMDD æ ¼å¼æ—¥æœŸçš„å­—ä¸²åˆ—è¡¨ã€‚
    """
    print("--- é–‹å§‹æ‰¹æ¬¡æŠ“å– TWSE BWIBBU_d è³‡æ–™ ---")
    
    for target_date in date_list:
        target_date = target_date.replace("/", "")
        max_attempts = 1  # é¦–æ¬¡å˜—è©¦ (1) + 3 æ¬¡é‡è©¦ = æœ€å¤š 4 æ¬¡æ©Ÿæœƒ
        
        for attempt in range(1, max_attempts + 1):
            
            # åŸ·è¡ŒæŠ“å–
            df = fetch_twse_BWIBBU_d_single(target_date)

            
            if df is not None:
                # æˆåŠŸ
                print(f"ğŸŒŸ {target_date} è³‡æ–™å·²å®Œæˆã€‚")
                break  # æˆåŠŸï¼Œè·³å‡ºé‡è©¦è¿´åœˆ
            
            # å¤±æ•—è™•ç†
            if attempt < max_attempts:
                # éå¢å»¶é²æ™‚é–“: ç¬¬ä¸€æ¬¡å¤±æ•—å»¶é² 1 å°æ™‚, ç¬¬äºŒæ¬¡ 2 å°æ™‚, ...
                # (attempt - 1) ä»£è¡¨ç¬¬å¹¾æ¬¡é‡è©¦ (1, 2, 3...)
                delay_hours = attempt 
                
                # âš ï¸ å¯¦éš›ç”Ÿç”¢ç’°å¢ƒè«‹ä½¿ç”¨: delay_seconds = delay_hours * 3600
                # æ¸¬è©¦ç’°å¢ƒç”¨:
                delay_seconds = delay_hours * 5 

                print(f"ğŸš¨ {target_date} æŠ“å–å¤±æ•— (ç¬¬ {attempt} æ¬¡å˜—è©¦)ã€‚å°‡åœ¨ {delay_seconds} ç§’å¾Œé‡è©¦ (ä¸‹æ¬¡ç­‰å¾… {delay_hours} å°æ™‚)...")
                time.sleep(delay_seconds)
            else:
                # è¶…éæœ€å¤§å˜—è©¦æ¬¡æ•¸
                print(f"âŒ {target_date} è³‡æ–™ç¶“é {max_attempts} æ¬¡å˜—è©¦å¾Œä»ç„¶å¤±æ•—ï¼Œè·³éæ­¤æ—¥æœŸã€‚")
        print("ç­‰å¾… 2 ç§’å¾Œï¼Œæº–å‚™è™•ç†ä¸‹ä¸€å€‹æ—¥æœŸ...")
        time.sleep(2)

# --- åŸ·è¡Œç¯„ä¾‹ ---

if __name__ == "__main__":
    # ç¯„ä¾‹æ—¥æœŸæ¸…å–®ã€‚è«‹æ›¿æ›ç‚ºæ‚¨è¦æŠ“å–çš„å¯¦éš›æ—¥æœŸã€‚
    # å»ºè­°åŒ…å«ä¸€äº›å·²çŸ¥æœ‰è³‡æ–™çš„æ—¥æœŸä¾†æ¸¬è©¦æˆåŠŸæ¡ˆä¾‹ã€‚
    
    # 2. åŸ·è¡Œæ—¥æœŸæ¸…å–®ç”Ÿæˆ
    final_date_list = get_date_list_based_on_time(CSV_FILE_PATH)
    # final_date_list = ["20210101"]
    # DATE_LIST_TO_FETCH = [
    #     "20251114", # æˆåŠŸç¯„ä¾‹ 1
    #     "20251115", # æˆåŠŸç¯„ä¾‹ 2
    #     "99991231"  # å¤±æ•—ç¯„ä¾‹ (æœªä¾†æ—¥æœŸï¼Œå°‡è§¸ç™¼é‡è©¦)
    # ]
    
    # æé†’ï¼šè«‹å…ˆç¢ºä¿æ‚¨çš„ç’°å¢ƒå·²å®‰è£æ‰€éœ€çš„å‡½å¼åº«ï¼š
    # pip install requests pandas

    print(final_date_list)

    batch_fetch_twse_BWIBBU_d(final_date_list)

# TEST_OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "test_datas", "raw" , "3_BWIBBU_d","test_output.csv" )
# print(TEST_OUTPUT_DIR)
# _check_folder_and_create(TEST_OUTPUT_DIR)
    