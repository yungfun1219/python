import requests
import pandas as pd
from io import StringIO
import urllib3
import re
from datetime import date
from typing import Optional, Tuple, List
from pathlib import Path
import os
import utils.jason_utils as jutils

# æŠ‘åˆ¶ç•¶ verify=False æ™‚å½ˆå‡ºçš„ InsecureRequestWarning è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ==========================================================
# åƒæ•¸è¨­å®š  --- é…ç½® (Configuration) ---
# ==========================================================
LOG_FETCH_DATE_FILENAME = "last_get_date.log" # å®šç¾©è¨˜éŒ„ä¸Šæ¬¡æˆåŠŸæŠ“å–æ—¥æœŸçš„æ—¥èªŒæª”æ¡ˆåç¨±
SUMMARY_LOG_FILENAME_PREFIX = "fetch_summary" # å®šç¾©æ‘˜è¦æ—¥èªŒæª”æ¡ˆå‰ç¶´

# æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨ä¸”ç¢ºå¯¦æ˜¯ä¸€å€‹æª”æ¡ˆ (éè³‡æ–™å¤¾)
def check_folder_and_create(folder_path: str):
    """
    åƒæ•¸:
        file_path (str): è¦æª¢æŸ¥çš„æª”æ¡ˆè·¯å¾‘ã€‚
    å›å‚³:
        bool: æª”æ¡ˆå­˜åœ¨æ™‚å›å‚³ Trueï¼›å¦å‰‡å›å‚³ Falseã€‚
    """
    OUTPUT_DIR, filename_new = jutils.get_path_to_folder_file(folder_path)
    jutils.check_and_create_folder(OUTPUT_DIR)
    jutils.check_file_exists(filename_new)
    return True

# å…±ç”¨çš„è¼”åŠ©å‡½å¼ï¼Œç”¨æ–¼è™•ç† TWSE çš„ Big5 ç·¨ç¢¼å’Œ Pandas è®€å–é‚è¼¯ã€‚
def _read_twse_csv(response_text: str, header_row: int) -> Optional[pd.DataFrame]:
    """
    Args:
        response_text: HTTP è«‹æ±‚å›å‚³çš„æ–‡å­—å…§å®¹ (Big5 ç·¨ç¢¼)ã€‚
        header_row: CSV æª”æ¡ˆä¸­è³‡æ–™è¡¨é ­æ‰€åœ¨çš„è¡Œæ•¸ (0-indexed)ã€‚
    Returns:
        Optional[pd.DataFrame]: è™•ç†å¾Œçš„ DataFrameã€‚
    """
    try:
        csv_data = StringIO(response_text)
        # å˜—è©¦è®€å– CSV
        df = pd.read_csv(
            csv_data, 
            header=header_row,          # è³‡æ–™è¡¨é ­æ‰€åœ¨çš„è¡Œæ•¸
            skipinitialspace=True,      # è·³éåˆ†éš”ç¬¦å¾Œçš„ç©ºæ ¼
            on_bad_lines='skip',        # è·³éæ ¼å¼ä¸æ­£ç¢ºçš„è¡Œ
            encoding='Big5'             # ä½¿ç”¨ Big5 ç·¨ç¢¼è®€å–
        )
        # TWSE çš„ CSV æ¬„ä½åç¨±å¸¸æœ‰éš±è—ç©ºæ ¼ï¼Œå°è‡´ df.columns ç„¡æ³•æ­£ç¢ºåŒ¹é…ã€‚
        if not df.empty:
            df.columns = df.columns.str.strip()
        # ç§»é™¤æ‰€æœ‰æ¬„ä½çš†ç‚ºç©ºçš„è¡Œ
        df = df.dropna(how='all')
        # ç§»é™¤è³‡æ–™å°¾éƒ¨å¯èƒ½å‡ºç¾çš„å½™ç¸½æˆ–å‚™è¨»è¡Œ
        if not df.empty and df.iloc[-1].astype(str).str.contains('åˆè¨ˆ|ç¸½è¨ˆ|å‚™è¨»', na=False).any():
            df = df.iloc[:-1]
        return df
    except Exception as e:
        print(f"åœ¨è®€å–æˆ–æ¸…ç† CSV æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

        return None
# å…±ç”¨çš„è¼”åŠ©å‡½å¼ï¼Œç”¨æ–¼ç™¼é€ HTTP è«‹æ±‚ä¸¦æª¢æŸ¥ç‹€æ…‹ã€‚
def _fetch_twse_data(url: str) -> Optional[str]:
    """
    Args:
        url: å®Œæ•´çš„ TWSE è³‡æ–™ URLã€‚
    Returns:
        Optional[str]: æˆåŠŸç²å–å¾Œï¼Œä»¥ Big5 è§£ç¢¼çš„æ–‡å­—å…§å®¹ã€‚
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    try:
        response = requests.get(url, headers=headers, verify=False, timeout=10)
        response.raise_for_status() 
        response.encoding = 'Big5'
        return response.text
    except requests.exceptions.HTTPError as errh:
        print(f"âŒ HTTP éŒ¯èª¤ï¼š{errh} (è©²æ—¥å¯èƒ½ç„¡äº¤æ˜“è³‡æ–™)")
    except requests.exceptions.RequestException as err:
        print(f"âŒ é€£ç·šæˆ– Requests éŒ¯èª¤: {err}")
    except Exception as e:
        print(f"âŒ ç™¼ç”Ÿå…¶ä»–éŒ¯èª¤: {e}")

    return None

#ã€‘å°‡æ‰€æœ‰å ±å‘Šçš„æŠ“å–çµæœæ‘˜è¦å¯«å…¥æ—¥èªŒæª”æ¡ˆï¼Œä¸¦åŒæ™‚åˆ—å°åˆ°æ§åˆ¶å°ã€‚
def log_summary_results(results: List[Tuple[str, Optional[pd.DataFrame]]], fetch_date: str, summary_filename_prefix: str = SUMMARY_LOG_FILENAME_PREFIX):
    BASE_DIR = Path(os.path.dirname(os.path.abspath(__file__)))
    OUTPUT_DIR = BASE_DIR / "datas" / "logs"

    # ç¢ºä¿æ—¥èªŒè³‡æ–™å¤¾å­˜åœ¨
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    log_file_name = f"{summary_filename_prefix}_{fetch_date}.log"
    filename_new = OUTPUT_DIR / log_file_name 
    
    # å»ºç«‹æ‘˜è¦å…§å®¹å­—ä¸²
    summary_lines = []
    
    header = "\n" + "="*50 + "\n"
    header += f"--- {fetch_date} å ±å‘ŠæŠ“å–çµæœæ‘˜è¦ ---\n"
    header += "="*50
    summary_lines.append(header)
    
    success_count = 0
    fail_count = 0

    for name, df in results:
        if df is not None:
            line = f"\n[ğŸŸ¢ {name} (æˆåŠŸ)] æ•¸æ“šç­†æ•¸: {len(df)}"
            success_count += 1
        else:
            line = f"[ğŸ”´ {name} (å¤±æ•—)] ç„¡æ•¸æ“šæˆ–æŠ“å–éŒ¯èª¤ã€‚"
            fail_count += 1
        summary_lines.append(line)

    footer = "\n" + "="*50
    footer += f"\nç¸½çµï¼šæˆåŠŸ {success_count} å€‹å ±å‘Š, å¤±æ•— {fail_count} å€‹å ±å‘Šã€‚"
    footer += "\næ‰€æœ‰æˆåŠŸæŠ“å–çš„ CSV æª”æ¡ˆå·²å„²å­˜è‡³å°æ‡‰çš„ 'datas/raw' å­è³‡æ–™å¤¾ä¸­ã€‚"
    footer += "\n--- æ—¥èªŒè¨˜éŒ„çµæŸ ---\n"
    
    summary_lines.append(footer)
    
    log_content = "\n".join(summary_lines)

    # å¯«å…¥æ—¥èªŒæª”æ¡ˆ
    try:
        with open(filename_new, 'w', encoding='utf-8') as f:
            f.write(log_content)
        
        # åŒæ™‚åˆ—å°åˆ°æ§åˆ¶å°
        print(log_content)
        print(f"[æ—¥èªŒ] æˆåŠŸå°‡æ‘˜è¦çµæœå¯«å…¥æª”æ¡ˆï¼š{filename_new}")
    except Exception as e:
        print(f"âŒ å¯«å…¥æ‘˜è¦æ—¥èªŒæª”æ¡ˆç™¼ç”ŸéŒ¯èª¤: {e}")


# --- 10 å¤§ TWSE å ±å‘ŠæŠ“å–å‡½å¼ (åˆ†é èˆ‡å€‹è‚¡) ---
def fetch_twse_stock_day(target_date: str, stock_no: str) -> Optional[pd.DataFrame]:
    """
    (1/10) æŠ“å–æŒ‡å®šæ—¥æœŸå’Œè‚¡ç¥¨ä»£è™Ÿçš„ STOCK_DAY å ±å‘Š (æ¯æ—¥æˆäº¤è³‡è¨Š)ã€‚
    URL: https://www.twse.com.tw/rwd/zh/afterTrading/STOCK_DAY
    """
    if not re.fullmatch(r'\d{8}', target_date): return None
    base_url = "https://www.twse.com.tw/rwd/zh/afterTrading/STOCK_DAY"
    url = f"{base_url}?date={target_date}&stockNo={stock_no}&response=csv"

    OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "1_STOCK_DAY")
    filename = OUTPUT_DIR + f"\\{target_date}_{stock_no}_STOCK_DAY.csv"

    check_folder_and_create(filename)

    print(f"å˜—è©¦æŠ“å– (1/10) {stock_no} STOCK_DAY è³‡æ–™...")
    response_text = _fetch_twse_data(url)
    
    if response_text is None: return None
    
    df = _read_twse_csv(response_text, header_row=1)
    if df is not None and 'æ—¥æœŸ' in df.columns:
        df = df[df['æ—¥æœŸ'].astype(str).str.strip() != '']
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… (1/10) {filename} å„²å­˜æˆåŠŸã€‚")
        return df
    return None

def fetch_twse_mi_index(target_date: str) -> Optional[pd.DataFrame]:
    """
    (2/10) æŠ“å–æŒ‡å®šæ—¥æœŸçš„ MI_INDEX å ±å‘Š (æ‰€æœ‰é¡è‚¡æˆäº¤çµ±è¨ˆ)ã€‚
    URL: https://www.twse.com.tw/rwd/zh/afterTrading/MI_INDEX
    """
    if not re.fullmatch(r'\d{8}', target_date): return None
    base_url = "https://www.twse.com.tw/rwd/zh/afterTrading/MI_INDEX"
    url = f"{base_url}?date={target_date}&type=ALLBUT0999&response=csv"
    OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "2_MI_INDEX")
    filename = OUTPUT_DIR + f"\\{target_date}_MI_INDEX_Sector.csv"

    check_folder_and_create(filename)
    
    print(f"å˜—è©¦æŠ“å– (2/10) MI_INDEX (é¡è‚¡çµ±è¨ˆ) è³‡æ–™...")
    response_text = _fetch_twse_data(url)
    if response_text is None: return None

    # MI_INDEX å ±è¡¨çš„è¡¨é ­åœ¨ç´¢å¼• 3
    df = _read_twse_csv(response_text, header_row=1)

    if df is not None and 'æŒ‡æ•¸' in df.columns:
        df = df[df['æŒ‡æ•¸'].astype(str).str.strip() != '']
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… (2/10) {filename} å„²å­˜æˆåŠŸã€‚")
        return df
    return None

def fetch_twse_bwibbu_d(target_date: str) -> Optional[pd.DataFrame]:
    """
    (3/10) æŠ“å–æŒ‡å®šæ—¥æœŸçš„ BWIBBU_d å ±å‘Š (ç™¼è¡Œé‡åŠ æ¬Šè‚¡åƒ¹æŒ‡æ•¸é¡è‚¡æ—¥æˆäº¤é‡å€¼åŠå ±é…¬ç‡)ã€‚
    URL: https://www.twse.com.tw/rwd/zh/afterTrading/BWIBBU_d
    """
    if not re.fullmatch(r'\d{8}', target_date): return None
    base_url = "https://www.twse.com.tw/rwd/zh/afterTrading/BWIBBU_d"
    url = f"{base_url}?date={target_date}&selectType=ALL&response=csv"
    
    OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "3_BWIBBU_d")
    filename = OUTPUT_DIR + f"\\{target_date}_BWIBBU_d_IndexReturn.csv"

    check_folder_and_create(filename)
        
    print(f"å˜—è©¦æŠ“å– (3/10) BWIBBU_d (é¡è‚¡å ±é…¬ç‡) è³‡æ–™...")
    response_text = _fetch_twse_data(url)
    if response_text is None: return None

    # BWIBBU_d å ±è¡¨çš„è¡¨é ­åœ¨ç´¢å¼• 3
    df = _read_twse_csv(response_text, header_row=1)

    if df is not None and 'è­‰åˆ¸ä»£è™Ÿ' in df.columns:
        df = df[df['è­‰åˆ¸ä»£è™Ÿ'].astype(str).str.strip() != '']
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… (3/10) {filename} å„²å­˜æˆåŠŸã€‚")
        return df
    return None

def fetch_twse_mi_index20(target_date: str) -> Optional[pd.DataFrame]:
    """
    (4/10) æŠ“å–æŒ‡å®šæ—¥æœŸçš„ MI_INDEX20 å ±å‘Š (æ”¶ç›¤æŒ‡æ•¸åŠæˆäº¤é‡å€¼è³‡è¨Š)ã€‚
    URL: https://www.twse.com.tw/rwd/zh/afterTrading/MI_INDEX20
    
    **ä¿®æ­£:** è¡¨é ­ç´¢å¼•æ”¹ç‚º 2 (åŸç‚º 1)ã€‚
    """
    if not re.fullmatch(r'\d{8}', target_date): return None
    base_url = "https://www.twse.com.tw/rwd/zh/afterTrading/MI_INDEX20"
    url = f"{base_url}?date={target_date}&response=csv"
        
    OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "4_MI_INDEX20")
    filename = OUTPUT_DIR + f"\\{target_date}_MI_INDEX20_Market.csv"
    
    check_folder_and_create(filename)
    
    print(f"å˜—è©¦æŠ“å– (4/10) MI_INDEX20 è³‡æ–™...")
    response_text = _fetch_twse_data(url)
    if response_text is None: return None
    
    # MI_INDEX20 å ±è¡¨çš„è¡¨é ­åœ¨ç´¢å¼• 2
    df = _read_twse_csv(response_text, header_row=1)

    if df is not None and 'è­‰åˆ¸ä»£è™Ÿ' in df.columns:
        df = df[df['è­‰åˆ¸ä»£è™Ÿ'].astype(str).str.strip() != '']
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… (4/10) {filename} å„²å­˜æˆåŠŸã€‚")
        return df
    return None

def fetch_twse_twtasu(target_date: str) -> Optional[pd.DataFrame]:
    """
    (5/10) æŠ“å–æŒ‡å®šæ—¥æœŸçš„ TWTASU å ±å‘Š (æ¯æ—¥ç¸½æˆäº¤é‡å€¼èˆ‡å¹³å‡è‚¡åƒ¹)ã€‚
    URL: https://www.twse.com.tw/rwd/zh/afterTrading/TWTASU
    
    """
    if not re.fullmatch(r'\d{8}', target_date): return None
    base_url = "https://www.twse.com.tw/rwd/zh/afterTrading/TWTASU"
    url = f"{base_url}?date={target_date}&response=csv"
    
    OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "5_TWTASU")
    filename = OUTPUT_DIR + f"\\{target_date}_TWTASU_VolumePrice.csv"

    check_folder_and_create(filename)
    
    print(f"å˜—è©¦æŠ“å– (5/10) TWTASU (ç¸½é‡å€¼) è³‡æ–™...")
    response_text = _fetch_twse_data(url)
    if response_text is None: return None

    # TWTASU å ±è¡¨çš„è¡¨é ­åœ¨ç´¢å¼• 3
    df = _read_twse_csv(response_text, header_row=2)
   
    if df is not None and 'è­‰åˆ¸åç¨±' in df.columns: 
        df = df[df['è­‰åˆ¸åç¨±'].astype(str).str.strip() != '']
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… (5/10) {filename} å„²å­˜æˆåŠŸã€‚")
        return df
    return None

def fetch_twse_bfiamu(target_date: str) -> Optional[pd.DataFrame]:
    """
    (6/10) æŠ“å–æŒ‡å®šæ—¥æœŸçš„ BFIAMU å ±å‘Š (è‡ªç‡Ÿå•†è²·è³£è¶…å½™ç¸½è¡¨)ã€‚
    URL: https://www.twse.com.tw/rwd/zh/afterTrading/BFIAMU
    
    **ä¿®æ­£:** è¡¨é ­ç´¢å¼•æ”¹ç‚º 3 (åŸç‚º 2)ã€‚
    """
    if not re.fullmatch(r'\d{8}', target_date): return None
    base_url = "https://www.twse.com.tw/rwd/zh/afterTrading/BFIAMU"
    url = f"{base_url}?date={target_date}&response=csv"
    
    OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "6_BFIAMU")
    filename = OUTPUT_DIR + f"\\{target_date}_BFIAMU_DealerTrade.csv"

    check_folder_and_create(filename)
    
    print(f"å˜—è©¦æŠ“å– (6/10) BFIAMU (è‡ªç‡Ÿå•†è²·è³£è¶…) è³‡æ–™...")
    response_text = _fetch_twse_data(url)
    if response_text is None: return None

    # BFIAMU å ±è¡¨çš„è¡¨é ­åœ¨ç´¢å¼• 3
    df = _read_twse_csv(response_text, header_row=1)

    if df is not None and 'åˆ†é¡æŒ‡æ•¸åç¨±' in df.columns:
        df = df.dropna(how='all') 
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… (6/10) {filename} å„²å­˜æˆåŠŸã€‚")
        return df
    return None

def fetch_twse_fmtqik(target_date: str) -> Optional[pd.DataFrame]:
    """
    (7/10) æŠ“å–æŒ‡å®šæ—¥æœŸçš„ FMTQIK å ±å‘Š (æ¯æ—¥åˆ¸å•†æˆäº¤é‡å€¼ç¸½è¡¨)ã€‚
    URL: https://www.twse.com.tw/rwd/zh/afterTrading/FMTQIK
    
    """
    if not re.fullmatch(r'\d{8}', target_date): return None
    base_url = "https://www.twse.com.tw/rwd/zh/afterTrading/FMTQIK"
    url = f"{base_url}?date={target_date}&response=csv"
    
    OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "7_FMTQIK")
    filename = OUTPUT_DIR + f"\\{target_date}_FMTQIK_BrokerVolume.csv"

    check_folder_and_create(filename)
    
    print(f"å˜—è©¦æŠ“å– (7/10) FMTQIK (åˆ¸å•†æˆäº¤ç¸½è¡¨) è³‡æ–™...")
    response_text = _fetch_twse_data(url)
    if response_text is None: return None

    # FMTQIK å ±è¡¨çš„è¡¨é ­åœ¨ç´¢å¼• 2
    df = _read_twse_csv(response_text, header_row=1)

    if df is not None and 'æ—¥æœŸ' in df.columns:
        df = df[df['æ—¥æœŸ'].astype(str).str.strip() != '']
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… (7/10) {filename} å„²å­˜æˆåŠŸã€‚")
        return df
    return None

# --- 10 å¤§ TWSE å ±å‘ŠæŠ“å–å‡½å¼ (ä¸‰å¤§æ³•äºº) ---

def fetch_twse_bfi82u(target_date: str) -> Optional[pd.DataFrame]:
    """
    (8/10) æŠ“å–æŒ‡å®šæ—¥æœŸçš„ BFI82U å ±å‘Š (ä¸‰å¤§æ³•äººè²·è³£è¶…å½™ç¸½è¡¨ - æ—¥)ã€‚
    URL: https://www.twse.com.tw/rwd/zh/fund/BFI82U
    
    """
    if not re.fullmatch(r'\d{8}', target_date): return None
    base_url = "https://www.twse.com.tw/rwd/zh/fund/BFI82U"
    # åªä½¿ç”¨ dayDate é€²è¡Œæ—¥æœŸåƒæ•¸æ¨¡çµ„åŒ–
    url = f"{base_url}?type=day&dayDate={target_date}&response=csv"
        
    OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "8_BFI82U")
    filename = OUTPUT_DIR + f"\\{target_date}_BFI82U_3IParty_Day.csv"

    check_folder_and_create(filename)
    
    print(f"å˜—è©¦æŠ“å– (8/10) BFI82U (ä¸‰å¤§æ³•äººæ—¥å ±) è³‡æ–™...")
    response_text = _fetch_twse_data(url)
    if response_text is None: return None

    # BFI82U å ±è¡¨çš„è¡¨é ­åœ¨ç´¢å¼• 3
    df = _read_twse_csv(response_text, header_row=1)

    if df is not None and 'å–®ä½åç¨±' in df.columns:
        df = df[df['å–®ä½åç¨±'].astype(str).str.strip() != '']
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… (8/10) {filename} å„²å­˜æˆåŠŸã€‚")
        return df
    return None

def fetch_twse_twt43u(target_date: str) -> Optional[pd.DataFrame]:
    """
    (9/10) æŠ“å–æŒ‡å®šæ—¥æœŸçš„ TWT43U å ±å‘Š (å¤–è³‡åŠé™¸è³‡è²·è³£è¶…å½™ç¸½è¡¨)ã€‚
    URL: https://www.twse.com.tw/rwd/zh/fund/TWT43U
    
    """
    if not re.fullmatch(r'\d{8}', target_date): return None
    base_url = "https://www.twse.com.tw/rwd/zh/fund/TWT43U"
    url = f"{base_url}?date={target_date}&response=csv"

    OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "9_TWT43U")
    filename = OUTPUT_DIR + f"\\{target_date}_TWT43U_ForeignTrade.csv"

    check_folder_and_create(filename)
    
    print(f"å˜—è©¦æŠ“å– (9/10) TWT43U (å¤–è³‡è²·è³£è¶…) è³‡æ–™...")
    response_text = _fetch_twse_data(url)
    if response_text is None: return None

    # TWT43U å ±è¡¨çš„è¡¨é ­åœ¨ç´¢å¼• 3
    df = _read_twse_csv(response_text, header_row=2)

    if df is not None and 'è­‰åˆ¸ä»£è™Ÿ' in df.columns:
        df = df[df['è­‰åˆ¸ä»£è™Ÿ'].astype(str).str.strip() != '']
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… (9/10) {filename} å„²å­˜æˆåŠŸã€‚")
        return df
    return None

def fetch_twse_twt44u(target_date: str) -> Optional[pd.DataFrame]:
    """
    (10/10) æŠ“å–æŒ‡å®šæ—¥æœŸçš„ TWT44U å ±å‘Š (æŠ•ä¿¡è²·è³£è¶…å½™ç¸½è¡¨)ã€‚
    URL: https://www.twse.com.tw/rwd/zh/fund/TWT44U
    """
    if not re.fullmatch(r'\d{8}', target_date): return None
    base_url = "https://www.twse.com.tw/rwd/zh/fund/TWT44U"
    url = f"{base_url}?date={target_date}&response=csv"
    
    OUTPUT_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "datas", "raw" , "10_TWT44U")
    filename = OUTPUT_DIR + f"\\{target_date}_TWT44U_InvestmentTrust.csv"

    check_folder_and_create(filename)
    
    print(f"å˜—è©¦æŠ“å– (10/10) TWT44U (æŠ•ä¿¡è²·è³£è¶…) è³‡æ–™...")
    response_text = _fetch_twse_data(url)
    if response_text is None: return None

    df = _read_twse_csv(response_text, header_row=1)

    if df is not None and 'è­‰åˆ¸ä»£è™Ÿ' in df.columns:
        df = df[df['è­‰åˆ¸ä»£è™Ÿ'].astype(str).str.strip() != '']
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… (10/10) {filename} å„²å­˜æˆåŠŸã€‚")
        return df
    return None

# --- ç¯„ä¾‹ä½¿ç”¨ (æ¨¡çµ„åŒ–åƒæ•¸åŒ–ä¸¦å‘¼å«æ‰€æœ‰ 10 å€‹å‡½å¼) ---

# è¨­å®šæ‚¨æƒ³è¦æŠ“å–çš„ç›®æ¨™æ—¥æœŸ (åªéœ€ä¿®æ”¹æ­¤è™•å³å¯æŠ“å–æ‰€æœ‰å ±å‘Šçš„è³‡æ–™)
# 1. å–å¾—ä»Šå¤©çš„æ—¥æœŸä¸¦æ ¼å¼åŒ–ç‚º YYYYMMDD

TARGET_DATE = date.today().strftime("%Y%m%d") 
TARGET_STOCK = "2330" # å°ç£ç©é«”é›»è·¯è£½é€ 
#TARGET_DATE = "20251008"  # æ¸¬è©¦ç”¨ç‰¹å®šæ—¥æœŸ

print("\n" + "="*50)
print("--- ç¨‹å¼é–‹å§‹åŸ·è¡Œï¼šTWSE 10 å¤§å ±å‘Šæ‰¹é‡æŠ“å– ---")
print(f"ğŸ¯ ç›®æ¨™æŸ¥è©¢æ—¥æœŸ: {TARGET_DATE} | è‚¡ç¥¨ä»£è™Ÿ: {TARGET_STOCK}")
print("="*50 + "\n")

# è¨­ç½®ä¸€å€‹åˆ—è¡¨ä¾†å„²å­˜çµæœï¼Œä¾¿æ–¼æœ€çµ‚é è¦½
results = []

# 1. STOCK_DAY (å€‹è‚¡æ—¥æˆäº¤è³‡è¨Š)
# æ”¹ä»¥å–®ç¨çš„ç¨‹å¼æŠ“å–è³‡æ–™
#results.append(("STOCK_DAY", fetch_twse_stock_day(TARGET_DATE, TARGET_STOCK)))

# 2. MI_INDEX (æ‰€æœ‰é¡è‚¡æˆäº¤çµ±è¨ˆ)
results.append(("MI_INDEX", fetch_twse_mi_index(TARGET_DATE))) 

# 3. BWIBBU_d (é¡è‚¡æ—¥æˆäº¤é‡å€¼åŠå ±é…¬ç‡)
results.append(("BWIBBU_d", fetch_twse_bwibbu_d(TARGET_DATE))) 

# 4. MI_INDEX20 (æ”¶ç›¤æŒ‡æ•¸åŠæˆäº¤é‡å€¼è³‡è¨Š)
results.append(("MI_INDEX20", fetch_twse_mi_index20(TARGET_DATE)))

# 5. TWTASU (æ¯æ—¥ç¸½æˆäº¤é‡å€¼èˆ‡å¹³å‡è‚¡åƒ¹)
results.append(("TWTASU", fetch_twse_twtasu(TARGET_DATE))) 

# 6. BFIAMU (è‡ªç‡Ÿå•†è²·è³£è¶…å½™ç¸½è¡¨)
results.append(("BFIAMU", fetch_twse_bfiamu(TARGET_DATE))) 

# 7. FMTQIK (æ¯æ—¥åˆ¸å•†æˆäº¤é‡å€¼ç¸½è¡¨)
results.append(("FMTQIK", fetch_twse_fmtqik(TARGET_DATE)) )

# 8. BFI82U (ä¸‰å¤§æ³•äººè²·è³£è¶…å½™ç¸½è¡¨ - æ—¥)
results.append(("BFI82U", fetch_twse_bfi82u(TARGET_DATE)))

# 9. TWT43U (å¤–è³‡åŠé™¸è³‡è²·è³£è¶…å½™ç¸½è¡¨)
results.append(("TWT43U", fetch_twse_twt43u(TARGET_DATE)))

# 10. TWT44U (æŠ•ä¿¡è²·è³£è¶…å½™ç¸½è¡¨)
results.append(("TWT44U", fetch_twse_twt44u(TARGET_DATE)))

# --- æœ€çµ‚çµæœé è¦½ ---
print("\n" + "="*50)
print("--- 10 å€‹å ±å‘ŠæŠ“å–çµæœæ‘˜è¦ ---")
print("="*50)

for name, df in results:
    if df is not None:
        print(f"\n[ğŸŸ¢ {name} (æˆåŠŸ)] æ•¸æ“šç­†æ•¸: {len(df)}")
        # print(df.head().to_markdown(index=False)) # è¨»é‡‹æ‰é¿å…è¼¸å‡ºéå¤š
    else:
        print(f"[ğŸ”´ {name} (å¤±æ•—)] ç„¡æ•¸æ“šæˆ–æŠ“å–éŒ¯èª¤ã€‚")

# å¢åŠ æ—¥èªŒå„²å­˜ï¼šè¨˜éŒ„æœ¬æ¬¡å˜—è©¦æŠ“å–çš„æ—¥æœŸ
log_summary_results(results, TARGET_DATE)

print("\næ‰€æœ‰ CSV æª”æ¡ˆå·²å„²å­˜è‡³ç¨‹å¼åŸ·è¡Œç›®éŒ„ä¸‹ã€‚")
print("--- ç¨‹å¼åŸ·è¡ŒçµæŸ ---")
